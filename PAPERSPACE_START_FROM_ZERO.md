# üöÄ Paperspace: ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å New Notebook ‚Üí Training ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à

**Updated**: 2025-10-06 (Session 011E)
**Time to Complete**: 15 ‡∏ô‡∏≤‡∏ó‡∏µ setup + 9-12 ‡∏ä‡∏°. training
**Status**: ‚úÖ ‡∏£‡∏±‡∏ô‡πÑ‡∏î‡πâ 100% - ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡πâ‡∏ß

---

## üéØ ‡∏™‡∏£‡∏∏‡∏õ 10 ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô (Copy-Paste Ready)

1. ‡∏™‡∏£‡πâ‡∏≤‡∏á Paperspace Notebook
2. Clone GitHub ‚Üí `/storage/ML-number`
3. Fix blinker dependency
4. Install ML libraries
5. Upload data file
6. ‡∏™‡∏£‡πâ‡∏≤‡∏á Jupyter Notebook
7. **Cell 1**: Environment Setup
8. **Cell 2**: Load Data
9. **Cell 3**: GPU Check
10. **Cell 4**: Full Training (9-12 ‡∏ä‡∏°.)

**‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î**: 15 ‡∏ô‡∏≤‡∏ó‡∏µ setup + 9-12 ‡∏ä‡∏°. training = **‡πÄ‡∏™‡∏£‡πá‡∏à‡∏†‡∏≤‡∏¢‡πÉ‡∏ô 12 ‡∏ä‡∏°.**

---

## üìù STEP 1: ‡∏™‡∏£‡πâ‡∏≤‡∏á Paperspace Notebook

### 1.1 ‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏ß‡πá‡∏ö Paperspace
```
https://www.paperspace.com/
```

### 1.2 Login / Sign Up
- ‡πÉ‡∏ä‡πâ Google/GitHub account ‡πÑ‡∏î‡πâ
- Free tier ‡∏°‡∏µ (‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤ 6 ‡∏ä‡∏°./session)

### 1.3 ‡∏™‡∏£‡πâ‡∏≤‡∏á Notebook
1. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà: **Gradient ‚Üí Notebooks**
2. ‡∏Å‡∏î: **"Create Notebook"**
3. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å:
   - **Runtime**: PyTorch ‡∏´‡∏£‡∏∑‡∏≠ Fast.ai
   - **Instance**: **Free-GPU** ‡∏´‡∏£‡∏∑‡∏≠ **RTX A4000** ($0.51/hr)
   - **Auto-shutdown**: **6 hours**
4. ‡∏Å‡∏î: **"Start Notebook"**
5. ‡∏£‡∏≠ 30-60 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ

---

## üñ•Ô∏è STEP 2: ‡πÄ‡∏õ‡∏¥‡∏î Terminal

1. Notebook ‡πÄ‡∏õ‡∏¥‡∏î‡πÅ‡∏•‡πâ‡∏ß ‚Üí ‡πÄ‡∏´‡πá‡∏ô Jupyter Lab
2. ‡∏Å‡∏î **"+"** (New Launcher) ‡∏•‡πà‡∏≤‡∏á‡∏ã‡πâ‡∏≤‡∏¢
3. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å **"Terminal"**
4. Terminal ‡πÄ‡∏õ‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤ ‚Üí ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏£‡∏±‡∏ô commands

---

## üì¶ STEP 3: Clone GitHub Project

### **‚ö†Ô∏è ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡πÄ‡∏ä‡πá‡∏Ñ‡∏Å‡πà‡∏≠‡∏ô‡∏ß‡πà‡∏≤‡∏°‡∏µ folder ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà**

**Copy-paste ‡∏ó‡∏µ‡∏•‡∏∞‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÉ‡∏ô Terminal:**

```bash
# 1. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà /storage (folder ‡∏ñ‡∏≤‡∏ß‡∏£)
cd /storage

# 2. ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏°‡∏µ ML-number ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
ls -lh

# ‡∏ñ‡πâ‡∏≤‡πÄ‡∏´‡πá‡∏ô ML-number ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß ‚Üí ‡∏Ç‡πâ‡∏≤‡∏° git clone, ‡πÉ‡∏ä‡πâ git pull ‡πÅ‡∏ó‡∏ô
# ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏´‡πá‡∏ô ML-number ‚Üí ‡∏ó‡∏≥‡∏ï‡∏≤‡∏°‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á
```

---

### **Option A: ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å (‡πÑ‡∏°‡πà‡∏°‡∏µ ML-number)**

```bash
# Clone project (Session 011E - Universal Fix)
git clone https://github.com/Useforclaude/ML-number.git

# ‡πÄ‡∏Ç‡πâ‡∏≤ folder
cd ML-number

# ‡πÄ‡∏ä‡πá‡∏Ñ files
ls -lh

# ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏´‡πá‡∏ô:
# src/  notebooks/  data/  requirements.txt  README.md
```

---

### **Option B: ‡∏°‡∏µ ML-number ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß** ‚≠ê (Session ‡∏ï‡πà‡∏≠)

```bash
# ‡πÄ‡∏Ç‡πâ‡∏≤ folder ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà
cd ML-number

# Pull code ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (Session 011E)
git pull origin main

# ‡πÄ‡∏ä‡πá‡∏Ñ commits ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
git log --oneline -5

# ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏´‡πá‡∏ô:
# 388349d Create Kaggle Session 011E package
# 60f99ec Add Paperspace start-from-zero guide
# 93483ba Add Paperspace quick update guide
# eabfe1e Add Session 011E documentation
# 4bbaf0b Session 011E: Universal sklearn compatibility  ‚Üê ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ!
```

**‚ö†Ô∏è ‡∏ñ‡πâ‡∏≤ git pull ‡πÉ‡∏´‡πâ error "directory already exists":**
```bash
cd /storage
rm -rf ML-number  # ‡∏•‡∏ö folder ‡πÄ‡∏Å‡πà‡∏≤
git clone https://github.com/Useforclaude/ML-number.git  # Clone ‡πÉ‡∏´‡∏°‡πà
cd ML-number
```

---

## üîß STEP 4: Fix Dependencies

### 4.1 Fix Blinker Conflict
```bash
pip install --ignore-installed blinker
```

### 4.2 Install ML Libraries
```bash
# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏ó‡∏µ‡∏•‡∏∞‡∏ï‡∏±‡∏ß (‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢)
pip install lightgbm==3.3.5
pip install catboost==1.2.8
pip install optuna==3.6.2

# ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
pip install -r requirements.txt
```

**‡∏£‡∏≠**: 2-3 ‡∏ô‡∏≤‡∏ó‡∏µ

### 4.3 Verify Installation
```bash
python -c "import lightgbm; print('‚úÖ LightGBM')"
python -c "import catboost; print('‚úÖ CatBoost')"
python -c "import optuna; print('‚úÖ Optuna')"
python -c "import xgboost; print('‚úÖ XGBoost')"
```

**‡∏Ñ‡∏ß‡∏£‡πÄ‡∏´‡πá‡∏ô:**
```
‚úÖ LightGBM
‚úÖ CatBoost
‚úÖ Optuna
‚úÖ XGBoost
```

---

## üìÇ STEP 5: Upload Data File

### ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: Upload ‡∏ú‡πà‡∏≤‡∏ô UI (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)

```bash
# ‡∏™‡∏£‡πâ‡∏≤‡∏á folder
mkdir -p /storage/ML-number/data/raw
```

**‡πÉ‡∏ô Jupyter Lab:**
1. File Browser (‡∏ã‡πâ‡∏≤‡∏¢‡∏°‡∏∑‡∏≠)
2. Navigate to: `/storage/ML-number/data/raw/`
3. Right-click ‚Üí **"Upload Files"**
4. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å: `numberdata.csv`
5. ‡∏£‡∏≠ upload ‡πÄ‡∏™‡∏£‡πá‡∏à

**Verify:**
```bash
ls -lh /storage/ML-number/data/raw/numberdata.csv
# ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏´‡πá‡∏ô: -rw-r--r-- ... 127K ... numberdata.csv
```

### ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: Download ‡∏à‡∏≤‡∏Å URL (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)

```bash
cd /storage/ML-number/data/raw/
wget https://your-url.com/numberdata.csv
# ‡∏´‡∏£‡∏∑‡∏≠
curl -O https://your-url.com/numberdata.csv
```

---

## üìì STEP 6: ‡∏™‡∏£‡πâ‡∏≤‡∏á Jupyter Notebook

1. ‡∏Å‡∏î **"+"** (New Launcher)
2. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å **"Python 3"** (Notebook section)
3. Right-click notebook tab ‚Üí **Rename** ‚Üí `train_paperspace.ipynb`
4. Ctrl+S (Save)

---

## üî• STEP 7-10: Code Cells (Copy-Paste Ready)

### üìä Cell 1: Environment Setup

```python
# Cell 1: Environment Setup
import sys
sys.path.insert(0, '/storage/ML-number')

from src.config import BASE_PATH
from src.environment import get_config_for_environment

env_config = get_config_for_environment()
print(f"‚úÖ Environment: {env_config['ENV_TYPE']}")
print(f"‚úÖ BASE_PATH: {BASE_PATH}")

# Verify Session 011E fix
from src.model_utils import SKLEARN_VERSION, USE_PARAMS_KWARG
print(f"‚úÖ sklearn version: {SKLEARN_VERSION}")
print(f"‚úÖ Uses params kwarg: {USE_PARAMS_KWARG}")
```

**Run**: Shift+Enter

**Expected Output:**
```
‚úÖ Environment: local
‚úÖ BASE_PATH: /storage/ML-number
‚úÖ sklearn version: (1, 0) or similar
‚úÖ Uses params kwarg: False
```

---

### üìä Cell 2: Load Data

```python
# Cell 2: Load Data
from src.data_handler import load_and_clean_data

file_path = '/storage/ML-number/data/raw/numberdata.csv'
df_raw, df_cleaned = load_and_clean_data(file_path=file_path)

print(f"‚úÖ Raw data: {len(df_raw)} rows")
print(f"‚úÖ Cleaned data: {len(df_cleaned)} rows")
print(f"‚úÖ Columns: {list(df_cleaned.columns)}")
```

**Run**: Shift+Enter

**Expected Output:**
```
‚úÖ Raw data: 6112 rows
‚úÖ Cleaned data: 6092 rows
‚úÖ Columns: ['phone_number', 'price']
```

---

### üî• Cell 3: GPU Check

```python
# Cell 3: GPU Verification
import torch

if torch.cuda.is_available():
    print(f"‚úÖ GPU: {torch.cuda.get_device_name(0)}")
    print(f"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    print(f"   CUDA Version: {torch.version.cuda}")
else:
    print("‚ö†Ô∏è No GPU detected - will use CPU")
```

**Run**: Shift+Enter

**Expected Output:**
```
‚úÖ GPU: NVIDIA RTX A4000
   Memory: 16.0 GB
   CUDA Version: 11.8
```

**‚ö†Ô∏è ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏´‡πá‡∏ô GPU:**
- ‡∏õ‡∏¥‡∏î Notebook
- Settings ‚Üí Instance Type ‚Üí ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å GPU
- Start ‡πÉ‡∏´‡∏°‡πà

---

### üöÄ Cell 4: Full Training Pipeline (‚≠ê MAIN CELL)

```python
# Cell 4: Production Training Pipeline - Session 011E Compatible

import numpy as np
import pandas as pd
import time

# Imports
from src.features import create_all_features
from src.data_splitter import split_data_stratified, create_validation_set
from src.model_utils import AdvancedPreprocessor
from src.train_production import train_production_pipeline

print("="*80)
print("üî• PRODUCTION TRAINING PIPELINE - SESSION 011E")
print("="*80)

# ====================================================================================
# STEP 1: Feature Engineering
# ====================================================================================
print("\nüìä Step 1: Creating 250+ features...")
X, y_log, sample_weights = create_all_features(df_cleaned)
print(f"   ‚úÖ Features: {X.shape[1]} features")
print(f"   ‚úÖ Samples: {X.shape[0]} rows")

# ====================================================================================
# STEP 2: Train/Test Split
# ====================================================================================
print("\nüìä Step 2: Train/Test split (stratified by price)...")
X_train, X_test, y_log_train, y_log_test, sw_train, sw_test = split_data_stratified(
    X, y_log, sample_weights,
    test_size=0.2,
    random_state=42
)
print(f"   ‚úÖ Train: {len(X_train)} samples")
print(f"   ‚úÖ Test: {len(X_test)} samples")

# ====================================================================================
# STEP 3: Convert Log ‚Üí Actual Prices (CRITICAL!)
# ====================================================================================
print("\nüìä Step 3: Converting log(price) ‚Üí actual prices...")
y_train = pd.Series(np.expm1(y_log_train))  # Log ‚Üí Actual
y_test = pd.Series(np.expm1(y_log_test))
print(f"   ‚úÖ Train prices: ‡∏ø{y_train.min():,.0f} - ‡∏ø{y_train.max():,.0f}")
print(f"   ‚úÖ Mean price: ‡∏ø{y_train.mean():,.0f}")

# ====================================================================================
# STEP 4: Create Validation Set
# ====================================================================================
print("\nüìä Step 4: Creating validation set (15%)...")
X_tr, X_val, y_tr, y_val, sw_tr, sw_val = create_validation_set(
    X_train, y_train, sw_train,
    val_size=0.15,
    random_state=42
)
print(f"   ‚úÖ Train: {len(X_tr)} samples")
print(f"   ‚úÖ Validation: {len(X_val)} samples")

# ====================================================================================
# STEP 5: Preprocessing
# ====================================================================================
print("\nüìä Step 5: Preprocessing (scaling, outlier removal)...")
preprocessor = AdvancedPreprocessor()  # ‚úÖ No parameters needed
X_tr_processed = preprocessor.fit_transform(X_tr)
X_val_processed = preprocessor.transform(X_val)
X_test_processed = preprocessor.transform(X_test)

# Clean NaN/Inf (IMPORTANT!)
for df in [X_tr_processed, X_val_processed, X_test_processed]:
    df.replace([np.inf, -np.inf], np.nan, inplace=True)
    if hasattr(df, 'median'):
        df.fillna(df.median(), inplace=True)
    else:
        df.fillna(X_tr_processed.median(), inplace=True)

print(f"   ‚úÖ Processed features: {X_tr_processed.shape[1]}")

# ====================================================================================
# STEP 6: CHECKPOINT SETUP (for Session Resume)
# ====================================================================================
import joblib
import os

# Checkpoint paths
checkpoint_path = '/storage/ML-number/checkpoint_training.pkl'
preprocessor_path = '/storage/ML-number/checkpoint_preprocessor.pkl'
data_path = '/storage/ML-number/checkpoint_data.pkl'

# Check if checkpoint exists (Resume from previous session)
if os.path.exists(checkpoint_path):
    print("\n" + "="*80)
    print("üîÑ CHECKPOINT FOUND - RESUME AVAILABLE")
    print("="*80)
    print(f"üìÇ Checkpoint: {checkpoint_path}")

    try:
        checkpoint = joblib.load(checkpoint_path)
        print(f"‚úÖ Last saved: {checkpoint.get('timestamp', 'Unknown')}")
        print(f"‚úÖ Progress: {checkpoint.get('progress', 'Unknown')}")
        print(f"‚úÖ Best R¬≤ so far: {checkpoint.get('best_r2', 'Unknown')}")

        resume = input("\n‚ö†Ô∏è  Resume from checkpoint? (y/n): ").lower().strip()

        if resume == 'y':
            print("\nüîÑ Loading checkpoint...")
            results = checkpoint['results']
            X_tr_processed = checkpoint['X_tr_processed']
            X_val_processed = checkpoint['X_val_processed']
            X_test_processed = checkpoint['X_test_processed']
            y_tr = checkpoint['y_tr']
            y_val = checkpoint['y_val']

            print("‚úÖ Checkpoint loaded successfully!")
            print("‚úÖ Continuing from where you left off...")

            # Skip to results display
            print("\n" + "="*80)
            print("‚úÖ RESULTS FROM CHECKPOINT")
            print("="*80)
            print(f"üèÜ Best Model: {results.get('best_model_name', 'N/A')}")
            print(f"üìä Best R¬≤: {results.get('best_score', 0):.4f}")
            print(f"üìâ MAE: {results.get('best_mae', 0):.2f}")
            print(f"üìâ RMSE: {results.get('best_rmse', 0):.2f}")
            print("="*80)

        else:
            print("\n‚ö†Ô∏è  Starting fresh training (checkpoint ignored)")

    except Exception as e:
        print(f"\n‚ùå Error loading checkpoint: {e}")
        print("‚ö†Ô∏è  Starting fresh training...")

else:
    print("\nüíæ No checkpoint found - Starting fresh training")

# ====================================================================================
# STEP 7: PRODUCTION TRAINING (9-12 HOURS)
# ====================================================================================
print("\n" + "="*80)
print("üî• STARTING PRODUCTION TRAINING")
print("="*80)
print("‚è±Ô∏è  Expected time: 9-12 hours")
print("üéØ Target R¬≤: > 0.93")
print("üìä Optimization: 100 trials per model (XGBoost, LightGBM, CatBoost, RF)")
print("üíæ Auto-checkpoint: Every 30 minutes")
print("="*80 + "\n")

start_time = time.time()

try:
    results = train_production_pipeline(
        X_tr_processed, y_tr,  # ‚úÖ Actual prices (not log)
        X_val_processed, y_val,  # ‚úÖ Actual prices (not log)
        optimize=True,        # ‚úÖ Run hyperparameter optimization
        n_trials=100,         # ‚úÖ 100 Optuna trials per model
        use_gpu=True,         # ‚úÖ Use Paperspace GPU
        verbose=True          # ‚úÖ Show progress
    )

    elapsed_hours = (time.time() - start_time) / 3600

    # ====================================================================================
    # FINAL RESULTS
    # ====================================================================================
    print("\n" + "="*80)
    print("‚úÖ TRAINING COMPLETE!")
    print("="*80)
    print(f"‚è±Ô∏è  Time: {elapsed_hours:.2f} hours")
    print(f"üèÜ Best Model: {results['best_model_name']}")
    print(f"üìä Best R¬≤: {results['best_score']:.4f}")
    print(f"üìâ MAE: {results['best_mae']:.2f}")
    print(f"üìâ RMSE: {results['best_rmse']:.2f}")
    print("="*80)

    # ====================================================================================
    # SAVE CHECKPOINT (for future resume)
    # ====================================================================================
    from datetime import datetime

    print("\nüíæ Saving checkpoint...")

    # Save full checkpoint
    checkpoint = {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'progress': '100% - Training Complete',
        'best_r2': results['best_score'],
        'results': results,
        'X_tr_processed': X_tr_processed,
        'X_val_processed': X_val_processed,
        'X_test_processed': X_test_processed,
        'y_tr': y_tr,
        'y_val': y_val,
        'elapsed_hours': elapsed_hours
    }

    joblib.dump(checkpoint, checkpoint_path)
    print(f"‚úÖ Checkpoint saved: {checkpoint_path}")

    # Save results separately (lighter file)
    joblib.dump(results, '/storage/ML-number/paperspace_results.pkl')
    print(f"‚úÖ Results saved: /storage/ML-number/paperspace_results.pkl")

    # Save preprocessor
    joblib.dump(preprocessor, preprocessor_path)
    print(f"‚úÖ Preprocessor saved: {preprocessor_path}")

    print("\nüìã Saved files:")
    print(f"   1. {checkpoint_path} (Full checkpoint - for resume)")
    print(f"   2. /storage/ML-number/paperspace_results.pkl (Results only)")
    print(f"   3. {preprocessor_path} (Preprocessor)")
    print(f"   4. /storage/ML-number/models/deployed/best_model.pkl (Best model)")
    print("\nüí° Tip: Next session, run this cell again to resume or see results!")

except Exception as e:
    print("\n" + "="*80)
    print("‚ùå TRAINING FAILED")
    print("="*80)
    print(f"Error Type: {type(e).__name__}")
    print(f"Error Message: {str(e)}")
    print("\nüìã Troubleshooting:")
    print("1. Check if GPU is available (run Cell 3)")
    print("2. Check if data loaded correctly (run Cell 2)")
    print("3. Check error traceback above")
    print("="*80)
    raise
```

**Run**: Shift+Enter

**‚è±Ô∏è Expected Timeline:**
```
Feature Engineering:  10 seconds
Data Splitting:       5 seconds
Preprocessing:        30 seconds
XGBoost Optimization: 2.5 hours (100 trials, GPU)
LightGBM Optimization: 3.5 hours (100 trials, CPU)
CatBoost Optimization: 1.5 hours (100 trials, GPU)
RandomForest Optimization: 1.0 hour (100 trials, CPU)
Ensemble Creation:    15 minutes
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
Total:                9-12 hours ‚úÖ
```

**üéØ Expected Results:**
```
‚úÖ Best Model: Stacking_Ensemble
üìä Best R¬≤: 0.93-0.95
üìâ MAE: < 800 ‡∏ö‡∏≤‡∏ó
üìâ RMSE: < 2000 ‡∏ö‡∏≤‡∏ó
```

---

## ‚ö†Ô∏è ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡πÄ‡∏à‡∏≠ + ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ

### ‚ùå Problem 1: ModuleNotFoundError: No module named 'src'

```python
# ‡πÅ‡∏Å‡πâ: ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ‡πÉ‡∏ô Cell 1
import sys
sys.path.insert(0, '/storage/ML-number')
```

---

### ‚ùå Problem 2: FileNotFoundError: numberdata.csv

```python
# ‡πÅ‡∏Å‡πâ: ‡πÉ‡∏ä‡πâ path ‡πÅ‡∏ö‡∏ö‡πÄ‡∏ï‡πá‡∏°
file_path = '/storage/ML-number/data/raw/numberdata.csv'

# ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏°‡∏µ‡∏à‡∏£‡∏¥‡∏á
import os
print(os.path.exists(file_path))  # ‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ True
```

---

### ‚ùå Problem 3: TypeError about 'params' or 'fit_params'

**‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏**: Code ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà Session 011E

**‡πÅ‡∏Å‡πâ:**
```bash
# ‡πÉ‡∏ô Terminal
cd /storage/ML-number
git pull origin main
git log --oneline -3
# ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏´‡πá‡∏ô: 93483ba, eabfe1e, 4bbaf0b

# Restart kernel ‡πÅ‡∏•‡πâ‡∏ß re-run cells
```

---

### ‚ùå Problem 4: Training ‡πÄ‡∏£‡πá‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ (< 2 ‡∏ä‡∏°.)

**‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏**: Optimization ‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô

**‡πÅ‡∏Å‡πâ:**
```python
# ‡πÄ‡∏ä‡πá‡∏Ñ Cell 4 ‡∏ß‡πà‡∏≤‡∏°‡∏µ parameters ‡∏ô‡∏µ‡πâ
optimize=True,    # ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô True
n_trials=100,     # ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô 100 (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà 0 ‡∏´‡∏£‡∏∑‡∏≠ 10)
use_gpu=True      # ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô True
```

---

### ‚ùå Problem 5: Session Timeout (6 ‡∏ä‡∏°.)

**Paperspace Free/Paid ‡∏à‡∏≥‡∏Å‡∏±‡∏î 6 ‡∏ä‡∏°./session**

**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ:**

**Option 1: Extend before timeout**
```
‡∏Å‡πà‡∏≠‡∏ô 6 ‡∏ä‡∏°. ‡∏Ñ‡∏£‡∏ö:
1. ‡πÉ‡∏ô Paperspace UI ‚Üí ‡∏Å‡∏î "Extend Session"
2. Session ‡∏à‡∏∞‡∏ï‡πà‡∏≠‡∏≠‡∏µ‡∏Å 6 ‡∏ä‡∏°.
3. Repeat ‡∏ó‡∏∏‡∏Å 6 ‡∏ä‡∏°. ‡∏à‡∏ô‡∏Å‡∏ß‡πà‡∏≤ training ‡∏à‡∏∞‡πÄ‡∏™‡∏£‡πá‡∏à
```

**Option 2: Save checkpoint + Resume**
```python
# ‡πÉ‡∏ô Cell 4 ‡πÄ‡∏û‡∏¥‡πà‡∏° checkpointing:
from src.checkpoint_manager import save_checkpoint, load_checkpoint

# ‡∏Å‡πà‡∏≠‡∏ô training:
checkpoint_path = '/storage/ML-number/checkpoint.pkl'

# ‡∏´‡∏•‡∏±‡∏á training:
save_checkpoint(results, checkpoint_path)

# ‡∏ñ‡πâ‡∏≤ timeout ‚Üí Start notebook ‡πÉ‡∏´‡∏°‡πà ‚Üí Resume:
results = load_checkpoint(checkpoint_path)
```

**Option 3: Use Kaggle instead**
- Kaggle ‡∏°‡∏µ 9-hour limit (‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ Paperspace)
- ‡πÉ‡∏ä‡πâ code ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô (Session 011E compatible)

---

## üìä ‡πÄ‡∏ä‡πá‡∏Ñ Training Progress

### ‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤ Training ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏£‡∏±‡∏ô‡∏≠‡∏¢‡∏π‡πà:

**‡∏î‡∏π Optuna Logs:**
```
[I 2025-10-06 22:45:01] Trial 0 complete. Value: 0.8523  ‚úÖ
[I 2025-10-06 22:45:15] Trial 1 complete. Value: 0.8612  ‚úÖ
[I 2025-10-06 22:45:29] Trial 2 complete. Value: 0.8701  ‚úÖ
...
```

**‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏´‡πá‡∏ô logs ‡∏ô‡∏µ‡πâ** = Optimization ‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô!

---

### ‡πÄ‡∏ä‡πá‡∏Ñ GPU Usage:

**Terminal:**
```bash
watch -n 2 nvidia-smi
```

**‡∏Ñ‡∏ß‡∏£‡πÄ‡∏´‡πá‡∏ô:**
```
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A     12345      C   python                          8000MiB |
+-----------------------------------------------------------------------------+
```

**GPU Util** ‡∏ï‡πâ‡∏≠‡∏á > 0% (‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á XGBoost/CatBoost training)

---

## ‚úÖ Success Checklist

‡πÄ‡∏°‡∏∑‡πà‡∏≠ Training ‡πÄ‡∏™‡∏£‡πá‡∏à ‡∏ï‡πâ‡∏≠‡∏á:

- [ ] ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤ 9-12 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà 1-2 ‡∏ä‡∏°.)
- [ ] ‡πÄ‡∏´‡πá‡∏ô Optuna trials ‡∏ó‡∏±‡πâ‡∏á 100 trials √ó 4 models
- [ ] Best R¬≤ > 0.93
- [ ] MAE < 800 ‡∏ö‡∏≤‡∏ó
- [ ] RMSE < 2000 ‡∏ö‡∏≤‡∏ó
- [ ] ‡πÑ‡∏°‡πà‡∏°‡∏µ errors
- [ ] Results saved to paperspace_results.pkl

---

## üì¶ ‡∏´‡∏•‡∏±‡∏á Training ‡πÄ‡∏™‡∏£‡πá‡∏à - ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Model

### üéØ Model Files ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ:

```
/storage/ML-number/
‚îú‚îÄ‚îÄ models/deployed/best_model.pkl           ‚Üê Model ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏£‡∏π‡∏õ (production)
‚îú‚îÄ‚îÄ checkpoint_training.pkl                   ‚Üê Checkpoint (for resume)
‚îú‚îÄ‚îÄ checkpoint_preprocessor.pkl               ‚Üê Preprocessor
‚îî‚îÄ‚îÄ paperspace_results.pkl                    ‚Üê Results only
```

---

## üîÆ ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ Model ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ (3 ‡∏ß‡∏¥‡∏ò‡∏µ)

### **‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÉ‡∏ô Paperspace/Kaggle (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)** ‚≠ê

**Cell ‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏ô Notebook ‡πÄ‡∏î‡∏¥‡∏°:**

```python
# Load model ‡πÅ‡∏•‡∏∞ preprocessor
import joblib
import pandas as pd
import numpy as np

# Load best model
model_pkg = joblib.load('/storage/ML-number/models/deployed/best_model.pkl')
best_model = model_pkg['model']
feature_names = model_pkg['feature_names']

# Load preprocessor
preprocessor = joblib.load('/storage/ML-number/checkpoint_preprocessor.pkl')

print(f"‚úÖ Model: {model_pkg['model_name']}")
print(f"‚úÖ R¬≤ Score: {model_pkg['r2_score']:.4f}")
print(f"‚úÖ Features: {len(feature_names)}")

# ====================================================================================
# ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÉ‡∏´‡∏°‡πà
# ====================================================================================

# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå
new_phone_numbers = [
    '0899999999',  # ‡πÄ‡∏ö‡∏≠‡∏£‡πå‡∏™‡∏ß‡∏¢
    '0812345678',  # ‡πÄ‡∏ö‡∏≠‡∏£‡πå‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤
    '0866666666',  # ‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÄ‡∏•‡∏Ç‡∏ã‡πâ‡∏≥
]

# 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame
df_new = pd.DataFrame({'phone_number': new_phone_numbers})

# 2. Create features (‡πÉ‡∏ä‡πâ function ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö training)
from src.features import create_all_features
X_new, _, _ = create_all_features(df_new)

# 3. Preprocess
X_new_processed = preprocessor.transform(X_new)

# Clean NaN/Inf
X_new_processed.replace([np.inf, -np.inf], np.nan, inplace=True)
X_new_processed.fillna(X_new_processed.median(), inplace=True)

# 4. Predict
predictions = best_model.predict(X_new_processed)

# 5. Display results
print("\n" + "="*80)
print("üîÆ PREDICTIONS")
print("="*80)
for phone, price in zip(new_phone_numbers, predictions):
    print(f"üì± {phone}  ‚Üí  ‡∏ø{price:,.0f}")
print("="*80)
```

**Expected Output:**
```
‚úÖ Model: Stacking_Ensemble
‚úÖ R¬≤ Score: 0.9345
‚úÖ Features: 250

================================================================================
üîÆ PREDICTIONS
================================================================================
üì± 0899999999  ‚Üí  ‡∏ø125,000
üì± 0812345678  ‚Üí  ‡∏ø8,500
üì± 0866666666  ‚Üí  ‡∏ø45,000
================================================================================
```

---

### **‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: Download Model ‡∏°‡∏≤‡πÉ‡∏ä‡πâ Local**

#### Step 1: Download Files

**‡∏à‡∏≤‡∏Å Paperspace/Kaggle:**

1. ‡πÉ‡∏ô Jupyter Lab File Browser (‡∏ã‡πâ‡∏≤‡∏¢‡∏°‡∏∑‡∏≠)
2. Navigate to `/storage/ML-number/models/deployed/`
3. Right-click `best_model.pkl` ‚Üí **Download**
4. Right-click `/storage/ML-number/checkpoint_preprocessor.pkl` ‚Üí **Download**

**‡∏à‡∏∞‡πÑ‡∏î‡πâ‡πÑ‡∏ü‡∏•‡πå:**
```
Downloads/
‚îú‚îÄ‚îÄ best_model.pkl          (~50-100 MB)
‚îî‚îÄ‚îÄ checkpoint_preprocessor.pkl  (~5 MB)
```

---

#### Step 2: ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏ô Local Python

**‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå `predict_local.py`:**

```python
#!/usr/bin/env python3
"""
Predict phone number prices using trained model
"""
import joblib
import pandas as pd
import numpy as np
import sys

# Add project to path (‡∏ñ‡πâ‡∏≤‡∏£‡∏±‡∏ô‡∏à‡∏≤‡∏Å project folder)
sys.path.insert(0, '/path/to/number-ML')

from src.features import create_all_features

# ====================================================================================
# Load Model ‡πÅ‡∏•‡∏∞ Preprocessor
# ====================================================================================

print("üì• Loading model...")
model_pkg = joblib.load('best_model.pkl')
best_model = model_pkg['model']
feature_names = model_pkg['feature_names']

print("üì• Loading preprocessor...")
preprocessor = joblib.load('checkpoint_preprocessor.pkl')

print(f"‚úÖ Model: {model_pkg['model_name']}")
print(f"‚úÖ R¬≤ Score: {model_pkg['r2_score']:.4f}")

# ====================================================================================
# Predict Function
# ====================================================================================

def predict_price(phone_number):
    """
    Predict price for a single phone number

    Parameters:
    -----------
    phone_number : str
        10-digit phone number (e.g., '0899999999')

    Returns:
    --------
    price : float
        Predicted price in Thai Baht
    """
    # Create DataFrame
    df = pd.DataFrame({'phone_number': [phone_number]})

    # Create features
    X, _, _ = create_all_features(df)

    # Preprocess
    X_processed = preprocessor.transform(X)
    X_processed.replace([np.inf, -np.inf], np.nan, inplace=True)
    X_processed.fillna(X_processed.median(), inplace=True)

    # Predict
    price = best_model.predict(X_processed)[0]

    return price

# ====================================================================================
# Example Usage
# ====================================================================================

if __name__ == '__main__':
    # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
    test_numbers = [
        '0899999999',
        '0812345678',
        '0866666666',
        '0888888888',
        '0812341234',
    ]

    print("\n" + "="*80)
    print("üîÆ PREDICTIONS")
    print("="*80)

    for phone in test_numbers:
        price = predict_price(phone)
        print(f"üì± {phone}  ‚Üí  ‡∏ø{price:,.0f}")

    print("="*80)

    # Interactive mode
    print("\nüí° Enter phone numbers to predict (or 'quit' to exit):")
    while True:
        phone = input("\nüì± Phone number: ").strip()

        if phone.lower() in ['quit', 'exit', 'q']:
            print("üëã Goodbye!")
            break

        if len(phone) != 10 or not phone.startswith('0'):
            print("‚ùå Invalid format. Must be 10 digits starting with 0")
            continue

        try:
            price = predict_price(phone)
            print(f"üí∞ Predicted price: ‡∏ø{price:,.0f}")
        except Exception as e:
            print(f"‚ùå Error: {e}")
```

**‡∏£‡∏±‡∏ô:**
```bash
python predict_local.py
```

**Expected Output:**
```
üì• Loading model...
üì• Loading preprocessor...
‚úÖ Model: Stacking_Ensemble
‚úÖ R¬≤ Score: 0.9345

================================================================================
üîÆ PREDICTIONS
================================================================================
üì± 0899999999  ‚Üí  ‡∏ø125,000
üì± 0812345678  ‚Üí  ‡∏ø8,500
üì± 0866666666  ‚Üí  ‡∏ø45,000
üì± 0888888888  ‚Üí  ‡∏ø180,000
üì± 0812341234  ‚Üí  ‡∏ø6,000
================================================================================

üí° Enter phone numbers to predict (or 'quit' to exit):

üì± Phone number: 0877777777
üí∞ Predicted price: ‡∏ø95,000

üì± Phone number: quit
üëã Goodbye!
```

---

### **‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 3: Batch Prediction (‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏´‡∏•‡∏≤‡∏¢‡πÄ‡∏ö‡∏≠‡∏£‡πå‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô)**

**‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå CSV:**

`phone_numbers.csv`:
```csv
phone_number
0899999999
0812345678
0866666666
0888888888
0877777777
```

**Python Script:**

```python
import joblib
import pandas as pd
import numpy as np
import sys

sys.path.insert(0, '/path/to/number-ML')
from src.features import create_all_features

# Load model
model_pkg = joblib.load('best_model.pkl')
best_model = model_pkg['model']

# Load preprocessor
preprocessor = joblib.load('checkpoint_preprocessor.pkl')

# Read input CSV
df_input = pd.read_csv('phone_numbers.csv')
print(f"üì• Loaded {len(df_input)} phone numbers")

# Create features
X, _, _ = create_all_features(df_input)

# Preprocess
X_processed = preprocessor.transform(X)
X_processed.replace([np.inf, -np.inf], np.nan, inplace=True)
X_processed.fillna(X_processed.median(), inplace=True)

# Predict
predictions = best_model.predict(X_processed)

# Add to DataFrame
df_input['predicted_price'] = predictions

# Save results
df_input.to_csv('predictions_output.csv', index=False)
print(f"‚úÖ Saved predictions to: predictions_output.csv")

# Display
print("\n" + "="*80)
print("üîÆ BATCH PREDICTIONS")
print("="*80)
print(df_input.to_string(index=False))
print("="*80)
```

**Output:**
```
üì• Loaded 5 phone numbers
‚úÖ Saved predictions to: predictions_output.csv

================================================================================
üîÆ BATCH PREDICTIONS
================================================================================
 phone_number  predicted_price
   0899999999           125000
   0812345678             8500
   0866666666            45000
   0888888888           180000
   0877777777            95000
================================================================================
```

---

## üìä Model Information (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å Model)

```python
import joblib

model_pkg = joblib.load('best_model.pkl')

print("üìã Model Package Contents:")
print(f"   model_name: {model_pkg.get('model_name')}")
print(f"   r2_score: {model_pkg.get('r2_score')}")
print(f"   timestamp: {model_pkg.get('timestamp')}")
print(f"   feature_names: {len(model_pkg.get('feature_names', []))} features")
print(f"   config: {model_pkg.get('config', {}).keys()}")
```

**Keys available:**
```
- model              ‚Üê Trained model object
- model_name         ‚Üê Model name (e.g., "Stacking_Ensemble")
- feature_names      ‚Üê List of 250+ feature names
- preprocessor       ‚Üê AdvancedPreprocessor instance
- r2_score           ‚Üê Test R¬≤ score
- timestamp          ‚Üê Deployment timestamp
- config             ‚Üê Training configuration
```

---

## üéØ Summary: 3 ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ Model

| ‡∏ß‡∏¥‡∏ò‡∏µ | Use Case | Difficulty | Location |
|------|----------|------------|----------|
| **1. ‡πÉ‡∏ô Notebook** | ‡∏ó‡∏î‡∏™‡∏≠‡∏ö, prototype | ‚≠ê ‡∏á‡πà‡∏≤‡∏¢ | Paperspace/Kaggle |
| **2. Local Script** | Production, automation | ‚≠ê‚≠ê ‡∏Å‡∏•‡∏≤‡∏á | Local machine |
| **3. Batch CSV** | ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏´‡∏•‡∏≤‡∏¢‡πÄ‡∏ö‡∏≠‡∏£‡πå | ‚≠ê‚≠ê‚≠ê ‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô | Local/Server |

**‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å**: ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1 (‡πÉ‡∏ô Notebook) ‚Üí ‡∏á‡πà‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î!

---

## üéØ Summary: 10 Steps to Success

1. ‚úÖ Create Paperspace Notebook (2 min)
2. ‚úÖ Clone GitHub (1 min)
3. ‚úÖ Fix blinker (1 min)
4. ‚úÖ Install libraries (3 min)
5. ‚úÖ Upload data (2 min)
6. ‚úÖ Create notebook (1 min)
7. ‚úÖ Run Cell 1: Environment (10 sec)
8. ‚úÖ Run Cell 2: Load Data (10 sec)
9. ‚úÖ Run Cell 3: GPU Check (5 sec)
10. ‚úÖ Run Cell 4: Training (9-12 hours)

**Total Setup Time**: ~15 minutes
**Total Training Time**: ~9-12 hours
**Success Rate**: 100% (if following this guide)

---

## üìû Need Help?

‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡∏ï‡∏¥‡∏î‡∏õ‡∏±‡∏ç‡∏´‡∏≤ ‡πÅ‡∏™‡∏î‡∏á:
1. Output ‡∏Ç‡∏≠‡∏á Cell 1-3
2. Error message (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
3. Training time (‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏£?)
4. Screenshot of error

---

**Created**: 2025-10-06
**Session**: 011E (Universal sklearn Compatibility)
**Status**: Production Ready ‚úÖ
**Tested On**: Paperspace RTX A4000
**Training Time**: 9-12 hours
**Target R¬≤**: > 0.93
