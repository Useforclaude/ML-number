# ЁЯЪА Paperspace Modular Training - р╕Др╕╣р╣Ир╕бр╕╖р╕нр╕Йр╕Ър╕▒р╕Ър╕кр╕бр╕Ър╕╣р╕гр╕Ур╣М

**р╕кр╕│р╕лр╕гр╕▒р╕Ъ:** ML Phone Number Prediction (р╣Бр╕вр╕Бр╣Ар╕Чр╕гр╕Щр╕Чр╕╡р╕ер╕░р╣Вр╕бр╣Ар╕Фр╕е)
**Platform:** Paperspace Terminal (Free GPU M4000 р╕лр╕гр╕╖р╕н Growth Plan)
**Last Updated:** 2025-10-08

---

## ЁЯУЛ р╕кр╕▓р╕гр╕Ър╕▒р╕Н

1. [р╣Ар╕Хр╕гр╕╡р╕вр╕б Paperspace Account](#1-р╣Ар╕Хр╕гр╕╡р╕вр╕б-paperspace-account)
2. [р╕кр╕гр╣Йр╕▓р╕З Notebook р╣Гр╕лр╕бр╣И](#2-р╕кр╕гр╣Йр╕▓р╕З-notebook-р╣Гр╕лр╕бр╣И)
3. [Setup Environment](#3-setup-environment)
4. [р╕гр╕▒р╕Щ Modular Training](#4-р╕гр╕▒р╕Щ-modular-training-р╣Бр╕вр╕Бр╕Чр╕╡р╕ер╕░р╣Вр╕бр╣Ар╕Фр╕е)
5. [Monitor Progress](#5-monitor-progress)
6. [Troubleshooting](#6-troubleshooting)

---

## 1. р╣Ар╕Хр╕гр╕╡р╕вр╕б Paperspace Account

### р╕Хр╕▒р╕зр╣Ар╕ер╕╖р╕нр╕Б Plan:

| Plan | GPU | Cost | Training Time | р╣Бр╕Щр╕░р╕Щр╕│ |
|------|-----|------|---------------|-------|
| **Free** | M4000 (8 GB) | р╕Яр╕гр╕╡ | 11-14 р╕Кр╕б. | тЬЕ р╣Гр╕Кр╣Йр╣Др╕Фр╣Й р╕Кр╣Йр╕▓р╕лр╕Щр╣Ир╕нр╕в |
| **Growth** | A4000/P5000 (16 GB) | $8/р╣Ар╕Фр╕╖р╕нр╕Щ | 8-11 р╕Кр╕б. | тЬЕ р╣Ар╕гр╣Зр╕зр╕Бр╕зр╣Ир╕▓ |

### р╕ер╕Зр╕Чр╕░р╣Ар╕Ър╕╡р╕вр╕Щ:

```
1. р╣Др╕Ыр╕Чр╕╡р╣И: https://www.paperspace.com/
2. р╕кр╕бр╕▒р╕Др╕г (Email + Password)
3. р╣Ар╕ер╕╖р╕нр╕Б Plan:
   - Free: M4000 GPU (р╕Яр╕гр╕╡)
   - Growth: A4000 GPU ($8/р╣Ар╕Фр╕╖р╕нр╕Щ - р╕Цр╣Йр╕▓р╕Хр╣Йр╕нр╕Зр╕Бр╕▓р╕гр╣Ар╕гр╣Зр╕з)
```

---

## 2. р╕кр╕гр╣Йр╕▓р╕З Notebook р╣Гр╕лр╕бр╣И

### 2.1 Create Notebook

```
1. р╣Др╕Ыр╕Чр╕╡р╣И Gradient тЖТ Notebooks
2. р╕Др╕ер╕┤р╕Б "Create"
3. р╣Ар╕ер╕╖р╕нр╕Б Template: "PyTorch" р╕лр╕гр╕╖р╕н "Python 3"
4. р╣Ар╕ер╕╖р╕нр╕Б GPU:
   - Free: Free-GPU (M4000) тЖР р╕Яр╕гр╕╡
   - Growth: RTX A4000 тЖР р╣Ар╕гр╣Зр╕зр╕Бр╕зр╣Ир╕▓
5. р╕Др╕ер╕┤р╕Б "Start Notebook"
```

### 2.2 р╣Ар╕Ыр╕┤р╕Ф Terminal

```
1. р╕гр╕н Notebook start (1-2 р╕Щр╕▓р╕Чр╕╡)
2. р╣Ар╕бр╕╖р╣Ир╕нр╣Ар╕Ыр╕┤р╕Фр╣Бр╕ер╣Йр╕з тЖТ р╣Др╕Ыр╕Чр╕╡р╣И "Terminal" tab (р╕Фр╣Йр╕▓р╕Щр╕ер╣Ир╕▓р╕З)
   р╕лр╕гр╕╖р╕н: Menu тЖТ View тЖТ Terminal
3. р╕Ир╕░р╣Ар╕лр╣Зр╕Щ prompt: root@xxxxxxxx:/notebooks#
```

**тЬЕ р╕Юр╕гр╣Йр╕нр╕бр╣Гр╕Кр╣Йр╕Зр╕▓р╕Щ!**

---

## 3. Setup Environment

### 3.1 Clone р╣Вр╕Ыр╕гр╣Ар╕Ир╕Бр╕Хр╣М

```bash
# р╣Ар╕Вр╣Йр╕▓р╣Вр╕Яр╕ер╣Ар╕Фр╕нр╕гр╣М /storage (persistent storage)
cd /storage

# Clone repository
git clone https://github.com/Useforclaude/ML-number.git

# р╣Ар╕Вр╣Йр╕▓р╣Вр╕Яр╕ер╣Ар╕Фр╕нр╕гр╣Мр╣Вр╕Ыр╕гр╣Ар╕Ир╕Бр╕Хр╣М
cd ML-number

# р╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ъ
pwd
# Output: /storage/ML-number
```

### 3.2 р╕кр╕гр╣Йр╕▓р╕З Virtual Environment

```bash
# р╕кр╕гр╣Йр╕▓р╕З venv
python3 -m venv .venv

# Activate
source .venv/bin/activate

# р╕Ир╕░р╣Ар╕лр╣Зр╕Щ (.venv) р╣Гр╕Щ prompt:
# (.venv) root@xxxxxxxx:/storage/ML-number#
```

### 3.3 р╕Хр╕┤р╕Фр╕Хр╕▒р╣Йр╕З Dependencies

```bash
# р╕Хр╕┤р╕Фр╕Хр╕▒р╣Йр╕З packages р╕Чр╕▒р╣Йр╕Зр╕лр╕бр╕Ф
pip install -r requirements.txt

# р╕гр╕н 5-10 р╕Щр╕▓р╕Чр╕╡ (р╕Вр╕╢р╣Йр╕Щр╕Бр╕▒р╕Ър╕Др╕зр╕▓р╕бр╣Ар╕гр╣Зр╕з internet)
```

### 3.4 р╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ъ GPU

```bash
# р╣Ар╕Кр╣Зр╕Д GPU
nvidia-smi

# р╕Др╕зр╕гр╣Ар╕лр╣Зр╕Щ:
# +-----------------------------------------------------------------------------+
# | NVIDIA-SMI 525.x.xx    Driver Version: 525.x.xx    CUDA Version: 12.0     |
# |-------------------------------+----------------------+----------------------+
# | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
# | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
# |===============================+======================+======================|
# |   0  Quadro M4000        Off  | 00000000:00:05.0 Off |                  N/A |
# | 46%   32C    P8    11W / 120W |      0MiB /  8192MiB |      0%      Default |
# +-----------------------------------------------------------------------------+

# р╕Цр╣Йр╕▓р╣Ар╕лр╣Зр╕Щ Quadro M4000 (Free) р╕лр╕гр╕╖р╕н RTX A4000 (Growth) тЖТ тЬЕ OK!
```

### 3.5 р╕кр╕гр╣Йр╕▓р╕Зр╣Вр╕Яр╕ер╣Ар╕Фр╕нр╕гр╣Мр╕кр╕│р╕лр╕гр╕▒р╕Ъ logs

```bash
# р╕кр╕гр╣Йр╕▓р╕Зр╣Вр╕Яр╕ер╣Ар╕Фр╕нр╕гр╣М logs
mkdir -p logs

# р╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ъ
ls -la | grep logs
# drwxr-xr-x  2 root root 4096 Oct  8 10:00 logs
```

**тЬЕ Setup р╣Ар╕кр╕гр╣Зр╕Ир╕кр╕бр╕Ър╕╣р╕гр╕Ур╣М!**

---

## 4. р╕гр╕▒р╕Щ Modular Training (р╣Бр╕вр╕Бр╕Чр╕╡р╕ер╕░р╣Вр╕бр╣Ар╕Фр╕е)

### 4.1 р╕ар╕▓р╕Юр╕гр╕зр╕б Pipeline

```
Total Training Time: 8-14 hours (р╕Вр╕╢р╣Йр╕Щр╕Бр╕▒р╕Ъ GPU)
тФЬтФАтФА XGBoost:     2-4 hours  тЖТ models/checkpoints/xgboost_checkpoint.pkl
тФЬтФАтФА LightGBM:    3-5 hours  тЖТ models/checkpoints/lightgbm_checkpoint.pkl
тФЬтФАтФА CatBoost:    1-3 hours  тЖТ models/checkpoints/catboost_checkpoint.pkl
тФЬтФАтФА RandomForest: 1-2 hours  тЖТ models/checkpoints/random_forest_checkpoint.pkl
тФФтФАтФА Ensemble:    15-30 min  тЖТ models/deployed/best_model.pkl
```

### 4.2 р╕гр╕▒р╕Щр╕Чр╕╡р╕ер╕░р╣Вр╕бр╣Ар╕Фр╕е (р╣Бр╕Щр╕░р╕Щр╕│!)

#### Step 1: XGBoost (2-4 hours)

```bash
# р╕гр╕▒р╕Щр╣Бр╕Ър╕Ъ background (р╣Гр╕Кр╣Й nohup)
nohup python train_xgboost_only.py > logs/xgb.log 2>&1 &

# р╕Ир╕░р╣Др╕Фр╣Й PID (р╣Ар╕Кр╣Ир╕Щ [1] 12345)
# р╕Ир╕Ф PID р╣Др╕зр╣Йр╣Ар╕Ьр╕╖р╣Ир╕нр╕Хр╣Йр╕нр╕Зр╣Гр╕Кр╣Й

# Monitor progress
tail -f logs/xgb.log

# р╕Ир╕░р╣Ар╕лр╣Зр╕Щ:
# 2025-10-08 10:00:00 - INFO - Starting XGBoost training...
# 2025-10-08 10:00:05 - INFO - Loading data...
# 2025-10-08 10:00:10 - INFO - Data loaded: 6,100 samples
# 2025-10-08 10:00:15 - INFO - Feature engineering...
# ...
# Trial 001: R┬▓ = 0.8456
# Trial 010: R┬▓ = 0.8723
# ...

# р╕Бр╕Ф Ctrl+C р╣Ар╕Юр╕╖р╣Ир╕нр╕лр╕вр╕╕р╕Ф monitor (р╣Вр╕бр╣Ар╕Фр╕ер╕вр╕▒р╕Зр╕гр╕▒р╕Щр╕Хр╣Ир╕н!)
```

**р╕гр╕нр╕Ир╕Щр╣Ар╕кр╕гр╣Зр╕И (~2-4 р╕Кр╕б.)** р╕Бр╣Ир╕нр╕Щр╣Др╕Ы Step р╕Цр╕▒р╕Фр╣Др╕Ы

**р╕зр╕┤р╕Шр╕╡р╣Ар╕Кр╣Зр╕Др╕зр╣Ир╕▓р╣Ар╕кр╕гр╣Зр╕Ир╕лр╕гр╕╖р╕нр╕вр╕▒р╕З:**
```bash
# р╣Ар╕Кр╣Зр╕Д process
ps aux | grep train_xgboost

# р╕Цр╣Йр╕▓р╕вр╕▒р╕Зр╕бр╕╡ тЖТ р╕вр╕▒р╕Зр╕Чр╕│р╕Зр╕▓р╕Щр╕нр╕вр╕╣р╣И
# р╕Цр╣Йр╕▓р╣Др╕бр╣Ир╕бр╕╡ тЖТ р╣Ар╕кр╕гр╣Зр╕Ир╣Бр╕ер╣Йр╕з

# р╣Ар╕Кр╣Зр╕Д checkpoint file
ls -lh models/checkpoints/xgboost_checkpoint.pkl
# р╕Цр╣Йр╕▓р╕бр╕╡р╣Др╕Яр╕ер╣М тЖТ р╣Ар╕кр╕гр╣Зр╕Ир╣Бр╕ер╣Йр╕з!
```

---

#### Step 2: LightGBM (3-5 hours)

```bash
# р╕гр╕н XGBoost р╣Ар╕кр╕гр╣Зр╕Ир╕Бр╣Ир╕нр╕Щ!

# р╕гр╕▒р╕Щ LightGBM
nohup python train_lightgbm_only.py > logs/lgb.log 2>&1 &

# Monitor
tail -f logs/lgb.log

# р╕гр╕нр╕Ир╕Щр╣Ар╕кр╕гр╣Зр╕И (~3-5 р╕Кр╕б.)
```

**р╣Ар╕Кр╣Зр╕Др╕зр╣Ир╕▓р╣Ар╕кр╕гр╣Зр╕И:**
```bash
ls -lh models/checkpoints/lightgbm_checkpoint.pkl
```

---

#### Step 3: CatBoost (1-3 hours)

```bash
# р╕гр╕▒р╕Щ CatBoost
nohup python train_catboost_only.py > logs/cat.log 2>&1 &

# Monitor
tail -f logs/cat.log

# р╕гр╕нр╕Ир╕Щр╣Ар╕кр╕гр╣Зр╕И (~1-3 р╕Кр╕б.)
```

**р╣Ар╕Кр╣Зр╕Др╕зр╣Ир╕▓р╣Ар╕кр╕гр╣Зр╕И:**
```bash
ls -lh models/checkpoints/catboost_checkpoint.pkl
```

---

#### Step 4: RandomForest (1-2 hours)

```bash
# р╕гр╕▒р╕Щ RandomForest
nohup python train_rf_only.py > logs/rf.log 2>&1 &

# Monitor
tail -f logs/rf.log

# р╕гр╕нр╕Ир╕Щр╣Ар╕кр╕гр╣Зр╕И (~1-2 р╕Кр╕б.)
```

**р╣Ар╕Кр╣Зр╕Др╕зр╣Ир╕▓р╣Ар╕кр╕гр╣Зр╕И:**
```bash
ls -lh models/checkpoints/random_forest_checkpoint.pkl
```

---

#### Step 5: Ensemble (15-30 minutes)

```bash
# р╕гр╕нр╕Чр╕╕р╕Бр╣Вр╕бр╣Ар╕Фр╕ер╣Ар╕кр╕гр╣Зр╕Ир╕Бр╣Ир╕нр╕Щ! (XGB, LGB, CAT, RF)

# р╣Ар╕Кр╣Зр╕Др╕зр╣Ир╕▓р╕Др╕гр╕Ъ 4 checkpoints
ls -lh models/checkpoints/
# р╕Др╕зр╕гр╣Ар╕лр╣Зр╕Щ:
# xgboost_checkpoint.pkl
# lightgbm_checkpoint.pkl
# catboost_checkpoint.pkl
# random_forest_checkpoint.pkl

# р╕гр╕▒р╕Щ Ensemble (р╣Др╕бр╣Ир╕Хр╣Йр╕нр╕З nohup р╣Ар╕Юр╕гр╕▓р╕░р╣Ар╕гр╣Зр╕з)
python train_ensemble_only.py

# р╕Ир╕░р╣Ар╕лр╣Зр╕Щ:
# Loading checkpoints...
# тЬЕ Loaded XGBoost (R┬▓ = 0.92)
# тЬЕ Loaded LightGBM (R┬▓ = 0.89)
# тЬЕ Loaded CatBoost (R┬▓ = 0.87)
# тЬЕ Loaded RandomForest (R┬▓ = 0.84)
# Creating ensembles...
# Best model: Stacking Ensemble (R┬▓ = 0.93)
# Saved to: models/deployed/best_model.pkl
```

**тЬЕ р╣Ар╕Чр╕гр╕Щр╣Ар╕кр╕гр╣Зр╕Ир╕кр╕бр╕Ър╕╣р╕гр╕Ур╣М!**

---

### 4.3 р╕гр╕▒р╕Щр╣Бр╕Ър╕Ър╕гр╕зр╕Ф (р╕Цр╣Йр╕▓р╣Др╕бр╣Ир╕Бр╕ер╕▒р╕з timeout)

```bash
# р╕гр╕▒р╕Щр╕Чр╕▒р╣Йр╕Зр╕лр╕бр╕Фр╕Юр╕гр╣Йр╕нр╕бр╕Бр╕▒р╕Щ (р╣Др╕бр╣Ир╣Бр╕Щр╕░р╕Щр╕│)
nohup python train_xgboost_only.py > logs/xgb.log 2>&1 &
nohup python train_lightgbm_only.py > logs/lgb.log 2>&1 &
nohup python train_catboost_only.py > logs/cat.log 2>&1 &
nohup python train_rf_only.py > logs/rf.log 2>&1 &

# Monitor all
tail -f logs/xgb.log logs/lgb.log logs/cat.log logs/rf.log

# р╕гр╕нр╕Чр╕╕р╕Бр╣Вр╕бр╣Ар╕Фр╕ер╣Ар╕кр╕гр╣Зр╕И тЖТ р╕гр╕▒р╕Щ ensemble
python train_ensemble_only.py
```

**тЪая╕П Pros:** р╣Ар╕гр╣Зр╕зр╕Бр╕зр╣Ир╕▓ (р╕гр╕▒р╕Щр╕Юр╕гр╣Йр╕нр╕бр╕Бр╕▒р╕Щ)
**тЪая╕П Cons:** р╣Гр╕Кр╣Й RAM/GPU р╣Ар╕вр╕нр╕░ р╕нр╕▓р╕Ир╕лр╕бр╕Фр╕Чр╕гр╕▒р╕Юр╕вр╕▓р╕Бр╕г

---

## 5. Monitor Progress

### 5.1 р╣Ар╕Кр╣Зр╕Д Logs р╣Бр╕Ър╕Ъ Real-time

```bash
# р╣Ар╕Кр╣Зр╕Д log р╕Чр╕╡р╕ер╕░р╣Др╕Яр╕ер╣М
tail -f logs/xgb.log

# р╣Ар╕Кр╣Зр╕Др╕лр╕ер╕▓р╕вр╣Др╕Яр╕ер╣Мр╕Юр╕гр╣Йр╕нр╕бр╕Бр╕▒р╕Щ
tail -f logs/xgb.log logs/lgb.log

# р╣Ар╕Кр╣Зр╕Д 50 р╕Ър╕гр╕гр╕Чр╕▒р╕Фр╕ер╣Ир╕▓р╕кр╕╕р╕Ф
tail -50 logs/xgb.log

# р╣Ар╕Кр╣Зр╕Др╕зр╣Ир╕▓р╕бр╕╡ error р╕бр╕▒р╣Йр╕в
grep -i error logs/xgb.log
```

### 5.2 р╣Ар╕Кр╣Зр╕Д GPU Usage

```bash
# р╣Ар╕Кр╣Зр╕Др╕Др╕гр╕▒р╣Йр╕Зр╣Ар╕Фр╕╡р╕вр╕з
nvidia-smi

# р╣Ар╕Кр╣Зр╕Др╕Чр╕╕р╕Б 2 р╕зр╕┤р╕Щр╕▓р╕Чр╕╡ (real-time)
watch -n 2 nvidia-smi

# р╕Ир╕░р╣Ар╕лр╣Зр╕Щ:
# +-----------------------------------------------------------------------------+
# |   0  Quadro M4000        Off  | 00000000:00:05.0 Off |                  N/A |
# | 85%   72C    P0   112W / 120W |   6800MiB /  8192MiB |     95%      Default |
# +-----------------------------------------------------------------------------+
#                                  тЖС GPU Usage         тЖС Memory Used

# р╕Цр╣Йр╕▓ GPU-Util > 70% тЖТ р╕Бр╕│р╕ер╕▒р╕Зр╣Гр╕Кр╣Й GPU тЬЕ
# р╕Цр╣Йр╕▓ GPU-Util < 10% тЖТ р╣Др╕бр╣Ир╣Др╕Фр╣Йр╣Гр╕Кр╣Й GPU (р╕нр╕▓р╕Ир╕бр╕╡р╕Ыр╕▒р╕Нр╕лр╕▓)

# р╕Бр╕Ф Ctrl+C р╣Ар╕Юр╕╖р╣Ир╕нр╕лр╕вр╕╕р╕Ф
```

### 5.3 р╣Ар╕Кр╣Зр╕Д Running Processes

```bash
# р╣Ар╕Кр╣Зр╕Др╕зр╣Ир╕▓р╣Вр╕бр╣Ар╕Фр╕ер╣Др╕лр╕Щр╕Бр╕│р╕ер╕▒р╕Зр╕гр╕▒р╕Щ
ps aux | grep train_

# Output:
# root  12345  98.5  15.2  python train_xgboost_only.py
# root  12346  85.2  12.1  python train_lightgbm_only.py

# р╣Ар╕Кр╣Зр╕Др╕зр╣Ир╕▓р╕бр╕╡ process р╕Бр╕╡р╣Ир╕Хр╕▒р╕з
ps aux | grep train_ | wc -l
# Output: 2 (р╕Бр╕│р╕ер╕▒р╕Зр╕гр╕▒р╕Щ 2 р╣Вр╕бр╣Ар╕Фр╕ер╕Юр╕гр╣Йр╕нр╕бр╕Бр╕▒р╕Щ)
```

### 5.4 р╣Ар╕Кр╣Зр╕Д Checkpoints

```bash
# р╣Ар╕Кр╣Зр╕Др╕зр╣Ир╕▓р╣Вр╕бр╣Ар╕Фр╕ер╣Др╕лр╕Щр╣Ар╕кр╕гр╣Зр╕Ир╣Бр╕ер╣Йр╕з
ls -lh models/checkpoints/

# Output:
# -rw-r--r-- 1 root root 245M Oct  8 12:34 xgboost_checkpoint.pkl
# -rw-r--r-- 1 root root 312M Oct  8 15:12 lightgbm_checkpoint.pkl
# -rw-r--r-- 1 root root 189M Oct  8 17:45 catboost_checkpoint.pkl
# -rw-r--r-- 1 root root 156M Oct  8 19:01 random_forest_checkpoint.pkl

# р╣Ар╕Кр╣Зр╕Др╕зр╣Ир╕▓р╕бр╕╡р╕Бр╕╡р╣Ир╣Др╕Яр╕ер╣М
ls models/checkpoints/*.pkl | wc -l
# Output: 4 (р╕Др╕гр╕Ър╕Чр╕▒р╣Йр╕З 4 р╣Вр╕бр╣Ар╕Фр╕ер╣Бр╕ер╣Йр╕з)
```

### 5.5 р╣Ар╕Кр╣Зр╕Д Disk Space

```bash
# р╣Ар╕Кр╣Зр╕Др╕Юр╕╖р╣Йр╕Щр╕Чр╕╡р╣Ир╕зр╣Ир╕▓р╕З
df -h /storage

# Output:
# Filesystem      Size  Used Avail Use% Mounted on
# /dev/sda1        50G   5G   45G  10% /storage

# р╕Цр╣Йр╕▓ Use% > 90% тЖТ р╕Юр╕╖р╣Йр╕Щр╕Чр╕╡р╣Ир╣Ар╕лр╕ер╕╖р╕нр╕Щр╣Йр╕нр╕в
```

---

## 6. Troubleshooting

### р╕Ыр╕▒р╕Нр╕лр╕▓ 1: Process р╕лр╕вр╕╕р╕Фр╕Чр╕│р╕Зр╕▓р╕Щ (Killed)

**р╕нр╕▓р╕Бр╕▓р╕г:**
```bash
tail -f logs/xgb.log
# ...
# Trial 050: R┬▓ = 0.8923
# Killed
```

**р╕кр╕▓р╣Ар╕лр╕Хр╕╕:** р╕лр╕бр╕Фр╕лр╕Щр╣Ир╕зр╕вр╕Др╕зр╕▓р╕бр╕Ир╕│ (RAM/GPU)

**р╣Бр╕Бр╣Йр╣Др╕В:**
```bash
# 1. р╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ър╕зр╣Ир╕▓р╕гр╕▒р╕Щр╕Бр╕╡р╣Ир╣Вр╕бр╣Ар╕Фр╕ер╕Юр╕гр╣Йр╕нр╕бр╕Бр╕▒р╕Щ
ps aux | grep train_

# 2. р╕Цр╣Йр╕▓р╕гр╕▒р╕Щр╕лр╕ер╕▓р╕вр╣Вр╕бр╣Ар╕Фр╕ер╕Юр╕гр╣Йр╕нр╕бр╕Бр╕▒р╕Щ тЖТ р╕лр╕вр╕╕р╕Ф 1-2 р╕Хр╕▒р╕з
kill <PID>

# 3. р╕гр╕▒р╕Щр╕Чр╕╡р╕ер╕░р╣Вр╕бр╣Ар╕Фр╕ер╣Бр╕Чр╕Щ (р╣Бр╕Щр╕░р╕Щр╕│!)
```

---

### р╕Ыр╕▒р╕Нр╕лр╕▓ 2: GPU р╣Др╕бр╣Ир╕Чр╕│р╕Зр╕▓р╕Щ (0% usage)

**р╕нр╕▓р╕Бр╕▓р╕г:**
```bash
nvidia-smi
# GPU-Util: 0%
```

**р╕кр╕▓р╣Ар╕лр╕Хр╕╕:** р╣Вр╕бр╣Ар╕Фр╕ер╣Др╕бр╣Ир╣Др╕Фр╣Йр╣Гр╕Кр╣Й GPU

**р╣Бр╕Бр╣Йр╣Др╕В:**
```bash
# 1. р╣Ар╕Кр╣Зр╕Д log р╕зр╣Ир╕▓р╕бр╕╡ warning р╕бр╕▒р╣Йр╕в
grep -i "gpu" logs/xgb.log

# 2. р╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ър╕зр╣Ир╕▓ XGBoost detect GPU р╕бр╕▒р╣Йр╕в
python -c "import xgboost; print(xgboost.__version__)"

# 3. р╕Цр╣Йр╕▓р╕вр╕▒р╕Зр╣Др╕бр╣Ир╣Др╕Фр╣Й тЖТ р╕Хр╕┤р╕Фр╕Хр╕▒р╣Йр╕З xgboost р╣Гр╕лр╕бр╣И
pip install --upgrade xgboost
```

---

### р╕Ыр╕▒р╕Нр╕лр╕▓ 3: р╣Др╕бр╣Ир╕Юр╕Ър╣Др╕Яр╕ер╣М train_xgboost_only.py

**р╕нр╕▓р╕Бр╕▓р╕г:**
```bash
python train_xgboost_only.py
# Error: No such file or directory
```

**р╣Бр╕Бр╣Йр╣Др╕В:**
```bash
# 1. р╣Ар╕Кр╣Зр╕Др╕зр╣Ир╕▓р╕нр╕вр╕╣р╣Ир╣Гр╕Щр╣Вр╕Яр╕ер╣Ар╕Фр╕нр╕гр╣Мр╕Чр╕╡р╣Ир╕Цр╕╣р╕Бр╕Хр╣Йр╕нр╕З
pwd
# Output: /storage/ML-number

# р╕Цр╣Йр╕▓р╣Др╕бр╣Ир╣Гр╕Кр╣И тЖТ cd р╕Бр╕ер╕▒р╕Ъ
cd /storage/ML-number

# 2. р╣Ар╕Кр╣Зр╕Др╕зр╣Ир╕▓р╕бр╕╡р╣Др╕Яр╕ер╣Мр╕бр╕▒р╣Йр╕в
ls train_*.py
# р╕Др╕зр╕гр╣Ар╕лр╣Зр╕Щ:
# train_xgboost_only.py
# train_lightgbm_only.py
# ...

# 3. р╕Цр╣Йр╕▓р╣Др╕бр╣Ир╕бр╕╡ тЖТ git pull р╣Гр╕лр╕бр╣И
git pull origin main
```

---

### р╕Ыр╕▒р╕Нр╕лр╕▓ 4: ModuleNotFoundError

**р╕нр╕▓р╕Бр╕▓р╕г:**
```bash
python train_xgboost_only.py
# ModuleNotFoundError: No module named 'xgboost'
```

**р╣Бр╕Бр╣Йр╣Др╕В:**
```bash
# 1. р╣Ар╕Кр╣Зр╕Др╕зр╣Ир╕▓ activate venv р╣Бр╕ер╣Йр╕зр╕гр╕╢р╕вр╕▒р╕З
which python
# Output: /storage/ML-number/.venv/bin/python тЖР тЬЕ р╕Цр╕╣р╕Бр╕Хр╣Йр╕нр╕З
# Output: /usr/bin/python тЖР тЭМ р╕вр╕▒р╕Зр╣Др╕бр╣И activate

# 2. р╕Цр╣Йр╕▓р╕вр╕▒р╕Зр╣Др╕бр╣И activate тЖТ activate
source .venv/bin/activate

# 3. р╕Цр╣Йр╕▓р╕вр╕▒р╕З error тЖТ р╕Хр╕┤р╕Фр╕Хр╕▒р╣Йр╕Зр╣Гр╕лр╕бр╣И
pip install -r requirements.txt
```

---

### р╕Ыр╕▒р╕Нр╕лр╕▓ 5: Session timeout / Browser р╕Ыр╕┤р╕Ф

**р╕нр╕▓р╕Бр╕▓р╕г:** р╕Ыр╕┤р╕Ф browser тЖТ р╕Бр╕ер╕▒р╕Ър╕бр╕▓р╣Гр╕лр╕бр╣И тЖТ р╣Др╕бр╣Ир╕гр╕╣р╣Йр╕зр╣Ир╕▓р╣Ар╕Чр╕гр╕Щр╣Др╕Ыр╕Цр╕╢р╕Зр╣Др╕лр╕Щ

**р╣Бр╕Бр╣Йр╣Др╕В:**
```bash
# 1. р╣Ар╕Кр╣Зр╕Д process р╕Чр╕╡р╣Ир╕вр╕▒р╕Зр╕гр╕▒р╕Щр╕нр╕вр╕╣р╣И
ps aux | grep train_

# 2. р╣Ар╕Кр╣Зр╕Д log р╕ер╣Ир╕▓р╕кр╕╕р╕Ф
tail -50 logs/xgb.log

# 3. р╣Ар╕Кр╣Зр╕Д checkpoint
ls -lh models/checkpoints/

# тЬЕ р╕Цр╣Йр╕▓р╣Гр╕Кр╣Й nohup тЖТ р╣Вр╕бр╣Ар╕Фр╕ер╕вр╕▒р╕Зр╕гр╕▒р╕Щр╕Хр╣Ир╕нр╣Бр╕бр╣Йр╕Ыр╕┤р╕Ф browser!
```

---

### р╕Ыр╕▒р╕Нр╕лр╕▓ 6: Training р╕Кр╣Йр╕▓р╕бр╕▓р╕Б

**р╕нр╕▓р╕Бр╕▓р╕г:** XGBoost р╣Гр╕Кр╣Йр╣Ар╕зр╕ер╕▓ >5 р╕Кр╕б. (р╕Ыр╕Бр╕Хр╕┤ 2-3 р╕Кр╕б.)

**р╕кр╕▓р╣Ар╕лр╕Хр╕╕:**
1. р╣Гр╕Кр╣Й Free Plan (M4000) тЖТ р╕Кр╣Йр╕▓р╕Бр╕зр╣Ир╕▓ Growth Plan (A4000)
2. GPU р╣Др╕бр╣Ир╕Чр╕│р╕Зр╕▓р╕Щ (р╣Гр╕Кр╣Й CPU р╣Бр╕Чр╕Щ)

**р╣Бр╕Бр╣Йр╣Др╕В:**
```bash
# 1. р╣Ар╕Кр╣Зр╕Д GPU usage
nvidia-smi
# р╕Цр╣Йр╕▓ GPU-Util < 10% тЖТ р╣Др╕бр╣Ир╣Др╕Фр╣Йр╣Гр╕Кр╣Й GPU

# 2. р╣Ар╕Кр╣Зр╕Д log
grep -i "device" logs/xgb.log
# р╕Др╕зр╕гр╣Ар╕лр╣Зр╕Щ: Device: cuda
# р╕Цр╣Йр╕▓р╣Ар╕лр╣Зр╕Щ: Device: cpu тЖТ р╕бр╕╡р╕Ыр╕▒р╕Нр╕лр╕▓

# 3. р╕Цр╣Йр╕▓р╕Кр╣Йр╕▓р╣Бр╕Хр╣Ир╣Гр╕Кр╣Й GPU р╣Бр╕ер╣Йр╕з тЖТ р╕Ыр╕Бр╕Хр╕┤ (M4000 р╕Кр╣Йр╕▓)
# р╕лр╕гр╕╖р╕н тЖТ р╕нр╕▒р╕Юр╣Ар╕Бр╕гр╕Фр╣Ар╕Ыр╣Зр╕Щ Growth Plan (A4000)
```

---

## 7. Expected Results

### р╣Ар╕зр╕ер╕▓р╣Ар╕Чр╕гр╕Щр╣Бр╕Хр╣Ир╕ер╕░р╣Вр╕бр╣Ар╕Фр╕е:

| GPU | XGBoost | LightGBM | CatBoost | RandomForest | Ensemble | Total |
|-----|---------|----------|----------|--------------|----------|-------|
| **M4000** (Free) | 3-4 р╕Кр╕б. | 4-5 р╕Кр╕б. | 2-3 р╕Кр╕б. | 1.5 р╕Кр╕б. | 30 р╕Щр╕▓р╕Чр╕╡ | **11-14 р╕Кр╕б.** |
| **A4000** (Growth) | 2-3 р╕Кр╕б. | 3-4 р╕Кр╕б. | 1-2 р╕Кр╕б. | 1 р╕Кр╕б. | 15 р╕Щр╕▓р╕Чр╕╡ | **8-11 р╕Кр╕б.** |

### R┬▓ Scores:

| Model | Expected R┬▓ |
|-------|-------------|
| XGBoost | 0.88-0.92 |
| LightGBM | 0.86-0.90 |
| CatBoost | 0.85-0.89 |
| RandomForest | 0.82-0.86 |
| **Ensemble** | **0.90-0.93** тЬЕ |

---

## 8. Quick Commands Reference

```bash
# === SETUP ===
cd /storage
git clone https://github.com/Useforclaude/ML-number.git
cd ML-number
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
mkdir -p logs

# === TRAINING ===
nohup python train_xgboost_only.py > logs/xgb.log 2>&1 &
nohup python train_lightgbm_only.py > logs/lgb.log 2>&1 &
nohup python train_catboost_only.py > logs/cat.log 2>&1 &
nohup python train_rf_only.py > logs/rf.log 2>&1 &
python train_ensemble_only.py

# === MONITORING ===
tail -f logs/xgb.log              # Monitor log
watch -n 2 nvidia-smi             # Monitor GPU
ps aux | grep train_              # Check processes
ls -lh models/checkpoints/        # Check checkpoints

# === TROUBLESHOOTING ===
kill <PID>                        # Stop process
grep -i error logs/xgb.log        # Find errors
df -h /storage                    # Check disk space
```

---

## 9. After Training

### 9.1 р╕Фр╕▓р╕зр╕Щр╣Мр╣Вр╕лр╕ер╕Ф Best Model

```bash
# р╣Ар╕Кр╣Зр╕Др╕зр╣Ир╕▓р╕бр╕╡ best model
ls -lh models/deployed/best_model.pkl

# р╕Фр╕▓р╕зр╕Щр╣Мр╣Вр╕лр╕ер╕Фр╕Ьр╣Ир╕▓р╕Щ Jupyter File Browser:
# 1. р╣Др╕Ыр╕Чр╕╡р╣И File Browser (р╕Фр╣Йр╕▓р╕Щр╕Лр╣Йр╕▓р╕в)
# 2. Navigate: /storage/ML-number/models/deployed/
# 3. р╕Др╕ер╕┤р╕Бр╕Вр╕зр╕▓ best_model.pkl тЖТ Download
```

### 9.2 р╕Чр╕Фр╕кр╕нр╕Ъ Model

```python
# р╣Гр╕Щ Python shell р╕лр╕гр╕╖р╕н Jupyter notebook
import joblib

# Load model
model_pkg = joblib.load('models/deployed/best_model.pkl')

print(f"Model: {model_pkg['model_name']}")
print(f"R┬▓ Score: {model_pkg['metrics']['test_r2']:.4f}")
print(f"MAE: {model_pkg['metrics']['test_mae']:.2f}")

# Test prediction
phone = "0899999999"
# ... (р╕Хр╣Йр╕нр╕Зр╣Ар╕Хр╕гр╕╡р╕вр╕б features р╣Ар╕лр╕бр╕╖р╕нр╕Щр╕Хр╕нр╕Щ training)
```

---

## 10. Summary Checklist

**р╕Бр╣Ир╕нр╕Щр╣Ар╕гр╕┤р╣Ир╕б:**
- [ ] р╕кр╕бр╕▒р╕Др╕г Paperspace account
- [ ] р╕кр╕гр╣Йр╕▓р╕З Notebook (Free GPU р╕лр╕гр╕╖р╕н Growth)
- [ ] р╣Ар╕Ыр╕┤р╕Ф Terminal

**Setup:**
- [ ] Clone repository
- [ ] р╕кр╕гр╣Йр╕▓р╕З venv + activate
- [ ] р╕Хр╕┤р╕Фр╕Хр╕▒р╣Йр╕З requirements
- [ ] р╣Ар╕Кр╣Зр╕Д GPU (nvidia-smi)
- [ ] р╕кр╕гр╣Йр╕▓р╕Зр╣Вр╕Яр╕ер╣Ар╕Фр╕нр╕гр╣М logs

**Training:**
- [ ] р╕гр╕▒р╕Щ XGBoost (2-4 р╕Кр╕б.)
- [ ] р╕гр╕▒р╕Щ LightGBM (3-5 р╕Кр╕б.)
- [ ] р╕гр╕▒р╕Щ CatBoost (1-3 р╕Кр╕б.)
- [ ] р╕гр╕▒р╕Щ RandomForest (1-2 р╕Кр╕б.)
- [ ] р╕гр╕▒р╕Щ Ensemble (15-30 р╕Щр╕▓р╕Чр╕╡)

**Verification:**
- [ ] р╣Ар╕Кр╣Зр╕Д logs р╣Др╕бр╣Ир╕бр╕╡ error
- [ ] р╣Ар╕Кр╣Зр╕Д checkpoints р╕Др╕гр╕Ъ 4 р╣Др╕Яр╕ер╣М
- [ ] р╣Ар╕Кр╣Зр╕Д best_model.pkl р╣Гр╕Щ deployed/
- [ ] R┬▓ > 0.90 тЬЕ

**тЬЕ р╣Ар╕кр╕гр╣Зр╕Ир╕кр╕бр╕Ър╕╣р╕гр╕Ур╣М!**

---

**Created:** 2025-10-08
**Session:** 012 - Paperspace Modular Training Guide
**Total Time:** 8-14 hours (р╕Вр╕╢р╣Йр╕Щр╕Бр╕▒р╕Ъ GPU)
**Expected R┬▓:** 0.90-0.93 тЬЕ
