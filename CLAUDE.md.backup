# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

---

# ğŸ”„ SESSION CONTINUITY PROTOCOL

> **Zero Context Loss Between Sessions** - Claude à¸ˆà¸³à¹„à¸”à¹‰à¸—à¸¸à¸à¸­à¸¢à¹ˆà¸²à¸‡ à¹à¸¡à¹‰à¸›à¸´à¸” session à¸«à¸£à¸·à¸­à¹„à¸Ÿà¸Ÿà¹‰à¸²à¸”à¸±à¸š

## ğŸ“š Table of Contents

1. [Mandatory Startup Files](#-mandatory-read-these-files-every-session-no-exceptions)
2. [Never Skip Rules](#-never-skip-rules)
3. [File Organization Rules](#-file-organization-rules-mandatory)
4. [Context Recognition Table](#-context-recognition-table)
5. [Auto-Update Checkpoint Rules](#-auto-update-checkpoint-rules)
6. [Session Integrity Checklist](#-session-integrity-checklist)
7. [Quick Recovery Commands](#-quick-recovery-commands)
8. [Session Connection Chain](#-session-connection-chain)
9. [Context Recovery Examples](#-context-recovery-examples)
10. [Success Criteria](#-success-criteria)
11. [30-Second Startup Protocol](#ï¸-30-second-session-startup-protocol)
12. [User Intent Recognition](#-user-intent-recognition)
13. [Checkpoint Validation](#-checkpoint-validation-rules)
14. [Auto-Checkpoint Implementation](#-auto-checkpoint-implementation)
15. [Progress Tracking](#-progress-tracking-formula)
16. [Error Recovery Protocol](#-error-recovery-protocol)
17. [Session Quality Metrics](#-session-quality-metrics)
18. [Pre-Flight Checklist](#-pre-flight-checklist-copy-paste-ready)
19. [Learning from Past Sessions](#-learning-from-past-sessions)
20. [Final Validation](#-final-validation-before-session-end)

---

## ğŸ¯ à¸—à¸³à¹„à¸¡à¸•à¹‰à¸­à¸‡à¸¡à¸µ Protocol à¸™à¸µà¹‰?

### à¸›à¸±à¸à¸«à¸²à¸—à¸µà¹ˆà¹à¸à¹‰à¹„à¸‚:
âŒ Claude à¸¥à¸·à¸¡à¸§à¹ˆà¸²à¸—à¸³à¸­à¸°à¹„à¸£à¹„à¸› session à¸—à¸µà¹ˆà¹à¸¥à¹‰à¸§
âŒ User à¸•à¹‰à¸­à¸‡à¸­à¸˜à¸´à¸šà¸²à¸¢à¹ƒà¸«à¸¡à¹ˆà¸—à¸¸à¸à¸„à¸£à¸±à¹‰à¸‡
âŒ à¹€à¸ªà¸µà¸¢à¹€à¸§à¸¥à¸²à¸«à¸² context à¸‹à¹‰à¸³à¹†
âŒ à¸‡à¸²à¸™à¸‚à¸²à¸”à¸•à¹ˆà¸­à¹€à¸¡à¸·à¹ˆà¸­à¸›à¸´à¸” session
âŒ à¹„à¸Ÿà¸Ÿà¹‰à¸²à¸”à¸±à¸š = à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¹ƒà¸«à¸¡à¹ˆà¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”

### à¸§à¸´à¸˜à¸µà¹à¸à¹‰:
âœ… **Auto-Resume**: à¸à¸´à¸¡à¸à¹Œ "à¸—à¸³à¸•à¹ˆà¸­" â†’ Claude à¸—à¸³à¸•à¹ˆà¸­à¸—à¸±à¸™à¸—à¸µ
âœ… **30-Second Recovery**: à¹„à¸”à¹‰ context à¸à¸¥à¸±à¸šà¸¡à¸²à¸ à¸²à¸¢à¹ƒà¸™ 30 à¸§à¸´à¸™à¸²à¸—à¸µ
âœ… **Zero Information Loss**: à¹„à¸¡à¹ˆà¸ªà¸¹à¸à¹€à¸ªà¸µà¸¢ context à¹€à¸¥à¸¢
âœ… **Auto-Save**: à¸šà¸±à¸™à¸—à¸¶à¸à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´à¸—à¸¸à¸ 30 à¸™à¸²à¸—à¸µ
âœ… **Session Chain**: à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸—à¸¸à¸ session à¹€à¸‚à¹‰à¸²à¸”à¹‰à¸§à¸¢à¸à¸±à¸™

---

## âš ï¸ MANDATORY: Read These Files EVERY Session (NO EXCEPTIONS!)

**BEFORE doing ANYTHING else, you MUST read these files in this exact order:**

### Priority 1 - CRITICAL (Read First, Always!)
1. **`.project_state.json`** - Current project state, progress tracking
2. **`checkpoints/checkpoint_latest.json`** - Last checkpoint with exact task state
3. **`NEXT_SESSION.md`** - Instructions for what to do next

### Priority 2 - IMPORTANT (Read if exists)
4. **`SESSION_SUMMARY.md`** - Summary of last session
5. **`FINAL_SUMMARY.md`** - Final summary of completed work

### Priority 3 - CONTEXT (Read on demand)
6. **`SESSION_COMPLETION_REPORT.md`** - Completion report
7. **`COLAB_SETUP.md` / `KAGGLE_SETUP.md`** - Platform-specific guides

---

## ğŸš« NEVER SKIP RULES

```plaintext
âŒ NEVER start work without reading .project_state.json
âŒ NEVER assume you know what to do next
âŒ NEVER ignore checkpoint files
âŒ NEVER skip updating checkpoints before ending session
âŒ NEVER forget to update NEXT_SESSION.md

âœ… ALWAYS read state files first (30 seconds investment)
âœ… ALWAYS update checkpoints every 30 minutes
âœ… ALWAYS update NEXT_SESSION.md before ending
âœ… ALWAYS preserve session_id chain
âœ… ALWAYS ask "What did I do last session?" before starting
```

---

## ğŸ“ FILE ORGANIZATION RULES (MANDATORY!)

**âš ï¸ CRITICAL: Project was refactored on 2025-10-08. Keep it clean!**

### File Placement Rules

```plaintext
âŒ NEVER create files in root directory (except listed below)
âŒ NEVER create documentation files (.md) in root
âŒ NEVER create training scripts in root
âŒ NEVER create setup scripts in root
âŒ NEVER move files without updating import paths

âœ… ALWAYS follow this structure:
```

### Directory Structure (MUST FOLLOW!)

```
number-ML/
â”œâ”€â”€ ROOT ONLY (6 files allowed):
â”‚   â”œâ”€â”€ README.md              â† Main project documentation
â”‚   â”œâ”€â”€ CLAUDE.md              â† This file (AI instructions)
â”‚   â”œâ”€â”€ NEXT_SESSION.md        â† Next session guide
â”‚   â”œâ”€â”€ QUICK_START.md         â† Quick start guide
â”‚   â”œâ”€â”€ requirements.txt       â† Dependencies
â”‚   â””â”€â”€ .project_state.json    â† Project state tracking
â”‚
â”œâ”€â”€ training/                  â† ALL training scripts go here
â”‚   â”œâ”€â”€ main.py               â† Full training pipeline
â”‚   â”œâ”€â”€ train_terminal.py     â† Terminal training script
â”‚   â””â”€â”€ modular/              â† Individual model training
â”‚       â”œâ”€â”€ train_xgboost_only.py
â”‚       â”œâ”€â”€ train_lightgbm_only.py
â”‚       â”œâ”€â”€ train_catboost_only.py
â”‚       â”œâ”€â”€ train_rf_only.py
â”‚       â””â”€â”€ train_ensemble_only.py
â”‚
â”œâ”€â”€ setup/                     â† ALL setup scripts go here
â”‚   â”œâ”€â”€ setup_local.py
â”‚   â”œâ”€â”€ setup_colab_complete.py
â”‚   â”œâ”€â”€ setup_paperspace.py
â”‚   â””â”€â”€ validate_paperspace.py
â”‚
â”œâ”€â”€ docs/                      â† ALL documentation files go here
â”‚   â”œâ”€â”€ README.md             â† Documentation index
â”‚   â”œâ”€â”€ guides/               â† Platform guides
â”‚   â”‚   â”œâ”€â”€ kaggle/          â† Kaggle-specific guides
â”‚   â”‚   â”œâ”€â”€ paperspace/      â† Paperspace guides
â”‚   â”‚   â”œâ”€â”€ colab/           â† Colab guides
â”‚   â”‚   â””â”€â”€ comparisons/     â† Platform comparisons
â”‚   â”œâ”€â”€ sessions/             â† Session summaries
â”‚   â”œâ”€â”€ fixes/                â† Fix documentation
â”‚   â”œâ”€â”€ protocols/            â† Protocols & workflows
â”‚   â””â”€â”€ implementation/       â† Implementation guides
â”‚
â”œâ”€â”€ scripts/                   â† Utility scripts
â”‚   â”œâ”€â”€ create_kaggle_package.py
â”‚   â”œâ”€â”€ paperspace_quickstart.py
â”‚   â”œâ”€â”€ quick_test.py
â”‚   â””â”€â”€ run_with_autosave.py
â”‚
â”œâ”€â”€ packages/                  â† Distribution packages
â”‚   â”œâ”€â”€ kaggle/
â”‚   â”‚   â””â”€â”€ notebooks/
â”‚   â”œâ”€â”€ paperspace/
â”‚   â””â”€â”€ colab/
â”‚
â”œâ”€â”€ src/                       â† Core source code (DON'T MOVE!)
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ environment.py
â”‚   â”œâ”€â”€ data_handler.py
â”‚   â”œâ”€â”€ features.py
â”‚   â”œâ”€â”€ model_utils.py
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ notebooks/                 â† Jupyter notebooks
â”œâ”€â”€ api/                       â† API code
â”œâ”€â”€ tests/                     â† Test files
â”œâ”€â”€ utils/                     â† Helper utilities
â”œâ”€â”€ data/                      â† Data files
â”œâ”€â”€ models/                    â† Saved models
â”œâ”€â”€ results/                   â† Results & visualizations
â”œâ”€â”€ logs/                      â† Log files
â””â”€â”€ checkpoints/               â† Session checkpoints
```

### File Creation Rules

**When creating NEW files:**

| File Type | Correct Location | Example |
|-----------|------------------|---------|
| Training script | `training/` or `training/modular/` | `training/modular/train_model.py` |
| Setup script | `setup/` | `setup/setup_platform.py` |
| Documentation | `docs/guides/{platform}/` | `docs/guides/kaggle/GUIDE.md` |
| Session summary | `docs/sessions/` | `docs/sessions/SESSION_013.md` |
| Fix documentation | `docs/fixes/` | `docs/fixes/FIX_ISSUE.md` |
| Utility script | `scripts/` | `scripts/helper_script.py` |
| Package | `packages/{platform}/` | `packages/kaggle/notebook.ipynb` |
| Test file | `tests/` | `tests/test_feature.py` |
| API endpoint | `api/` | `api/new_endpoint.py` |

**When modifying import paths:**

```python
# âœ… CORRECT - For files in training/modular/
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# âœ… CORRECT - For files in training/
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# âœ… CORRECT - For files in setup/
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
```

### Verification Before Commit

**ALWAYS verify file locations before git commit:**

```bash
# Check no unwanted files in root
ls -1 *.py *.md | wc -l
# Expected: Should be 0 (except allowed files)

# Verify training scripts are in training/
ls training/*.py training/modular/*.py
# Expected: All training scripts listed

# Verify docs are in docs/
ls docs/guides/*/*.md | wc -l
# Expected: 50+ documentation files

# Verify setup scripts are in setup/
ls setup/*.py
# Expected: All setup scripts listed
```

### Common Mistakes to AVOID

```plaintext
âŒ BAD: Creating train_new_model.py in root
âœ… GOOD: Creating training/modular/train_new_model.py

âŒ BAD: Creating PLATFORM_GUIDE.md in root
âœ… GOOD: Creating docs/guides/platform/PLATFORM_GUIDE.md

âŒ BAD: Creating setup_env.py in root
âœ… GOOD: Creating setup/setup_env.py

âŒ BAD: Moving files without updating imports
âœ… GOOD: Update all import paths after moving files

âŒ BAD: Creating SESSION_014.md in root
âœ… GOOD: Creating docs/sessions/SESSION_014.md
```

### Benefits of This Structure

1. **Clean Root** - Easy to see essential files
2. **Easy Navigation** - Know where everything is
3. **Scalable** - Easy to add new files
4. **Professional** - Industry-standard organization
5. **Maintainable** - Clear separation of concerns

**Remember**: This structure was carefully designed. Don't break it!

---

## ğŸ“‹ Context Recognition Table

When user says this â†’ You MUST do this:

| User Input | Required Actions |
|------------|------------------|
| **"à¸—à¸³à¸•à¹ˆà¸­"** / **"Continue"** / **"Resume"** | 1. Read `.project_state.json`<br>2. Read `checkpoints/checkpoint_latest.json`<br>3. Read `NEXT_SESSION.md`<br>4. Continue from last task |
| **"à¹€à¸£à¸´à¹ˆà¸¡à¹ƒà¸«à¸¡à¹ˆ"** / **"Start fresh"** | 1. Read `.project_state.json`<br>2. Ask user to confirm reset<br>3. Create new session_id<br>4. Reset checkpoints |
| **"à¸ªà¸–à¸²à¸™à¸°"** / **"Status"** | 1. Read `.project_state.json`<br>2. Show progress percentage<br>3. List completed/pending tasks |
| **"à¸­à¸±à¸›à¹€à¸”à¸• checkpoint"** / **"Save progress"** | 1. Update `checkpoints/checkpoint_latest.json`<br>2. Update `.project_state.json`<br>3. Update `NEXT_SESSION.md` |
| **"à¸—à¸³à¸­à¸°à¹„à¸£à¸­à¸¢à¸¹à¹ˆ"** / **"What was I doing?"** | 1. Read `checkpoints/checkpoint_latest.json`<br>2. Show last 3 tasks completed<br>3. Show next task to do |

---

## ğŸ”„ Auto-Update Checkpoint Rules

**MANDATORY AUTO-SAVE TRIGGERS:**

1. **Every 30 minutes of work** - Auto-update checkpoint
2. **Before ending session** - MUST update all state files
3. **After completing major task** - Update immediately
4. **When user explicitly asks** - Update on demand
5. **Before any destructive operation** - Backup current state

**What to save in checkpoint:**
```json
{
  "timestamp": "2025-10-03T14:30:00Z",
  "session_id": "session_002",
  "parent_session": "session_001",
  "current_task": "Training XGBoost model",
  "last_completed_task": "Feature engineering completed",
  "next_task": "Train LightGBM model",
  "progress_percentage": 65,
  "files_modified": ["src/train.py", "models/xgboost_model.pkl"],
  "custom_notes": "XGBoost achieved RÂ² = 0.92, continuing with ensemble"
}
```

---

## âœ… Session Integrity Checklist

**Run this checklist at START of EVERY session:**

- [ ] Read `.project_state.json` âœ“
- [ ] Read `checkpoints/checkpoint_latest.json` âœ“
- [ ] Read `NEXT_SESSION.md` âœ“
- [ ] Understand what was done last session âœ“
- [ ] Know exactly what to do next âœ“
- [ ] Verify virtual environment is active âœ“

**Run this checklist at END of EVERY session:**

- [ ] Update `checkpoints/checkpoint_latest.json` with timestamp âœ“
- [ ] Update `.project_state.json` with new progress âœ“
- [ ] Update `NEXT_SESSION.md` with clear next steps âœ“
- [ ] Save all modified files âœ“
- [ ] Document any errors or blockers âœ“

---

## ğŸ¯ Quick Recovery Commands

**User Quick Commands** (recognize these patterns):

| Command | Action |
|---------|--------|
| `/resume` | Read checkpoints + continue last task |
| `/status` | Show current progress + next steps |
| `/last-task` | Show last completed task |
| `/save` | Update all checkpoint files now |
| `/what-next` | Read NEXT_SESSION.md + show plan |
| `/reset` | Start fresh session (ask confirmation first) |

---

## ğŸ”— Session Connection Chain

**Every session MUST have these identifiers:**

```python
session_info = {
    "session_id": "session_XXX",           # Current session (increment)
    "parent_session": "session_XXX-1",     # Previous session
    "session_start": "2025-10-03T14:00:00Z",
    "session_purpose": "Complete model training",
    "continuation_from": "checkpoint_20251003_131638.json"
}
```

**Session Linking Rules:**
- Session IDs must be sequential (`session_001`, `session_002`, etc.)
- Always reference parent_session for traceability
- Save session chain in `.project_state.json`

---

## ğŸ“ Context Recovery Examples

### Example 1: User returns after 3 days

**User**: "à¸—à¸³à¸•à¹ˆà¸­"

**Claude MUST do:**
```python
1. Read .project_state.json
   â†’ See progress is at 75%, session_001 was 3 days ago

2. Read checkpoints/checkpoint_latest.json
   â†’ Last task: "All tests passing, ready for Colab deployment"

3. Read NEXT_SESSION.md
   â†’ Next step: "Deploy to Colab and run full training"

4. Response:
   "I see from checkpoint_latest.json that the last session (session_001, 3 days ago)
    completed all tests successfully. The project is at 75% completion.

    Next task: Deploy to Google Colab and run full training pipeline.

    Should I proceed with Colab deployment?"
```

### Example 2: Electricity cut during training

**User**: "à¹„à¸Ÿà¸”à¸±à¸š à¸—à¸³à¸•à¹ˆà¸­à¸ˆà¸²à¸à¸—à¸µà¹ˆà¸„à¹‰à¸²à¸‡"

**Claude MUST do:**
```python
1. Read checkpoints/checkpoint_latest.json
   â†’ Last save: "Training XGBoost - Trial 87/150"

2. Check if model checkpoint exists
   â†’ Look for models/experiments/xgboost_partial.pkl

3. Response:
   "I found the last checkpoint from 15 minutes ago. You were training XGBoost,
    completed 87 out of 150 Optuna trials (58% of hyperparameter optimization).

    Options:
    1. Resume from trial 87 (if intermediate checkpoint exists)
    2. Restart XGBoost training from scratch

    Which would you prefer?"
```

### Example 3: Starting new session

**User**: "à¸ªà¸–à¸²à¸™à¸°"

**Claude MUST do:**
```python
1. Read .project_state.json
   â†’ Progress: 75%, session_001 completed

2. Read checkpoints/checkpoint_latest.json
   â†’ 15 files modified, all imports fixed, tests passing

3. Response:
   "ğŸ“Š Project Status:

    âœ… Completed (75%):
    - Environment setup
    - Dynamic configuration
    - Multi-format data loader
    - Batch prediction scripts
    - All imports fixed
    - All tests passing

    ğŸ“‹ Pending (25%):
    - Colab deployment
    - Kaggle deployment
    - Full training with optimization
    - Final model deployment

    ğŸ¯ Next Task: Deploy to Colab and run full training

    Ready to continue?"
```

---

## ğŸ¯ Success Criteria

**Session is properly resumed if:**

âœ… Claude knows exactly what was done last session
âœ… Claude knows exactly what to do next
âœ… Claude preserves all context (files modified, progress, etc.)
âœ… Claude asks relevant questions based on last checkpoint
âœ… User doesn't need to re-explain anything

**Session has FAILED if:**

âŒ Claude asks "What do you want me to do?" without reading state
âŒ Claude starts from scratch ignoring previous work
âŒ Claude doesn't know what happened last session
âŒ User has to remind Claude of context

---

## â±ï¸ 30-Second Session Startup Protocol

**MANDATORY for EVERY session start:**

```bash
# 1. Read state (10 sec)
cat .project_state.json
cat checkpoints/checkpoint_latest.json

# 2. Read next steps (10 sec)
cat NEXT_SESSION.md

# 3. Verify environment (10 sec)
pwd                          # Check we're in correct directory
source .venv/bin/activate    # Activate virtual environment
python -c "from src.config import BASE_PATH; print(BASE_PATH)"  # Verify imports
```

**Total time: 30 seconds**
**Result: Full context recovery**

---

## ğŸ§  User Intent Recognition

**Recognize these patterns and respond appropriately:**

### Pattern 1: Continuation Intent
**User says**: "à¸—à¸³à¸•à¹ˆà¸­", "Continue", "Resume", "Next", "à¸•à¹ˆà¸­à¹€à¸™à¸·à¹ˆà¸­à¸‡"
**Action**: Read checkpoints â†’ Continue last task â†’ No questions asked

### Pattern 2: Status Check Intent
**User says**: "à¸ªà¸–à¸²à¸™à¸°", "Status", "Where are we?", "Progress", "à¸—à¸³à¹„à¸›à¸–à¸¶à¸‡à¹„à¸«à¸™"
**Action**: Read state â†’ Show progress â†’ Ask if want to continue

### Pattern 3: Confusion/Lost Intent
**User says**: "à¹€à¸£à¸²à¸à¸³à¸¥à¸±à¸‡à¸—à¸³à¸­à¸°à¹„à¸£", "What am I doing?", "Lost track", "Forgot"
**Action**: Read checkpoints â†’ Explain last 3 tasks â†’ Show next task â†’ Ask if need recap

### Pattern 4: Save Intent
**User says**: "à¸šà¸±à¸™à¸—à¸¶à¸", "Save", "Checkpoint", "à¸­à¸±à¸›à¹€à¸”à¸•"
**Action**: Update all state files â†’ Confirm saved â†’ Show what was saved

### Pattern 5: Fresh Start Intent
**User says**: "à¹€à¸£à¸´à¹ˆà¸¡à¹ƒà¸«à¸¡à¹ˆ", "Start over", "Reset", "Clean slate"
**Action**: Read current state â†’ Show progress â†’ **ASK CONFIRMATION** â†’ Then reset

### Pattern 6: Emergency Recovery Intent
**User says**: "à¹„à¸Ÿà¸”à¸±à¸š", "Crashed", "Lost session", "Error happened"
**Action**: Read last checkpoint â†’ Check timestamp â†’ Offer recovery options

---

## ğŸ“Œ Checkpoint Validation Rules

**Before accepting a checkpoint as valid, verify:**

1. **Timestamp Check**:
   - âœ… Checkpoint < 24 hours old = Highly reliable
   - âš ï¸ Checkpoint 1-7 days old = Reliable but ask for confirmation
   - âŒ Checkpoint > 7 days old = Ask user to verify state

2. **Completeness Check**:
   ```python
   required_fields = [
       "timestamp",
       "session_id",
       "current_task",
       "progress_percentage",
       "next_task"
   ]
   ```

3. **Consistency Check**:
   - Does `.project_state.json` match `checkpoint_latest.json`?
   - Do file timestamps match checkpoint timestamp?
   - Is progress_percentage logical?

4. **File Existence Check**:
   - Do files mentioned in checkpoint actually exist?
   - Are modified files actually modified?

---

## ğŸ”„ Auto-Checkpoint Implementation

**Claude must auto-save checkpoint at these exact moments:**

### Trigger 1: Every 30 Minutes
```python
if time_since_last_checkpoint > 30 * 60:  # 30 minutes in seconds
    save_checkpoint({
        "trigger": "time_based",
        "interval": "30_minutes"
    })
```

### Trigger 2: Major Task Completion
```python
major_tasks = [
    "Model training completed",
    "Feature engineering done",
    "All tests passed",
    "Deployment successful"
]

if current_task in major_tasks:
    save_checkpoint({
        "trigger": "task_completion",
        "task": current_task
    })
```

### Trigger 3: Before Session End
```python
# When detecting session is ending (user says "bye", "done", etc.)
if session_ending_detected:
    save_checkpoint({
        "trigger": "session_end",
        "reason": "User ending session"
    })
```

### Trigger 4: Before Risky Operations
```python
risky_operations = [
    "Deleting files",
    "Major refactoring",
    "Destructive git operations",
    "Model overwriting"
]

if operation in risky_operations:
    save_checkpoint({
        "trigger": "safety_backup",
        "operation": operation
    })
```

---

## ğŸ“Š Progress Tracking Formula

**Calculate progress percentage accurately:**

```python
def calculate_progress():
    total_tasks = len(completed_tasks) + len(pending_tasks)
    progress = (len(completed_tasks) / total_tasks) * 100

    # Weighted progress (optional, more accurate)
    weighted_progress = sum([
        environment_setup.progress * 0.15,
        data_loading.progress * 0.10,
        feature_engineering.progress * 0.20,
        model_training.progress * 0.30,
        evaluation.progress * 0.10,
        deployment.progress * 0.15
    ])

    return {
        "simple_progress": round(progress, 1),
        "weighted_progress": round(weighted_progress, 1),
        "stage": get_current_stage(progress)
    }
```

**Progress Stages:**
- 0-20%: Setup & Configuration
- 21-40%: Data Preparation
- 41-70%: Model Training
- 71-90%: Evaluation & Optimization
- 91-100%: Deployment & Documentation

---

## ğŸš¨ Error Recovery Protocol

**When things go wrong, follow this protocol:**

### Step 1: Identify Error Type
- **Import Error** â†’ Check venv activation
- **File Not Found** â†’ Check BASE_PATH in config
- **Model Error** â†’ Check if model file exists
- **Memory Error** â†’ Reduce batch size or features

### Step 2: Check Last Known Good State
```python
1. Read checkpoints/checkpoint_latest.json
2. Identify last successful task
3. Check if files from that checkpoint still exist
4. Verify data integrity
```

### Step 3: Offer Recovery Options
```
Option 1: Resume from last checkpoint (safest)
Option 2: Retry failed task only
Option 3: Skip and continue (if non-critical)
Option 4: Rollback to earlier checkpoint
```

### Step 4: Document Error
```python
error_log = {
    "timestamp": "2025-10-03T15:30:00Z",
    "error_type": "ImportError",
    "error_message": "Cannot import name 'CONFIG' from 'src.config'",
    "attempted_fix": "Activated venv + verified imports",
    "resolution": "Fixed by using absolute imports",
    "prevention": "Always use 'from src.xxx import' pattern"
}
```

---

## ğŸ¯ Session Quality Metrics

**Every session should achieve these metrics:**

### Quality Indicators (GREEN = Good)
- âœ… Context recovery time < 60 seconds
- âœ… Zero information loss between sessions
- âœ… User asks < 2 clarifying questions
- âœ… All checkpoints have timestamps
- âœ… Progress moves forward (not backward)

### Warning Signs (YELLOW = Needs Attention)
- âš ï¸ User asks "What were we doing?"
- âš ï¸ Checkpoint > 24 hours old
- âš ï¸ Progress percentage doesn't change
- âš ï¸ Multiple files modified without checkpoint

### Failure Indicators (RED = Critical Issue)
- âŒ User has to explain context from scratch
- âŒ Lost track of completed tasks
- âŒ No checkpoint exists
- âŒ Session starts without reading state files

---

## ğŸ“ Pre-Flight Checklist (Copy-Paste Ready)

**Run this EVERY session start (takes 30 seconds):**

```bash
# === SESSION START CHECKLIST ===

# 1. Verify location
pwd
# Expected: /home/u-and-an/projects/number-ML (or your project path)

# 2. Activate virtual environment
source .venv/bin/activate
# Expected: (.venv) appears in prompt

# 3. Read project state
cat .project_state.json | head -30
# Expected: See version, progress, last_updated

# 4. Read latest checkpoint
cat checkpoints/checkpoint_latest.json | head -40
# Expected: See timestamp, current_task, next_task

# 5. Read next session guide
cat NEXT_SESSION.md | head -50
# Expected: See clear instructions for what to do next

# 6. Verify imports work
python -c "from src.config import BASE_PATH; print(f'âœ… BASE_PATH: {BASE_PATH}')"
# Expected: âœ… BASE_PATH: /your/project/path

# 7. Check files exist
ls -lh checkpoints/*.json | tail -5
# Expected: See recent checkpoint files

# === CHECKLIST COMPLETE ===
# Total time: ~30 seconds
# Status: Ready to work! ğŸš€
```

---

## ğŸ“ Learning from Past Sessions

**Session Memory Protocol:**

### What to Remember
1. **Technical Decisions**: Why we chose XGBoost over RandomForest
2. **Failed Attempts**: What didn't work and why
3. **Optimization Results**: Which hyperparameters worked best
4. **User Preferences**: Does user prefer verbose or concise output?

### What to Document
```python
session_learnings = {
    "successful_patterns": [
        "Using stratified split by price quintiles prevents leakage",
        "Feature selection improves RÂ² from 0.87 to 0.93",
        "Ensemble methods always beat individual models"
    ],
    "failed_attempts": [
        "Direct PDF conversion loses Thai fonts - use MDâ†’HTMLâ†’PDF",
        "Training without sample weights underperforms on rare numbers",
        "GPU params crash on Kaggle CPU environment"
    ],
    "best_practices": [
        "Always activate venv before any Python command",
        "Use absolute imports (from src.xxx) everywhere",
        "Update checkpoint every 30 minutes during long training"
    ]
}
```

### Update CLAUDE.md When
- New pattern discovered (add to examples)
- New error fixed (add to Known Issues)
- New best practice learned (add to guidelines)
- New platform supported (add to Platform Notes)

---

## âœ¨ Final Validation Before Session End

**Before saying goodbye, Claude MUST:**

1. âœ… Update `checkpoints/checkpoint_latest.json` with final state
2. âœ… Update `.project_state.json` with new progress percentage
3. âœ… Update `NEXT_SESSION.md` with clear next steps
4. âœ… List all files modified in this session
5. âœ… Document any errors encountered + fixes
6. âœ… Save current session_id for next session to reference

**Final message template:**
```
ğŸ“‹ Session Summary:
âœ… Completed: [task_1, task_2, task_3]
ğŸ“Š Progress: X% â†’ Y% (â–³Z%)
ğŸ“ Files Modified: N files
ğŸ”„ Checkpoint Saved: checkpoints/checkpoint_YYYYMMDD_HHMMSS.json
ğŸ¯ Next Session: [clear_instruction_for_next_task]

Type "à¸—à¸³à¸•à¹ˆà¸­" next time to resume exactly where we left off!
```

---

## âš ï¸ CRITICAL RULE: ALWAYS USE VIRTUAL ENVIRONMENT

**MANDATORY**: ALL Python commands, installations, and executions MUST be run inside the virtual environment (.venv)

```bash
# âœ… CORRECT - Activate venv first
source .venv/bin/activate  # Linux/Mac
.venv\Scripts\activate     # Windows

# Then run commands
python setup_local.py --install-deps
python main.py --run-all
pip install <package>

# âŒ WRONG - Never run outside venv
python main.py  # Will fail or use wrong packages
```

**Why**: Prevents dependency conflicts and ensures consistent environment across all platforms.

---

## ğŸ“‹ Project Overview

**Project**: ML Phone Number Price Prediction (Thai Lucky Number System)
**Goal**: Train ML models to achieve RÂ² > 0.90, using FULL optimization (no shortcuts!)
**Platform**: Local development, Google Colab, Kaggle Notebook

This is a machine learning system for predicting Thai phone number prices based on numerical patterns, cultural significance, and market demand. The system achieves RÂ² > 0.90 using advanced feature engineering (250+ features) and ensemble methods with XGBoost, LightGBM, and CatBoost.

## âš ï¸ Critical Rules (DO NOT VIOLATE)

```plaintext
âŒ DO NOT reduce training time
âŒ DO NOT remove code/functions
âŒ DO NOT modify configurations without explicit reason
âŒ DO NOT skip any model training
âŒ DO NOT change features, config, or model parameters arbitrarily

âœ… MUST train all models completely
âœ… MUST run full training pipeline to completion
âœ… Training time doesn't matter - completion matters
âœ… Only fix errors, don't optimize unless asked
âœ… Follow instructions exactly - don't do extra work
```

## Quick Start Commands

### Environment Setup
```bash
# Create and activate virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Running the ML Pipeline

```bash
# Full pipeline with optimization (production)
python main.py --run-all --optimize --feature-selection

# Quick pipeline without optimization (development)
python main.py --run-all

# Run individual steps
python main.py --data                    # Step 1: Load and clean data
python main.py --features                # Step 2: Create 250+ features
python main.py --split                   # Step 3: Train/test split
python main.py --train --optimize        # Step 4: Train models with hyperparameter tuning
python main.py --ensemble                # Step 5: Create ensemble models
python main.py --evaluate                # Step 6: Evaluate models
python main.py --visualize               # Step 7: Generate plots
python main.py --deploy                  # Step 8: Deploy best model
```

### Testing

```bash
# Run all tests
python tests/run_tests.py

# Run specific test module
python tests/run_tests.py test_features

# Run with pytest
pytest tests/

# Run with coverage
bash tests/run_coverage.sh

# Performance testing
pytest tests/test_performance.py -v -s
```

### API Deployment

```bash
# FastAPI (recommended)
python main.py --deploy --api-type fastapi --port 8000

# Flask
python main.py --deploy --api-type flask --port 5000

# Test API
curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{"phone_number": "0899999999"}'
```

## Architecture Overview

### Core Pipeline Flow

1. **Data Loading** (`src/data_handler.py`)
   - Auto-detects phone number and price columns
   - Cleans and validates data
   - Calculates sample weights for imbalanced data
   - Computes market statistics (must be calculated from training data only to prevent leakage)

2. **Feature Engineering** (`src/features.py`)
   - 250+ engineered features organized in 6 categories:
     - Basic features (30+): digit frequency, sum, mean, variance
     - Pattern features (50+): sequences, repeating patterns, mirrors
     - Cultural features (40+): Thai lucky numbers, auspicious combinations
     - Mathematical features (30+): entropy, Fibonacci, prime patterns
     - Market features (20+): rarity scores, tier classification
     - Advanced features (80+): position-weighted, interactions, polynomials

3. **Data Splitting** (`src/data_splitter.py`)
   - **CRITICAL**: Stratified split based on price quintiles
   - Train indices MUST be created BEFORE feature engineering to prevent data leakage
   - Market statistics calculated only from training data

4. **Preprocessing** (`src/model_utils.py`)
   - AdvancedPreprocessor with outlier removal and scaling
   - Feature selection (hybrid method combining multiple techniques)
   - Optional polynomial and interaction features

5. **Model Training** (`src/train.py`)
   - Base models: XGBoost, LightGBM, CatBoost, Random Forest
   - Hyperparameter optimization using Optuna (150 trials default)
   - Cross-validation with 10 folds
   - Support for sample weights

6. **Tier-Specific Models** (`src/tier_models.py`)
   - Dynamic price tier boundaries using KMeans
   - Separate models for standard/premium/luxury tiers
   - Router model for tier classification
   - Soft voting for predictions near boundaries

7. **Ensemble Methods** (`src/train.py`)
   - Weighted ensemble
   - Stacking ensemble
   - Advanced optimized stacking

8. **Evaluation** (`src/evaluate.py`)
   - RÂ², MAE, RMSE metrics
   - Feature importance analysis
   - Prediction analysis by price tier

9. **Visualization** (`src/visualize.py`)
   - Model comparison plots
   - Feature importance charts
   - Error distribution analysis
   - Comprehensive dashboard

## ğŸ› Known Issues & Critical Fixes

### 1. Import Errors (CRITICAL)

```python
# âŒ WRONG
from config import CONFIG
from model_utils import optimize_xgboost

# âœ… CORRECT
from src.config import CONFIG
from src.model_utils import optimize_xgboost
```

**Fix**: All files in `src/` must use absolute imports (`from src.xxx import`)

### 2. KeyError in Hyperparameters

```python
# âŒ WRONG - Causes KeyError with duplicate names
params = {
    'n_estimators': trial.suggest_int('n_estimators', 100, 1000)
}

# âœ… CORRECT - Use unique names per model
params = {
    'n_estimators': trial.suggest_int('xgb_n_estimators', 100, 1000),
    'max_depth': trial.suggest_int('xgb_max_depth', 3, 15)
}
```

### 3. Feature Grouping Bug

```python
# âŒ WRONG - Duplicate features
feature_groups = {
    'power_features': ['power_sum', 'weighted_sum'],
    'count_features': ['power_sum', 'digit_count']  # power_sum appears twice!
}

# âœ… CORRECT - No duplicates
feature_groups = {
    'power_features': ['power_sum', 'weighted_sum'],
    'count_features': ['digit_count', 'unique_count']
}
```

### 4. NaN/Inf Handling (MUST DO)

```python
# Always add after preprocessing
X_processed = X_processed.replace([np.inf, -np.inf], np.nan)
X_processed = X_processed.fillna(X_processed.median())
```

### 5. GPU Parameters on CPU Environment

```python
# âŒ DON'T use on Kaggle/CPU-only environments
params = {
    'task_type': 'GPU',
    'devices': '0:1'
}

# âœ… USE CPU parameters
params = {
    'task_type': 'CPU',
    'thread_count': -1
}
```

### 6. SimpleImputer Import

```python
# âŒ WRONG (old scikit-learn)
from sklearn.preprocessing import SimpleImputer

# âœ… CORRECT
from sklearn.impute import SimpleImputer
```

## Critical Implementation Details

### Data Leakage Prevention

**IMPORTANT**: To prevent data leakage, follow this exact sequence in main.py:

```python
# âœ… CORRECT: Create train/test indices BEFORE feature engineering
train_indices, test_indices = train_test_split(
    np.arange(len(df_cleaned)),
    test_size=0.2,
    stratify=pd.qcut(df_cleaned['price'], q=5, labels=False),
    random_state=42
)

# Pass train_indices to feature pipeline
X, y, sample_weights = run_feature_pipeline(df_cleaned, train_indices=train_indices)

# âŒ WRONG: Don't create features first, then split
# This causes market statistics to leak from test to train
```

The `calculate_market_statistics()` function in `data_handler.py` MUST only use training data.

### Configuration System

All configurations live in `src/config.py`:

- `CONFIG`: Feature engineering settings (lucky numbers, patterns, scores)
- `MODEL_CONFIG`: ML model settings (hyperparameters, CV folds, etc.)
- `TUNING_PARAMS`: Advanced tuning for rare/premium numbers
- `HYPERPARAMETER_RANGES`: Optuna search spaces

**Path Configuration** (`src/config.py`):
```python
# For Kaggle
BASE_PATH = '/kaggle/working/'

# For local development
BASE_PATH = '/home/user/projects/number-ML'

# For Google Colab
BASE_PATH = '/content/drive/MyDrive/ML_Project_Refactored'

# Dynamic (recommended)
BASE_PATH = os.getenv('ML_BASE_PATH', '/kaggle/working/ML_Project_Refactored')
```

### Thai Cultural Features

This project heavily relies on Thai numerology and cultural beliefs:

- Lucky digits: 1, 3, 4, 5, 6, 8, 9
- Unlucky digits: 0, 2, 7
- Premium pairs: 45, 54, 59, 95, 88, 99, 66, etc.
- Special endings: 9999 (highest score), 8888, 6666, 789 (dragon pattern)
- ABC position (digits 3-5): Special scoring for 789, 639, 519

These are defined in `CONFIG` and used throughout feature engineering.

### Sample Weights

The system uses progressive sample weights for high-value numbers:
- Thresholds: [10k, 50k, 100k, 500k, 1M]
- Weights: [1.0, 2.0, 4.0, 6.0, 8.0, 10.0]

This ensures the model doesn't underfit on rare expensive numbers.

## Adding New Features

To add custom features, edit `src/features.py`:

```python
def my_custom_feature(phone_number):
    """
    Your feature logic here

    Parameters:
    -----------
    phone_number : str
        10-digit phone number

    Returns:
    --------
    score : float
        Feature score
    """
    # Implementation
    return score

# Add to create_all_features() or create_masterpiece_features()
df['my_feature'] = df['phone_number'].apply(my_custom_feature)
```

## Directory Structure

```
number-ML/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Original CSV files
â”‚   â”œâ”€â”€ processed/        # cleaned_data.csv
â”‚   â””â”€â”€ features/         # features.pkl, train_indices.npy, test_indices.npy
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ deployed/         # best_model.pkl (production)
â”‚   â””â”€â”€ experiments/      # Experimental models
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py         # All configuration settings
â”‚   â”œâ”€â”€ data_handler.py   # Data loading and cleaning
â”‚   â”œâ”€â”€ features.py       # Feature engineering (250+ features)
â”‚   â”œâ”€â”€ data_splitter.py  # Stratified train/test split
â”‚   â”œâ”€â”€ model_utils.py    # Preprocessing and feature selection
â”‚   â”œâ”€â”€ train.py          # Model training and ensembles
â”‚   â”œâ”€â”€ tier_models.py    # Tier-specific modeling
â”‚   â”œâ”€â”€ evaluate.py       # Model evaluation
â”‚   â””â”€â”€ visualize.py      # Plotting functions
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ app.py            # FastAPI/Flask app
â”‚   â””â”€â”€ prediction.py     # Prediction pipeline
â”œâ”€â”€ tests/                # Comprehensive test suite
â”‚   â”œâ”€â”€ run_tests.py      # Test runner
â”‚   â”œâ”€â”€ run_coverage.sh   # Coverage script
â”‚   â””â”€â”€ test_*.py         # Test modules
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ helpers.py        # Helper functions
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ figures/          # Plots and visualizations
â”‚   â”œâ”€â”€ reports/          # Evaluation reports
â”‚   â””â”€â”€ metrics/          # Performance metrics
â””â”€â”€ main.py               # Main pipeline orchestrator
```

## Common Development Tasks

### Adjusting Model Performance

To increase RÂ² score:
1. Increase `optuna_trials` in `MODEL_CONFIG` (default: 150)
2. Increase `max_features` for feature selection (default: 250)
3. Enable polynomial features: `use_polynomial_features: True`
4. Enable tier-specific models: `use_tier_models: True`

### Memory Optimization

If running out of memory:
1. Reduce `max_features` in config (from 250 to 100)
2. Disable polynomial features: `use_polynomial_features: False`
3. Reduce `optuna_trials` (from 150 to 50)
4. Use fewer CV folds: `cv_folds: 5` (from 10)

### Debugging

Enable detailed logging:
```bash
python main.py --run-all --log-level DEBUG
```

Logs are saved to `logs/pipeline_YYYYMMDD_HHMMSS.log`

## Model Deployment

The deployed model package (`models/deployed/best_model.pkl`) contains:
- `model`: Best trained model
- `model_name`: Model name (e.g., "XGBoost")
- `feature_names`: List of feature names
- `preprocessor`: AdvancedPreprocessor instance
- `r2_score`: Test RÂ² score
- `timestamp`: Deployment timestamp
- `config`: MODEL_CONFIG used for training

Load for inference:
```python
import joblib
deployment = joblib.load('models/deployed/best_model.pkl')
model = deployment['model']
preprocessor = deployment['preprocessor']
```

## Performance Targets

- RÂ² Score: > 0.90 (target: 0.93+)
- MAE: < 0.05
- RMSE: < 0.08
- Best ensemble typically achieves RÂ² â‰ˆ 0.93

## Dependencies

Core ML libraries:
- scikit-learn >= 1.0.0
- xgboost >= 1.5.0
- lightgbm >= 3.3.0
- catboost >= 1.0.0
- optuna >= 3.0.0
- pandas >= 1.3.0
- numpy < 2.0.0 (compatibility)

See `requirements.txt` for full list.

## ğŸ¯ Success Criteria

When training completes successfully, you should have:

```python
âœ… Models trained: 6+ models (XGBoost, LightGBM, CatBoost, RF, ExtraTrees, GradientBoosting)
âœ… Ensemble created
âœ… RÂ² Score > 0.90 (target: 0.93+)
âœ… All models saved to models/deployed/
âœ… No errors during training pipeline
```

## ğŸ“ Development Philosophy

1. **Read original code carefully** - Don't change anything prematurely
2. **Fix only what's broken** - No optimization unless requested
3. **Test incrementally** - imports â†’ functions â†’ pipeline
4. **KISS principle** - Keep It Simple, Stupid!
5. **Don't overthink** - Follow instructions exactly

## ğŸ” Debugging Workflow

If errors occur:

1. Read error message thoroughly
2. Identify root cause (usually imports or KeyError)
3. Fix at source, not everywhere that might be related
4. Test each component separately
5. Document error and solution

## Platform-Specific Notes

### For Kaggle Notebook

See `CLAUDE_KAGGLE.md` for complete Kaggle-specific setup instructions including:
- Cell 1: Complete environment setup
- Cell 2: Full training pipeline
- Import fixes for Kaggle paths
- Data preparation steps

### For Local Development

This is the default setup. Use commands in "Quick Start Commands" section above.

## ğŸ“š Additional Resources

- `CLAUDE_KAGGLE.md` - Complete Kaggle notebook setup guide
- `README.md` - User-facing documentation
- `implementation_guide.md` - Original implementation notes
- `tests/test_summary.md` - Testing documentation
