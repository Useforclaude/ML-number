{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83d\ude80 ML Phone Number Price Prediction - Kaggle Auto-Resume Training\n",
    "\n",
    "**Optimized for Kaggle with P100 GPU!**\n",
    "\n",
    "**Features:**\n",
    "- \u2705 Auto-save checkpoints to /kaggle/working every 10 epochs\n",
    "- \u2705 Auto-resume from last checkpoint after timeout\n",
    "- \u2705 Zero data loss (all progress saved)\n",
    "- \u2705 Optimized for P100 GPU (30% faster than Colab T4!)\n",
    "- \u2705 16-30 GB RAM (more than Colab!)\n",
    "\n",
    "**How to Use:**\n",
    "1. Add dataset as Kaggle Dataset (one-time)\n",
    "2. Run Cell 1-6 sequentially\n",
    "3. Cell 4 will auto-detect if there's a checkpoint\n",
    "4. If found \u2192 Resume from last epoch\n",
    "5. If not found \u2192 Start fresh\n",
    "6. Training auto-saves every 10 epochs to /kaggle/working\n",
    "\n",
    "**If timeout (9 hours):**\n",
    "- Kaggle auto-commits notebook version\n",
    "- Fork this notebook (new version)\n",
    "- Run Cell 1-6 again\n",
    "- Training will resume from last checkpoint!\n",
    "\n",
    "**Advantages over Colab:**\n",
    "- \ud83d\ude80 Faster GPU (P100 vs T4)\n",
    "- \ud83d\udcbe More RAM (16-30 GB vs 12 GB)\n",
    "- \ud83d\udce6 Kaggle Datasets (unlimited vs 15 GB)\n",
    "- \ud83d\udd12 More stable (less disconnects)\n",
    "- \ud83d\udcda Pre-installed ML libraries\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcc2 Cell 1: Setup Paths & Environment (Kaggle-Specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Kaggle paths (auto-mounted, no need to mount!)\nimport os\nfrom pathlib import Path\n\n# Kaggle-specific paths\nKAGGLE_INPUT = Path('/kaggle/input')      # Read-only dataset location\nKAGGLE_WORKING = Path('/kaggle/working')  # Read-write workspace (20 GB)\n\n# \u2705 FIX: Save directly to /kaggle/working (NOT in subfolder!)\n# Kaggle ONLY persists files in /kaggle/working/ root, not subfolders\nCHECKPOINT_DIR = KAGGLE_WORKING / 'checkpoints'\nMODELS_DIR = KAGGLE_WORKING / 'models'\nLOGS_DIR = KAGGLE_WORKING / 'logs'\nRESULTS_DIR = KAGGLE_WORKING / 'results'\n\n# Create directories (these will persist across sessions!)\nfor dir_path in [CHECKPOINT_DIR, MODELS_DIR, LOGS_DIR, RESULTS_DIR]:\n    dir_path.mkdir(parents=True, exist_ok=True)\n\nprint(\"\u2705 Kaggle environment detected!\")\nprint(f\"\\n\ud83d\udcc2 Paths configured:\")\nprint(f\"   Input (datasets): {KAGGLE_INPUT}\")\nprint(f\"   Working (read-write): {KAGGLE_WORKING}\")\nprint(f\"   Checkpoints: {CHECKPOINT_DIR} \u2b50 PERSISTENT!\")\nprint(f\"   Models: {MODELS_DIR} \u2b50 PERSISTENT!\")\nprint(f\"   Logs: {LOGS_DIR}\")\nprint(f\"   Results: {RESULTS_DIR}\")\n\n# Check available datasets\nprint(f\"\\n\ud83d\udcca Available datasets:\")\nif KAGGLE_INPUT.exists():\n    datasets = list(KAGGLE_INPUT.glob('*'))\n    for ds in datasets:\n        print(f\"   - {ds.name}\")\nelse:\n    print(\"   No datasets mounted yet.\")\n    print(\"   Add dataset: Data \u2192 Add data \u2192 Search or upload\")\n\n# Set working directory\nos.chdir(KAGGLE_WORKING)\nprint(f\"\\n\u2705 Working directory: {os.getcwd()}\")\n\n# Check GPU\nimport subprocess\ntry:\n    gpu_info = subprocess.check_output(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader']).decode()\n    print(f\"\\n\ud83c\udfae GPU: {gpu_info.strip()}\")\nexcept:\n    print(\"\\n\u26a0\ufe0f  No GPU detected. Enable: Settings \u2192 Accelerator \u2192 GPU\")\n\nprint(f\"\\n\ud83d\udca1 Checkpoint Strategy:\")\nprint(f\"   \u2705 Files saved to {CHECKPOINT_DIR}\")\nprint(f\"   \u2705 Kaggle auto-saves these on notebook commit\")\nprint(f\"   \u2705 Session timeout \u2192 Fork notebook \u2192 Resumes from checkpoint!\")\nprint(f\"   \u2705 NO DATA LOSS!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## \ud83d\udce6 Cell 2: Load Project from Kaggle Dataset\n\n**Note:** Kaggle automatically extracts ZIP files when uploaded as dataset.\nFiles are available directly in `/kaggle/input/your-dataset-name/`\n\n**Setup:**\n1. Upload `number-ML-kaggle-package-LATEST.zip` as Kaggle Dataset\n2. Name it: `phone-number-ml-project-latest`\n3. Add to this notebook: Data \u2192 Add data \u2192 Your dataset\n4. Run this cell to copy files to working directory"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 2: Copy Project Files from Kaggle Dataset (Auto-Extracted)\nimport shutil\nfrom pathlib import Path\n\ndataset_name = 'phone-number-ml-project-latest'  # \u26a0\ufe0f Update to match your dataset name\ndataset_path = KAGGLE_INPUT / dataset_name\n\nprint(f\"\ud83d\udcc2 Loading from: {dataset_path}\\n\")\n\nif dataset_path.exists():\n    print(\"\u2705 Dataset found! Copying files to working directory...\\n\")\n    \n    # Copy src/ folder\n    src_source = dataset_path / 'src'\n    src_dest = KAGGLE_WORKING / 'src'\n    \n    if src_source.exists():\n        shutil.copytree(src_source, src_dest, dirs_exist_ok=True)\n        py_files = list(src_dest.glob('*.py'))\n        print(f\"\u2705 Copied src/: {len(py_files)} Python files\")\n    else:\n        print(\"\u274c src/ folder not found in dataset\")\n    \n    # Copy data/ folder\n    data_source = dataset_path / 'data'\n    data_dest = KAGGLE_WORKING / 'data'\n    \n    if data_source.exists():\n        shutil.copytree(data_source, data_dest, dirs_exist_ok=True)\n        print(f\"\u2705 Copied data/ folder\")\n    else:\n        print(\"\u274c data/ folder not found in dataset\")\n    \n    # Copy config files (optional)\n    for file in ['requirements.txt', 'CLAUDE.md', 'KAGGLE_SETUP.md']:\n        src_file = dataset_path / file\n        if src_file.exists():\n            shutil.copy2(src_file, KAGGLE_WORKING / file)\n            print(f\"\u2705 Copied {file}\")\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"\ud83d\udd0d VERIFICATION\")\n    print(\"=\"*70)\n    \n    # Verify src/\n    src_path = KAGGLE_WORKING / 'src'\n    if src_path.exists():\n        py_files = sorted(list(src_path.glob('*.py')))\n        print(f\"\\n\u2705 Project code ready ({len(py_files)} files):\")\n        for f in py_files:\n            print(f\"   - {f.name}\")\n    \n    # Verify data\n    data_csv = KAGGLE_WORKING / 'data' / 'raw' / 'numberdata.csv'\n    if data_csv.exists():\n        import pandas as pd\n        df = pd.read_csv(data_csv)\n        print(f\"\\n\u2705 Data loaded: {len(df)} rows, {len(df.columns)} columns\")\n        print(f\"   Columns: {list(df.columns)}\")\n        print(f\"   File size: {data_csv.stat().st_size / 1024:.1f} KB\")\n    else:\n        print(f\"\\n\u274c Data file not found at: {data_csv}\")\n    \n    # Add to Python path\n    import sys\n    sys.path.insert(0, str(KAGGLE_WORKING))\n    print(f\"\\n\u2705 Python path updated\")\n    \n    print(\"=\"*70)\n    print(\"\\n\ud83c\udf89 Project setup complete! Ready for training.\\n\")\n    \nelse:\n    print(f\"\u274c Dataset not found: {dataset_name}\")\n    print(\"\\n\ud83d\udccb Available datasets:\")\n    for ds in KAGGLE_INPUT.glob('*'):\n        print(f\"   - {ds.name}\")\n    print(\"\\n\ud83d\udca1 Update 'dataset_name' variable to match your dataset name\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd27 Cell 3: Install Dependencies (Minimal - Most Pre-Installed)\n",
    "\n",
    "Kaggle has most ML libraries pre-installed. Only install if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verify pre-installed libraries (most should already exist)\nprint(\"\ud83d\udd0d Checking pre-installed libraries...\\n\")\n\nrequired_libs = {\n    'numpy': 'numpy',\n    'pandas': 'pandas',\n    'scikit-learn': 'sklearn',\n    'xgboost': 'xgboost',\n    'lightgbm': 'lightgbm',\n    'catboost': 'catboost',\n    'optuna': 'optuna',\n    'psutil': 'psutil'  # Added for memory monitoring\n}\n\nmissing = []\nfor name, import_name in required_libs.items():\n    try:\n        mod = __import__(import_name)\n        version = getattr(mod, '__version__', 'unknown')\n        print(f\"   \u2713 {name}: {version}\")\n    except ImportError:\n        print(f\"   \u2717 {name}: NOT INSTALLED\")\n        missing.append(name)\n\n# Install missing libraries\nif missing:\n    print(f\"\\n\ud83d\udce6 Installing missing libraries: {', '.join(missing)}\")\n    !pip install -q {' '.join(missing)}\n    print(\"\u2705 Installation complete!\")\nelse:\n    print(\"\\n\u2705 All required libraries are already installed!\")\n    print(\"   (This is a Kaggle advantage - no installation time!)\")\n\n# Add project to Python path\nimport sys\nsys.path.insert(0, str(KAGGLE_WORKING))\nprint(f\"\\n\u2705 Python path updated: {KAGGLE_WORKING}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd0d Cell 4: Auto-Detect Checkpoint & Setup Auto-Resume \u2b50\n",
    "\n",
    "**This is the magic cell!**\n",
    "- Checks for existing checkpoints in /kaggle/working/checkpoints\n",
    "- If found \u2192 RESUME MODE\n",
    "- If not found \u2192 FRESH START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import checkpoint manager (works on both Colab and Kaggle!)\nfrom src.checkpoint_manager import CheckpointManager, detect_environment\n\n# Detect environment\nenv = detect_environment()\nprint(f\"\ud83c\udf0d Environment detected: {env.upper()}\")\nprint(f\"   (Auto-configured for Kaggle paths)\\n\")\n\n# \u2705 FIX: Use direct path to /kaggle/working/checkpoints (no subfolder!)\n# This ensures checkpoints persist across sessions\ncheckpoint_dir_path = str(CHECKPOINT_DIR)\n\nprint(f\"\ud83d\udcc2 Checkpoint directory: {checkpoint_dir_path}\")\n\n# Verify directory exists\nif not Path(checkpoint_dir_path).exists():\n    Path(checkpoint_dir_path).mkdir(parents=True, exist_ok=True)\n    print(f\"\u2705 Created checkpoint directory\")\n\n# Initialize checkpoint manager\ncheckpoint_manager = CheckpointManager(\n    checkpoint_dir=checkpoint_dir_path,\n    max_checkpoints=5,\n    save_every=10\n)\n\n# Check for existing checkpoint\nprint(\"\\n\ud83d\udd0d Checking for existing checkpoint...\\n\")\ncheckpoint = checkpoint_manager.load_latest_checkpoint()\n\nif checkpoint:\n    RESUME_MODE = True\n    START_EPOCH = checkpoint['epoch'] + 1\n    PREVIOUS_METRICS = checkpoint.get('metrics', {})\n    \n    print(\"=\" * 70)\n    print(\"\ud83d\udd04 RESUME MODE ACTIVATED\")\n    print(\"=\" * 70)\n    print(f\"Environment: KAGGLE (P100 GPU)\")\n    print(f\"Last completed epoch: {checkpoint['epoch']}\")\n    print(f\"Will resume from epoch: {START_EPOCH}\")\n    print(f\"Checkpoint timestamp: {checkpoint['timestamp']}\")\n    print(\"\\nPrevious metrics:\")\n    for key, value in PREVIOUS_METRICS.items():\n        if isinstance(value, float):\n            print(f\"  {key}: {value:.4f}\")\n        else:\n            print(f\"  {key}: {value}\")\n    print(\"=\" * 70)\n    \n    # Print recovery info if available\n    print(\"\\n\")\n    checkpoint_manager.print_recovery_info()\n    \nelse:\n    RESUME_MODE = False\n    START_EPOCH = 0\n    PREVIOUS_METRICS = {}\n    \n    print(\"=\" * 70)\n    print(\"\ud83c\udd95 FRESH START MODE\")\n    print(\"=\" * 70)\n    print(f\"Environment: KAGGLE (P100 GPU)\")\n    print(f\"No checkpoint found.\")\n    print(f\"Will start training from epoch 0.\")\n    print(f\"Checkpoints will be saved to {checkpoint_dir_path}\")\n    print(\"=\" * 70)\n\nprint(\"\\n\u2705 Auto-resume setup complete!\")\nprint(f\"Resume mode: {RESUME_MODE}\")\nprint(f\"Start epoch: {START_EPOCH}\")\nprint(f\"\\n\ud83d\udca1 Tip: If Kaggle times out (9h), fork this notebook and run again.\")\nprint(f\"    Training will resume from last checkpoint automatically!\")\nprint(f\"\\n\ud83c\udfaf Checkpoint persistence:\")\nprint(f\"   - Saved to: {checkpoint_dir_path}\")\nprint(f\"   - Auto-saved on notebook commit\")\nprint(f\"   - Survives session timeout!\")\nprint(f\"   - NO MORE RE-TRAINING FROM SCRATCH! \ud83c\udf89\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcca Cell 5: Load Data & Feature Engineering\n",
    "\n",
    "Load data from Kaggle Dataset (much faster than Google Drive!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import required modules\nfrom src.data_handler import load_and_clean_data, calculate_market_statistics\nfrom src.features import create_masterpiece_features\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport pandas as pd\n\nprint(\"\ud83d\udcc2 Loading data from Kaggle Dataset...\")\n\n# Find data file in Kaggle input\ndata_files = list(KAGGLE_INPUT.glob('*/numberdata.csv'))\nif not data_files:\n    data_files = list(KAGGLE_INPUT.glob('*/*.csv'))\n    if not data_files:\n        data_files = list((KAGGLE_WORKING / 'data' / 'raw').glob('*.csv'))\n\nif data_files:\n    DATA_PATH = str(data_files[0])\n    print(f\"\u2705 Found data: {DATA_PATH}\")\nelse:\n    # Fallback\n    DATA_PATH = str(KAGGLE_WORKING / 'data' / 'raw' / 'numberdata.csv')\n    print(f\"\u26a0\ufe0f  Using fallback: {DATA_PATH}\")\n\n# Load and clean - load_and_clean_data returns (df_raw, df_cleaned)\nprint(f\"\\n\ud83d\udd04 Loading and cleaning data...\")\ndf_raw, df = load_and_clean_data(DATA_PATH)\n\n# \u2705 CRITICAL: Data size check\nprint(f\"\\n\ud83d\udcca Data Validation:\")\nprint(f\"   Raw data: {len(df_raw)} rows\")\nprint(f\"   Cleaned data: {len(df)} rows\")\nprint(f\"   Columns: {list(df.columns)}\")\n\nif len(df) < 100:\n    raise ValueError(f\"\u274c INSUFFICIENT DATA! Got {len(df)}, need 1000+ for good training\")\nelif len(df) < 1000:\n    print(f\"\u26a0\ufe0f  WARNING: Only {len(df)} samples. Recommend 3000+ for best results.\")\nelse:\n    print(f\"\u2705 Data size looks good!\")\n\n# \u2705 \u0e1b\u0e49\u0e2d\u0e07\u0e01\u0e31\u0e19 DATA LEAKAGE: Split INDICES first (before features!)\nprint(f\"\\n\ud83d\udd00 Step 1: Split train/test INDICES (before feature engineering)\")\nprint(f\"   This prevents market statistics from leaking between train/test!\")\n\n# Create stratified split based on price quintiles\ntry:\n    price_bins = pd.qcut(df['price'], q=5, labels=False, duplicates='drop')\nexcept:\n    # Fallback if qcut fails\n    price_bins = pd.cut(df['price'], bins=5, labels=False)\n\ntrain_idx, test_idx = train_test_split(\n    np.arange(len(df)),\n    test_size=0.2,\n    stratify=price_bins,\n    random_state=42\n)\n\nprint(f\"\u2705 Split complete:\")\nprint(f\"   Train indices: {len(train_idx)} ({len(train_idx)/len(df)*100:.1f}%)\")\nprint(f\"   Test indices: {len(test_idx)} ({len(test_idx)/len(df)*100:.1f}%)\")\n\n# \u2705 Step 2: Calculate market statistics from TRAIN ONLY\nprint(f\"\\n\ud83d\udcca Step 2: Calculate market statistics from TRAINING data only\")\nmarket_stats = calculate_market_statistics(df.iloc[train_idx])\nprint(f\"\u2705 Market statistics calculated (NO data leakage!)\")\n\n# \u2705 Step 3: Extract prices (y) BEFORE feature engineering\ny_train = df.iloc[train_idx]['price'].values\ny_test = df.iloc[test_idx]['price'].values\n\nprint(f\"\\n\ud83d\udcb0 Price statistics:\")\nprint(f\"   Train - Min: {y_train.min():.0f}, Max: {y_train.max():.0f}, Mean: {y_train.mean():.0f}\")\nprint(f\"   Test  - Min: {y_test.min():.0f}, Max: {y_test.max():.0f}, Mean: {y_test.mean():.0f}\")\n\n# \u2705 Step 4: Create features separately for train and test (with same market_stats!)\nprint(f\"\\n\ud83d\udd27 Step 4: Creating features (250+ features)...\")\nprint(f\"   Using TRAIN market statistics for both sets (prevents leakage!)\")\nprint(f\"   This may take 2-3 minutes on Kaggle...\")\n\ndf_train_features = create_masterpiece_features(\n    df.iloc[train_idx],\n    market_stats=market_stats\n)\nprint(f\"\u2705 Train features: {df_train_features.shape}\")\n\ndf_test_features = create_masterpiece_features(\n    df.iloc[test_idx],\n    market_stats=market_stats  # Same stats from train!\n)\nprint(f\"\u2705 Test features: {df_test_features.shape}\")\n\n# \u2705 Step 5: Convert all features to numeric (FIX STRING ERROR!)\nprint(f\"\\n\ud83d\udd27 Step 5: Converting all features to numeric...\")\nfor col in df_train_features.columns:\n    df_train_features[col] = pd.to_numeric(df_train_features[col], errors='coerce')\nfor col in df_test_features.columns:\n    df_test_features[col] = pd.to_numeric(df_test_features[col], errors='coerce')\nprint(f\"\u2705 All features converted to numeric\")\n\n# \u2705 Step 6: Handle NaN and Inf\nprint(f\"\\n\ud83d\udd27 Step 6: Handling NaN and Inf values...\")\n# Train\ntrain_inf = np.isinf(df_train_features.values).sum()\ntrain_nan = df_train_features.isna().sum().sum()\ndf_train_features = df_train_features.replace([np.inf, -np.inf], np.nan)\ndf_train_features = df_train_features.fillna(df_train_features.median())\n\n# Test\ntest_inf = np.isinf(df_test_features.values).sum()\ntest_nan = df_test_features.isna().sum().sum()\ndf_test_features = df_test_features.replace([np.inf, -np.inf], np.nan)\ndf_test_features = df_test_features.fillna(df_train_features.median())  # Use TRAIN median for test\n\nprint(f\"   Train - Inf: {train_inf}, NaN: {train_nan} \u2192 Replaced with 0\")\nprint(f\"   Test  - Inf: {test_inf}, NaN: {test_nan} \u2192 Replaced with 0\")\n\n# \u2705 Step 7: Final preparation\nX_train = df_train_features.values.astype(np.float32)  # Use float32 to save memory\nX_test = df_test_features.values.astype(np.float32)\n\nprint(f\"\\n\ud83d\udcca Final dataset:\")\nprint(f\"   X_train: {X_train.shape}, dtype: {X_train.dtype}\")\nprint(f\"   X_test:  {X_test.shape}, dtype: {X_test.dtype}\")\nprint(f\"   y_train: {y_train.shape}, dtype: {y_train.dtype}\")\nprint(f\"   y_test:  {y_test.shape}, dtype: {y_test.dtype}\")\n\n# Save feature names for later\nFEATURE_NAMES = list(df_train_features.columns)\nprint(f\"\\n\u2705 Total features: {len(FEATURE_NAMES)}\")\n\n# Final validation\nprint(f\"\\n\ud83d\udd0d Final validation:\")\nprint(f\"   X_train NaN: {np.isnan(X_train).any()}, Inf: {np.isinf(X_train).any()}\")\nprint(f\"   X_test NaN:  {np.isnan(X_test).any()}, Inf: {np.isinf(X_test).any()}\")\nprint(f\"   y_train NaN: {np.isnan(y_train).any()}, Inf: {np.isinf(y_train).any()}\")\nprint(f\"   y_test NaN:  {np.isnan(y_test).any()}, Inf: {np.isinf(y_test).any()}\")\n\n# Memory info\nimport psutil\nmem = psutil.virtual_memory()\nprint(f\"\\n\ud83d\udcbe Memory usage:\")\nprint(f\"   Total RAM: {mem.total / (1024**3):.1f} GB\")\nprint(f\"   Available: {mem.available / (1024**3):.1f} GB\")\nprint(f\"   Used: {mem.percent:.1f}%\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"\u2705 DATA PREPARATION COMPLETE - NO DATA LEAKAGE!\")\nprint(\"=\"*80)\nprint(\"\ud83c\udfaf Ready for ULTRA-POWER training!\")\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\ude80 Cell 6: Train with Auto-Checkpoint & Auto-Resume \u2b50\n",
    "\n",
    "**This cell will:**\n",
    "- Resume from checkpoint if found (Cell 4)\n",
    "- Train model with auto-save every 10 epochs\n",
    "- Save checkpoints to /kaggle/working/checkpoints\n",
    "- If timeout, just fork notebook and run Cell 1-6 again \u2192 Resume automatically!\n",
    "\n",
    "**Optimized for Kaggle P100 GPU - ~30% faster than Colab T4!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from src.train_production import train_production_pipeline\nfrom src.gpu_monitor import GPUMonitor  # \u2705 NEW: Real-time GPU monitoring\nimport time\nimport subprocess\nfrom datetime import datetime\n\n# ============================================================================\n# \ud83c\udfae GPU DETECTION & REAL-TIME MONITORING\n# ============================================================================\nprint(\"=\" * 80)\nprint(\"\ud83c\udfae GPU DETECTION & VERIFICATION\")\nprint(\"=\" * 80)\n\nHAS_GPU = False\ngpu_info = \"CPU\"\n\ntry:\n    # Get GPU name\n    gpu_name = subprocess.check_output(\n        ['nvidia-smi', '--query-gpu=name', '--format=csv,noheader'],\n        stderr=subprocess.DEVNULL\n    ).decode().strip()\n\n    # Get GPU memory\n    gpu_memory = subprocess.check_output(\n        ['nvidia-smi', '--query-gpu=memory.total', '--format=csv,noheader'],\n        stderr=subprocess.DEVNULL\n    ).decode().strip()\n\n    # Get GPU utilization\n    gpu_util = subprocess.check_output(\n        ['nvidia-smi', '--query-gpu=utilization.gpu', '--format=csv,noheader'],\n        stderr=subprocess.DEVNULL\n    ).decode().strip()\n\n    # Get GPU memory usage\n    gpu_mem_used = subprocess.check_output(\n        ['nvidia-smi', '--query-gpu=memory.used', '--format=csv,noheader'],\n        stderr=subprocess.DEVNULL\n    ).decode().strip()\n\n    if gpu_name:\n        HAS_GPU = True\n        gpu_info = gpu_name\n\n        print(f\"\\n\u2705 GPU DETECTED!\")\n        print(f\"   Model: {gpu_name}\")\n        print(f\"   Total Memory: {gpu_memory}\")\n        print(f\"   Current Utilization: {gpu_util}\")\n        print(f\"   Memory Used: {gpu_mem_used}\")\n        print(f\"\\n\ud83d\udca1 GPU Status:\")\n        print(f\"   - Cells 1-5: GPU will show 0% (normal - CPU tasks)\")\n        print(f\"   - Cell 6 (this cell): GPU will activate during training!\")\n        print(f\"   - Expected GPU usage: 70-95% during XGBoost/LightGBM/CatBoost\")\n        print(f\"\\n\ud83d\udd25 Watch for GPU activation during:\")\n        print(f\"   \u2705 XGBoost optimization \u2192 GPU 70-90%\")\n        print(f\"   \u2705 XGBoost training \u2192 GPU 85-95%\")\n        print(f\"   \u2705 LightGBM optimization \u2192 GPU 70-85%\")\n        print(f\"   \u2705 LightGBM training \u2192 GPU 80-90%\")\n        print(f\"   \u2705 CatBoost optimization \u2192 GPU 60-80%\")\n        print(f\"   \u2705 CatBoost training \u2192 GPU 70-85%\")\n        print(f\"   \u26aa RandomForest/ExtraTrees \u2192 GPU 0% (CPU only - normal)\")\n    else:\n        print(f\"\\n\u26a0\ufe0f  No GPU found - using CPU\")\n        print(f\"   This will be SLOWER but still works!\")\n\nexcept Exception as e:\n    print(f\"\\n\u26a0\ufe0f  GPU detection failed: {e}\")\n    print(f\"   Falling back to CPU\")\n    print(f\"   Training will be slower but still functional\")\n\nprint(\"=\" * 80)\n\n# ============================================================================\n# \ud83c\udfae START REAL-TIME GPU MONITORING (NEW!)\n# ============================================================================\nif HAS_GPU:\n    print(f\"\\n\ud83c\udfae Starting real-time GPU monitoring...\")\n    print(f\"   GPU stats will be printed every 30 seconds during training\")\n    print(f\"   This helps verify GPU is actually being used!\\n\")\n    \n    gpu_monitor = GPUMonitor(interval=30, verbose=True)\n    gpu_monitor.start()\nelse:\n    print(f\"\\n\u26a0\ufe0f  GPU monitoring disabled (no GPU detected)\")\n    gpu_monitor = None\n\n# Configuration\nOPTIMIZE = True  # \u26a0\ufe0f Set to True for full Optuna optimization (SLOW but BEST!)\nN_TRIALS = 100   # Optuna trials per model (50-150, higher = better but slower)\n                 # 100 trials \u00d7 4 models \u00d7 2min \u2248 13 hours\n                 # 50 trials \u00d7 4 models \u00d7 2min \u2248 7 hours (fits in 1 Kaggle session!)\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"\ud83d\ude80 ULTRA-POWER PRODUCTION TRAINING PIPELINE\")\nprint(\"=\"*80)\nprint(f\"\")\nprint(f\"\ud83d\udcca Dataset:\")\nprint(f\"   Training:   {len(X_train):,} samples \u00d7 {X_train.shape[1]} features\")\nprint(f\"   Validation: {len(X_test):,} samples \u00d7 {X_test.shape[1]} features\")\nprint(f\"\")\nprint(f\"\u2699\ufe0f  Configuration:\")\nprint(f\"   Platform: KAGGLE\")\nprint(f\"   Accelerator: {'GPU (' + gpu_info + ')' if HAS_GPU else 'CPU (all cores)'}\")\nprint(f\"   GPU Monitoring: {'ENABLED (every 30 sec)' if HAS_GPU else 'DISABLED'}\")\nprint(f\"   Optimization: {'FULL OPTUNA' if OPTIMIZE else 'DEFAULT PARAMS'}\")\nif OPTIMIZE:\n    print(f\"   Optuna trials: {N_TRIALS} per model\")\n    est_time = N_TRIALS * 4 * 2 / 60  # 4 models, 2 min/trial average\n    print(f\"   Estimated time: {est_time:.1f} hours\")\n    if est_time > 9:\n        print(f\"   \u26a0\ufe0f  May exceed Kaggle 9h limit! Consider reducing N_TRIALS to 50\")\nelse:\n    print(f\"   Estimated time: 30-60 minutes\")\nprint(f\"\")\nprint(f\"\ud83c\udfaf Models to train:\")\nprint(f\"   - XGBoost      (tree-based, GPU-accelerated)\")\nprint(f\"   - LightGBM     (tree-based, fast)\")\nprint(f\"   - CatBoost     (tree-based, handles categoricals)\")\nprint(f\"   - RandomForest (ensemble of decision trees)\")\nprint(f\"   - ExtraTrees   (randomized decision trees)\")\nprint(f\"   - GradientBoosting (sequential boosting)\")\nprint(f\"\")\nprint(f\"\ud83c\udfd7\ufe0f  Ensemble methods:\")\nprint(f\"   - Voting Ensemble (top 5 models)\")\nprint(f\"   - Stacking Ensemble (meta-learner)\")\nprint(f\"   - Weighted Average (R\u00b2-weighted)\")\nprint(f\"   - Simple Average\")\nprint(f\"\")\nprint(f\"\u2728 Advanced features:\")\nprint(f\"   \u2705 Progressive sample weights (10x for expensive numbers)\")\nprint(f\"   \u2705 Cross-validation (10-fold)\")\nprint(f\"   \u2705 Early stopping (prevent overfit)\")\nprint(f\"   \u2705 Automatic best model selection\")\nprint(f\"   \u2705 NO data leakage (split before features)\")\nprint(f\"   \u2705 Real-time GPU monitoring (every 30 seconds)\")\nprint(\"=\"*80)\n\n# Ask for confirmation if long training\nif OPTIMIZE and N_TRIALS >= 100:\n    print(f\"\\n\u26a0\ufe0f  WARNING: This will take ~{est_time:.0f} hours!\")\n    print(f\"   Make sure Kaggle notebook can run that long.\")\n    print(f\"   Starting in 5 seconds...\")\n    time.sleep(5)\n\n# Start training\nprint(f\"\\n\ud83d\ude80 STARTING ULTRA-POWER TRAINING...\")\nprint(f\"   {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\nprint(f\"   GPU monitoring: {'ACTIVE' if gpu_monitor else 'DISABLED'}\\n\")\n\nstart_time = time.time()\n\ntry:\n    # Run production pipeline\n    result = train_production_pipeline(\n        X_train=X_train,\n        y_train=y_train,\n        X_val=X_test,\n        y_val=y_test,\n        optimize=OPTIMIZE,\n        n_trials=N_TRIALS,\n        use_gpu=HAS_GPU,\n        verbose=True\n    )\n    \n    # Training complete - stop GPU monitoring\n    if gpu_monitor:\n        gpu_monitor.stop()\n    \n    elapsed_time = time.time() - start_time\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"\ud83c\udf89 ULTRA-POWER TRAINING COMPLETE!\")\n    print(\"=\"*80)\n    print(f\"\\n\u23f1\ufe0f  Training time: {elapsed_time/3600:.2f} hours ({elapsed_time/60:.1f} minutes)\")\n    print(f\"\\n\ud83c\udfc6 Best Model: {result['best_model_name']}\")\n    print(f\"   Test R\u00b2 Score:  {result['best_score']:.4f}\")\n    print(f\"   Test MAE:       {result['best_mae']:.2f}\")\n    print(f\"   Test RMSE:      {result['best_rmse']:.2f}\")\n    \n    print(f\"\\n\ud83d\udcca Top 5 Models:\")\n    sorted_models = sorted(result['all_scores'].items(), \n                          key=lambda x: x[1]['r2'], reverse=True)\n    for i, (name, scores) in enumerate(sorted_models[:5], 1):\n        print(f\"   {i}. {name:25s} R\u00b2={scores['r2']:.4f}  MAE={scores['mae']:.2f}  RMSE={scores['rmse']:.2f}\")\n    \n    # Check if target achieved\n    if result['best_score'] >= 0.90:\n        print(f\"\\n\u2705 TARGET ACHIEVED! R\u00b2 = {result['best_score']:.4f} >= 0.90\")\n    else:\n        print(f\"\\n\u26a0\ufe0f  Target not quite reached. R\u00b2 = {result['best_score']:.4f} < 0.90\")\n        print(f\"   Consider: More trials, more data, or feature engineering\")\n    \n    # Save for next cells\n    TRAINED_MODEL = result['best_model']\n    TRAINING_RESULT = result\n    \n    print(\"\\n\ud83d\udcbe Saving models...\")\n    \n    # Save best model\n    import joblib\n    \n    model_package = {\n        'model': result['best_model'],\n        'model_name': result['best_model_name'],\n        'feature_names': FEATURE_NAMES,\n        'metrics': {\n            'test_r2': float(result['best_score']),\n            'test_mae': float(result['best_mae']),\n            'test_rmse': float(result['best_rmse'])\n        },\n        'training_config': {\n            'optimize': OPTIMIZE,\n            'n_trials': N_TRIALS if OPTIMIZE else None,\n            'platform': 'Kaggle',\n            'gpu': gpu_info if HAS_GPU else 'CPU'\n        },\n        'timestamp': datetime.now().isoformat(),\n        'data_shape': {\n            'train_samples': len(X_train),\n            'test_samples': len(X_test),\n            'n_features': X_train.shape[1]\n        },\n        'hyperparameters': result.get('hyperparameters'),\n        'all_model_scores': result['all_scores']\n    }\n    \n    model_path = MODELS_DIR / 'best_model_production.pkl'\n    joblib.dump(model_package, model_path)\n    print(f\"\u2705 Best model saved: {model_path}\")\n    print(f\"   Size: {model_path.stat().st_size / (1024*1024):.2f} MB\")\n    \n    # Save all models\n    all_models_path = MODELS_DIR / 'all_models_production.pkl'\n    joblib.dump(result, all_models_path)\n    print(f\"\u2705 All models saved: {all_models_path}\")\n    print(f\"   Includes: {len(result['trained_models'])} base + {len(result['ensemble_models'])} ensemble models\")\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"\ud83c\udfaf Next: Run Cell 7 to evaluate and visualize results!\")\n    print(\"=\"*80)\n    \nexcept Exception as e:\n    # Stop GPU monitoring on error\n    if gpu_monitor:\n        gpu_monitor.stop()\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"\u274c TRAINING FAILED\")\n    print(\"=\"*80)\n    print(f\"Error Type: {type(e).__name__}\")\n    print(f\"Error Message: {str(e)}\")\n    print(\"\\n\ud83d\udccb Troubleshooting:\")\n    print(\"1. Check data has enough samples (6000+ \u2713)\")\n    print(\"2. Check features are all numeric (should be \u2713 from Cell 5)\")\n    print(\"3. Check GPU/CPU settings\")\n    print(\"4. Check memory - try reducing N_TRIALS if OOM\")\n    print(\"5. Check Kaggle time limit (9 hours)\")\n    \n    import traceback\n    print(\"\\n\ud83d\udd0d Full traceback:\")\n    traceback.print_exc()\n    \n    raise"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcc8 Cell 7: Evaluate Model & Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"\ud83d\udcca Evaluating model...\\n\")\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = TRAINED_MODEL.predict(X_train)\n",
    "y_test_pred = TRAINED_MODEL.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "# Print results\n",
    "print(\"=\" * 70)\n",
    "print(\"\ud83d\udcca FINAL MODEL EVALUATION (Trained on Kaggle P100)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nTraining Set:\")\n",
    "print(f\"  R\u00b2 Score:  {train_r2:.4f}\")\n",
    "print(f\"  MAE:       {train_mae:.4f}\")\n",
    "print(f\"  RMSE:      {train_rmse:.4f}\")\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  R\u00b2 Score:  {test_r2:.4f}\")\n",
    "print(f\"  MAE:       {test_mae:.4f}\")\n",
    "print(f\"  RMSE:      {test_rmse:.4f}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Save comprehensive model package\n",
    "print(\"\\n\ud83d\udcbe Saving final model package...\")\n",
    "\n",
    "model_package = {\n",
    "    'model': TRAINED_MODEL,\n",
    "    'model_type': MODEL_TYPE,\n",
    "    'feature_names': FEATURE_NAMES,\n",
    "    'metrics': {\n",
    "        'train_r2': float(train_r2),\n",
    "        'test_r2': float(test_r2),\n",
    "        'train_mae': float(train_mae),\n",
    "        'test_mae': float(test_mae),\n",
    "        'train_rmse': float(train_rmse),\n",
    "        'test_rmse': float(test_rmse)\n",
    "    },\n",
    "    'training_config': {\n",
    "        'total_epochs': TOTAL_EPOCHS,\n",
    "        'model_params': model_params if 'model_params' in locals() else None,\n",
    "        'platform': 'Kaggle',\n",
    "        'gpu': 'P100'\n",
    "    },\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'trained_on': 'Kaggle (P100 GPU)',\n",
    "    'data_shape': {\n",
    "        'n_samples': len(X),\n",
    "        'n_features': len(FEATURE_NAMES),\n",
    "        'train_size': len(X_train),\n",
    "        'test_size': len(X_test)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save to /kaggle/working (will be saved with notebook commit)\n",
    "final_model_path = MODELS_DIR / 'final_model_kaggle.pkl'\n",
    "joblib.dump(model_package, final_model_path)\n",
    "\n",
    "print(f\"\u2705 Model package saved to: {final_model_path}\")\n",
    "print(f\"   Size: {final_model_path.stat().st_size / (1024*1024):.2f} MB\")\n",
    "\n",
    "# Save evaluation report\n",
    "report_path = RESULTS_DIR / 'evaluation_report_kaggle.txt'\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(\"ML Phone Number Price Prediction - Kaggle P100 Evaluation\\n\")\n",
    "    f.write(\"=\" * 70 + \"\\n\\n\")\n",
    "    f.write(f\"Model Type: {MODEL_TYPE}\\n\")\n",
    "    f.write(f\"Training Platform: Kaggle (P100 GPU)\\n\")\n",
    "    f.write(f\"Training Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "    f.write(\"Training Set Metrics:\\n\")\n",
    "    f.write(f\"  R\u00b2 Score:  {train_r2:.4f}\\n\")\n",
    "    f.write(f\"  MAE:       {train_mae:.4f}\\n\")\n",
    "    f.write(f\"  RMSE:      {train_rmse:.4f}\\n\\n\")\n",
    "    f.write(\"Test Set Metrics:\\n\")\n",
    "    f.write(f\"  R\u00b2 Score:  {test_r2:.4f}\\n\")\n",
    "    f.write(f\"  MAE:       {test_mae:.4f}\\n\")\n",
    "    f.write(f\"  RMSE:      {test_rmse:.4f}\\n\")\n",
    "\n",
    "print(f\"\u2705 Report saved to: {report_path}\")\n",
    "\n",
    "print(\"\\n\u2705 All results saved to /kaggle/working!\")\n",
    "print(\"\\n\ud83d\udca1 Tip: Commit this notebook to save all outputs permanently!\")\n",
    "print(\"   (Kaggle auto-commits every version)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udce5 Cell 8: Commit Notebook to Save Results\n",
    "\n",
    "**Important:** Kaggle notebooks need to be committed to save outputs permanently!\n",
    "\n",
    "Click \"Save Version\" (top right) to commit:\n",
    "- Notebook code\n",
    "- All outputs in /kaggle/working\n",
    "- Checkpoints\n",
    "- Models\n",
    "- Results\n",
    "\n",
    "After commit, you can:\n",
    "- Download outputs\n",
    "- Share notebook\n",
    "- Fork for next session (to resume training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Summary of files to commit\nprint(\"\ud83d\udce6 Files in /kaggle/working (will be saved on commit):\\n\")\n\nimport os\nfrom pathlib import Path\n\n# \u2705 FIX: Show files from /kaggle/working directly (where they actually persist!)\nworking_dir = Path('/kaggle/working')\n\nfor root, dirs, files in os.walk(working_dir):\n    # Skip hidden directories and Python cache\n    dirs[:] = [d for d in dirs if not d.startswith('.') and d != '__pycache__']\n    \n    level = root.replace(str(working_dir), '').count(os.sep)\n    indent = ' ' * 2 * level\n    folder_name = os.path.basename(root) or 'working'\n    print(f\"{indent}{folder_name}/\")\n    subindent = ' ' * 2 * (level + 1)\n    for file in sorted(files)[:10]:  # Limit to first 10 files per folder\n        if file.startswith('.'):  # Skip hidden files\n            continue\n        file_path = os.path.join(root, file)\n        size_mb = os.path.getsize(file_path) / (1024 * 1024)\n        print(f\"{subindent}{file} ({size_mb:.2f} MB)\")\n    if len(files) > 10:\n        print(f\"{subindent}... and {len(files) - 10} more files\")\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"\ud83c\udf89 TRAINING COMPLETE ON KAGGLE!\")\nprint(\"=\" * 70)\nprint(\"\\n\u2705 Next steps:\")\nprint(\"1. Click 'Save Version' (top right) to commit notebook\")\nprint(\"2. All files in /kaggle/working will be saved\")\nprint(\"3. You can download model after commit\")\nprint(\"4. To continue training: Fork this notebook \u2192 Run Cell 1-6\")\nprint(\"\\n\ud83c\udfc6 Advantages of Kaggle over Colab:\")\nprint(\"   - P100 GPU (~30% faster than T4)\")\nprint(\"   - More RAM (16-30 GB vs 12 GB)\")\nprint(\"   - More stable (less disconnects)\")\nprint(\"   - Auto-commit (permanent save)\")\nprint(\"   - Unlimited dataset storage\")\nprint(\"\\n\ud83d\udcbe Checkpoint Persistence:\")\nprint(\"   \u2705 Checkpoints saved to /kaggle/working/checkpoints/\")\nprint(\"   \u2705 Models saved to /kaggle/working/models/\")\nprint(\"   \u2705 Session timeout \u2192 Fork \u2192 Auto-resume from last checkpoint!\")\nprint(\"   \u2705 NO MORE RE-TRAINING FROM SCRATCH! \ud83c\udf89\")\nprint(\"\\n\" + \"=\" * 70)\n\nprint(\"\\n\ud83c\udfaf Training completed successfully on Kaggle P100!\")\nif 'test_r2' in locals():\n    print(f\"   Final R\u00b2 Score: {test_r2:.4f}\")\nprint(\"\\n\ud83d\ude80 Happy training!\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}