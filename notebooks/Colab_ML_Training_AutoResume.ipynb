{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üöÄ ML Phone Number Price Prediction - Colab Auto-Resume Training\n",
    "\n",
    "**Features:**\n",
    "- ‚úÖ Auto-save checkpoints to Google Drive every 10 epochs\n",
    "- ‚úÖ Auto-resume from last checkpoint after disconnection\n",
    "- ‚úÖ Zero data loss (all progress saved to Drive)\n",
    "- ‚úÖ Reconnect-proof training\n",
    "\n",
    "**How to Use:**\n",
    "1. Run Cell 1-4 sequentially\n",
    "2. Cell 4 will auto-detect if there's a checkpoint\n",
    "3. If found ‚Üí Resume from last epoch\n",
    "4. If not found ‚Üí Start fresh\n",
    "5. Training auto-saves every 10 epochs to Drive\n",
    "\n",
    "**If disconnected:**\n",
    "- Just reconnect and run Cell 1-4 again\n",
    "- Training will resume from last saved checkpoint!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cell1_header"
   },
   "source": [
    "## üìÇ Cell 1: Mount Google Drive & Setup Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell1"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# Project directory in Google Drive\n",
    "PROJECT_NAME = 'ML_Phone_Number_Project'\n",
    "PROJECT_DIR = f'/content/drive/MyDrive/{PROJECT_NAME}'\n",
    "\n",
    "# Create project directories\n",
    "import os\n",
    "directories = [\n",
    "    f'{PROJECT_DIR}/checkpoints',\n",
    "    f'{PROJECT_DIR}/models',\n",
    "    f'{PROJECT_DIR}/logs',\n",
    "    f'{PROJECT_DIR}/results',\n",
    "    f'{PROJECT_DIR}/data'\n",
    "]\n",
    "\n",
    "for dir_path in directories:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    \n",
    "print(\"‚úÖ Google Drive mounted successfully!\")\n",
    "print(f\"üìÅ Project directory: {PROJECT_DIR}\")\n",
    "print(\"\\nüìÇ Created directories:\")\n",
    "for dir_path in directories:\n",
    "    print(f\"   - {dir_path}\")\n",
    "\n",
    "# Change to project directory\n",
    "%cd /content\n",
    "print(f\"\\n‚úÖ Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cell2_header"
   },
   "source": [
    "## üì¶ Cell 2: Upload & Extract Project Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell2"
   },
   "outputs": [],
   "source": [
    "# Option 1: Upload ZIP file manually\n",
    "print(\"üì§ Upload Options:\")\n",
    "print(\"   Option A: Upload ZIP file from your computer\")\n",
    "print(\"   Option B: Download from GitHub/URL\")\n",
    "print(\"\")\n",
    "\n",
    "# Choose your option:\n",
    "USE_MANUAL_UPLOAD = True  # Set to False to use GitHub URL\n",
    "\n",
    "if USE_MANUAL_UPLOAD:\n",
    "    # Upload manually\n",
    "    from google.colab import files\n",
    "    print(\"Please upload the project ZIP file...\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    # Get uploaded filename\n",
    "    zip_filename = list(uploaded.keys())[0]\n",
    "    print(f\"‚úÖ Uploaded: {zip_filename}\")\n",
    "else:\n",
    "    # Download from URL\n",
    "    GITHUB_URL = \"YOUR_GITHUB_RELEASE_URL_HERE.zip\"  # Update this!\n",
    "    zip_filename = \"project.zip\"\n",
    "    !wget -O {zip_filename} \"{GITHUB_URL}\"\n",
    "    print(f\"‚úÖ Downloaded: {zip_filename}\")\n",
    "\n",
    "# Extract ZIP\n",
    "print(\"\\nüì¶ Extracting project files...\")\n",
    "!unzip -o {zip_filename} -d /content/\n",
    "\n",
    "# Change to project directory\n",
    "import os\n",
    "if os.path.exists('/content/number-ML'):\n",
    "    %cd /content/number-ML\n",
    "    print(\"‚úÖ Project extracted successfully!\")\n",
    "    print(f\"üìÅ Current directory: {os.getcwd()}\")\n",
    "else:\n",
    "    print(\"‚ùå Project directory not found. Check ZIP structure.\")\n",
    "\n",
    "# List files\n",
    "print(\"\\nüìÇ Project structure:\")\n",
    "!ls -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cell3_header"
   },
   "source": [
    "## üîß Cell 3: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell3"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "print(\"üì¶ Installing dependencies...\")\n",
    "print(\"This may take 2-5 minutes...\\n\")\n",
    "\n",
    "!pip install -q --upgrade pip\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "# Verify imports\n",
    "print(\"\\n‚úÖ Verifying imports...\")\n",
    "try:\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import sklearn\n",
    "    import xgboost as xgb\n",
    "    import lightgbm as lgb\n",
    "    import catboost\n",
    "    import optuna\n",
    "    print(\"   ‚úì numpy:\", np.__version__)\n",
    "    print(\"   ‚úì pandas:\", pd.__version__)\n",
    "    print(\"   ‚úì scikit-learn:\", sklearn.__version__)\n",
    "    print(\"   ‚úì xgboost:\", xgb.__version__)\n",
    "    print(\"   ‚úì lightgbm:\", lgb.__version__)\n",
    "    print(\"   ‚úì catboost:\", catboost.__version__)\n",
    "    print(\"   ‚úì optuna:\", optuna.__version__)\n",
    "    print(\"\\n‚úÖ All dependencies installed successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "    print(\"Please check requirements.txt and try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cell4_header"
   },
   "source": [
    "## üîç Cell 4: Auto-Detect Checkpoint & Setup Auto-Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell4"
   },
   "outputs": [],
   "source": [
    "# Import checkpoint manager\n",
    "import sys\n",
    "sys.path.insert(0, '/content/number-ML')\n",
    "\n",
    "from src.checkpoint_manager import CheckpointManager\n",
    "\n",
    "# Initialize checkpoint manager\n",
    "CHECKPOINT_DIR = f\"{PROJECT_DIR}/checkpoints\"\n",
    "checkpoint_manager = CheckpointManager(\n",
    "    checkpoint_dir=CHECKPOINT_DIR,\n",
    "    max_checkpoints=5,\n",
    "    save_every=10\n",
    ")\n",
    "\n",
    "# Check for existing checkpoint\n",
    "print(\"üîç Checking for existing checkpoint...\\n\")\n",
    "checkpoint = checkpoint_manager.load_latest_checkpoint()\n",
    "\n",
    "if checkpoint:\n",
    "    RESUME_MODE = True\n",
    "    START_EPOCH = checkpoint['epoch'] + 1\n",
    "    PREVIOUS_METRICS = checkpoint.get('metrics', {})\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"üîÑ RESUME MODE ACTIVATED\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Last completed epoch: {checkpoint['epoch']}\")\n",
    "    print(f\"Will resume from epoch: {START_EPOCH}\")\n",
    "    print(f\"Checkpoint timestamp: {checkpoint['timestamp']}\")\n",
    "    print(\"\\nPrevious metrics:\")\n",
    "    for key, value in PREVIOUS_METRICS.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Print recovery info if available\n",
    "    print(\"\\n\")\n",
    "    checkpoint_manager.print_recovery_info()\n",
    "    \n",
    "else:\n",
    "    RESUME_MODE = False\n",
    "    START_EPOCH = 0\n",
    "    PREVIOUS_METRICS = {}\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"üÜï FRESH START MODE\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"No checkpoint found.\")\n",
    "    print(\"Will start training from epoch 0.\")\n",
    "    print(\"Checkpoints will be saved to Google Drive every 10 epochs.\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n‚úÖ Auto-resume setup complete!\")\n",
    "print(f\"Resume mode: {RESUME_MODE}\")\n",
    "print(f\"Start epoch: {START_EPOCH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cell5_header"
   },
   "source": [
    "## üìä Cell 5: Load Data & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell5"
   },
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "from src.data_handler import load_and_clean_data\n",
    "from src.features import create_masterpiece_features\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"üìÇ Loading data...\")\n",
    "\n",
    "# Load data (adjust path as needed)\n",
    "# Option 1: From project data folder\n",
    "DATA_PATH = 'data/raw/numberdata.csv'\n",
    "\n",
    "# Option 2: From Google Drive\n",
    "# DATA_PATH = f'{PROJECT_DIR}/data/numberdata.csv'\n",
    "\n",
    "# Load and clean\n",
    "df = load_and_clean_data(DATA_PATH)\n",
    "print(f\"‚úÖ Loaded {len(df)} records\")\n",
    "print(f\"   Columns: {list(df.columns)}\")\n",
    "\n",
    "# Feature engineering\n",
    "print(\"\\nüîß Creating features...\")\n",
    "df_features = create_masterpiece_features(df)\n",
    "print(f\"‚úÖ Created {len(df_features.columns)} features\")\n",
    "\n",
    "# Prepare X and y\n",
    "feature_cols = [col for col in df_features.columns if col not in ['phone_number', 'price']]\n",
    "X = df_features[feature_cols].values\n",
    "y = df_features['price'].values\n",
    "\n",
    "print(f\"\\nüìä Dataset shape:\")\n",
    "print(f\"   Features (X): {X.shape}\")\n",
    "print(f\"   Target (y): {y.shape}\")\n",
    "\n",
    "# Train/test split\n",
    "print(\"\\n‚úÇÔ∏è Splitting train/test...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"   Train: {X_train.shape}\")\n",
    "print(f\"   Test: {X_test.shape}\")\n",
    "\n",
    "# Save feature names for later\n",
    "FEATURE_NAMES = feature_cols\n",
    "\n",
    "print(\"\\n‚úÖ Data preparation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cell6_header"
   },
   "source": [
    "## üöÄ Cell 6: Train with Auto-Checkpoint & Auto-Resume\n",
    "\n",
    "**This cell will:**\n",
    "- Resume from checkpoint if found (Cell 4)\n",
    "- Train model with auto-save every 10 epochs\n",
    "- Save checkpoints to Google Drive\n",
    "- If disconnected, just run Cell 1-6 again ‚Üí Resume automatically!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell6"
   },
   "outputs": [],
   "source": [
    "from src.train_colab import train_with_auto_resume\n",
    "\n",
    "# Training configuration\n",
    "TOTAL_EPOCHS = 100  # Adjust as needed\n",
    "MODEL_TYPE = 'xgboost'  # Options: 'xgboost', 'lightgbm', 'catboost', 'random_forest'\n",
    "SAVE_EVERY = 10  # Save checkpoint every N epochs\n",
    "\n",
    "# Model parameters (adjust as needed)\n",
    "model_params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'n_estimators': 500,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üöÄ TRAINING WITH AUTO-CHECKPOINT & AUTO-RESUME\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Model type: {MODEL_TYPE}\")\n",
    "print(f\"Total epochs: {TOTAL_EPOCHS}\")\n",
    "print(f\"Save every: {SAVE_EVERY} epochs\")\n",
    "print(f\"Resume mode: {RESUME_MODE}\")\n",
    "if RESUME_MODE:\n",
    "    print(f\"Starting from epoch: {START_EPOCH}\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\")\n",
    "\n",
    "# Train with auto-resume\n",
    "result = train_with_auto_resume(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_test,\n",
    "    y_val=y_test,\n",
    "    model_type=MODEL_TYPE,\n",
    "    checkpoint_dir=CHECKPOINT_DIR,\n",
    "    project_dir=PROJECT_DIR,\n",
    "    total_epochs=TOTAL_EPOCHS,\n",
    "    save_every=SAVE_EVERY,\n",
    "    params=model_params\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ TRAINING COMPLETE!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Final R¬≤ Score: {result['metrics']['r2_score']:.4f}\")\n",
    "print(f\"Best R¬≤ Score: {result['best_score']:.4f}\")\n",
    "print(f\"Final Train Loss: {result['metrics']['train_loss']:.4f}\")\n",
    "print(f\"Final Val Loss: {result['metrics']['val_loss']:.4f}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Save result for next cell\n",
    "TRAINED_MODEL = result['model']\n",
    "TRAINING_METRICS = result['metrics']\n",
    "\n",
    "print(\"\\nüíæ Model and checkpoints saved to Google Drive:\")\n",
    "print(f\"   {PROJECT_DIR}/checkpoints/\")\n",
    "print(f\"   {PROJECT_DIR}/models/\")\n",
    "print(\"\\n‚úÖ Safe to disconnect now! Progress is saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cell7_header"
   },
   "source": [
    "## üìà Cell 7: Evaluate Model & Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell7"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"üìä Evaluating model...\\n\")\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = TRAINED_MODEL.predict(X_train)\n",
    "y_test_pred = TRAINED_MODEL.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "# Print results\n",
    "print(\"=\" * 60)\n",
    "print(\"üìä FINAL MODEL EVALUATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTraining Set:\")\n",
    "print(f\"  R¬≤ Score:  {train_r2:.4f}\")\n",
    "print(f\"  MAE:       {train_mae:.4f}\")\n",
    "print(f\"  RMSE:      {train_rmse:.4f}\")\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  R¬≤ Score:  {test_r2:.4f}\")\n",
    "print(f\"  MAE:       {test_mae:.4f}\")\n",
    "print(f\"  RMSE:      {test_rmse:.4f}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save comprehensive model package\n",
    "print(\"\\nüíæ Saving final model package...\")\n",
    "\n",
    "model_package = {\n",
    "    'model': TRAINED_MODEL,\n",
    "    'model_type': MODEL_TYPE,\n",
    "    'feature_names': FEATURE_NAMES,\n",
    "    'metrics': {\n",
    "        'train_r2': float(train_r2),\n",
    "        'test_r2': float(test_r2),\n",
    "        'train_mae': float(train_mae),\n",
    "        'test_mae': float(test_mae),\n",
    "        'train_rmse': float(train_rmse),\n",
    "        'test_rmse': float(test_rmse)\n",
    "    },\n",
    "    'training_config': {\n",
    "        'total_epochs': TOTAL_EPOCHS,\n",
    "        'model_params': model_params if 'model_params' in locals() else None\n",
    "    },\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'trained_on': 'Google Colab',\n",
    "    'data_shape': {\n",
    "        'n_samples': len(X),\n",
    "        'n_features': len(FEATURE_NAMES),\n",
    "        'train_size': len(X_train),\n",
    "        'test_size': len(X_test)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save to Google Drive\n",
    "final_model_path = f\"{PROJECT_DIR}/models/final_model_complete.pkl\"\n",
    "joblib.dump(model_package, final_model_path)\n",
    "\n",
    "print(f\"‚úÖ Model package saved to: {final_model_path}\")\n",
    "\n",
    "# Save evaluation report\n",
    "report_path = f\"{PROJECT_DIR}/results/evaluation_report.txt\"\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(\"ML Phone Number Price Prediction - Evaluation Report\\n\")\n",
    "    f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "    f.write(f\"Model Type: {MODEL_TYPE}\\n\")\n",
    "    f.write(f\"Training Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "    f.write(\"Training Set Metrics:\\n\")\n",
    "    f.write(f\"  R¬≤ Score:  {train_r2:.4f}\\n\")\n",
    "    f.write(f\"  MAE:       {train_mae:.4f}\\n\")\n",
    "    f.write(f\"  RMSE:      {train_rmse:.4f}\\n\\n\")\n",
    "    f.write(\"Test Set Metrics:\\n\")\n",
    "    f.write(f\"  R¬≤ Score:  {test_r2:.4f}\\n\")\n",
    "    f.write(f\"  MAE:       {test_mae:.4f}\\n\")\n",
    "    f.write(f\"  RMSE:      {test_rmse:.4f}\\n\")\n",
    "\n",
    "print(f\"‚úÖ Report saved to: {report_path}\")\n",
    "print(\"\\n‚úÖ All results saved to Google Drive!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cell8_header"
   },
   "source": [
    "## üì• Cell 8: Download Final Model (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell8"
   },
   "outputs": [],
   "source": [
    "# Download final model to local machine\n",
    "from google.colab import files\n",
    "\n",
    "print(\"üì• Downloading final model...\\n\")\n",
    "\n",
    "# Download model\n",
    "model_path = f\"{PROJECT_DIR}/models/final_model_complete.pkl\"\n",
    "files.download(model_path)\n",
    "\n",
    "print(\"‚úÖ Model downloaded!\")\n",
    "print(\"\\nüìÇ Files in Google Drive:\")\n",
    "print(f\"   Models: {PROJECT_DIR}/models/\")\n",
    "print(f\"   Checkpoints: {PROJECT_DIR}/checkpoints/\")\n",
    "print(f\"   Results: {PROJECT_DIR}/results/\")\n",
    "print(f\"   Logs: {PROJECT_DIR}/logs/\")\n",
    "\n",
    "print(\"\\nüéâ Training complete! All files safely stored in Google Drive.\")\n",
    "print(\"\\n‚ÑπÔ∏è  You can reconnect anytime and resume training from last checkpoint!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Colab_ML_Training_AutoResume.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
