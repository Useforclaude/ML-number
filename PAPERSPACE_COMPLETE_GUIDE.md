# ðŸ“˜ Paperspace Complete Guide - Step by Step

**Created**: 2025-10-06
**For**: ML Phone Number Training on Paperspace
**Time needed**: ~25 minutes setup + 9-12 hours training

---

## ðŸŽ¯ Overview

à¸„à¸¹à¹ˆà¸¡à¸·à¸­à¸™à¸µà¹‰à¸ˆà¸°à¸žà¸²à¸„à¸¸à¸“à¸•à¸±à¹‰à¸‡à¹à¸•à¹ˆ:
1. Login Paperspace
2. Create/Open Notebook
3. Setup environment
4. Fix dependencies
5. Upload data
6. Run training in Jupyter Lab

**à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢**: à¹€à¸£à¸´à¹ˆà¸¡ training à¸šà¸™ Paperspace à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸£à¸­ Kaggle

---

## ðŸ“‹ STEP 1: Login & Open Paperspace

### 1.1 Login
- à¹„à¸›à¸—à¸µà¹ˆ: https://console.paperspace.com/
- Login à¸”à¹‰à¸§à¸¢ account

### 1.2 Navigate to Notebooks
```
Console â†’ Gradient â†’ Notebooks
```

### 1.3 Check Existing Notebooks
**à¸–à¹‰à¸²à¸¡à¸µ notebook à¸­à¸¢à¸¹à¹ˆà¹à¸¥à¹‰à¸§:**
- à¸„à¸¥à¸´à¸ "Open" â†’ à¸‚à¹‰à¸²à¸¡à¹„à¸› STEP 3

**à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µ:**
- à¸—à¸³ STEP 2 à¸•à¹ˆà¸­

---

## ðŸ“‹ STEP 2: Create New Notebook (Optional)

### 2.1 Click "Create Notebook"

### 2.2 Configuration

**Machine Type:**
```
Free tier:
  âœ… Free-GPU (Quadro M4000) â† à¹€à¸¥à¸·à¸­à¸à¸™à¸µà¹‰

Pro tier (à¸–à¹‰à¸²à¸ˆà¹ˆà¸²à¸¢ $8/month):
  â­ P4000 (8GB VRAM)
  â­ P5000 (16GB VRAM)
```

**Container:**
```
Recommended:
  - Fast.ai (à¸¡à¸µ PyTorch, Jupyter, GPU drivers)

Alternative:
  - PyTorch
  - TensorFlow
```

**Workspace:**
```
None (à¹€à¸£à¸²à¸ˆà¸° clone à¸ˆà¸²à¸ GitHub)
```

**Advanced Options:**
```
Auto-shutdown:
  - Free: 6 hours (à¸ˆà¸°à¸›à¸´à¸”à¹€à¸­à¸‡)
  - Pro: Never / Custom (à¸•à¸±à¹‰à¸‡à¹€à¸­à¸‡à¹„à¸”à¹‰)

Persistent Storage:
  - Free: 5 GB (/storage)
  - Pro: 50 GB (/storage)
```

### 2.3 Start Notebook
- à¸„à¸¥à¸´à¸ "Start Notebook"
- à¸£à¸­ 2-5 à¸™à¸²à¸—à¸µ
- à¸ªà¸–à¸²à¸™à¸°à¸ˆà¸°à¹€à¸›à¹‡à¸™: "Running" (à¸ªà¸µà¹€à¸‚à¸µà¸¢à¸§)

### 2.4 Open Jupyter
- à¸„à¸¥à¸´à¸ "Open"
- à¸ˆà¸°à¹€à¸›à¸´à¸” Jupyter Lab (à¸«à¸£à¸·à¸­ Notebook)

---

## ðŸ“‹ STEP 3: Open Terminal in Jupyter

### à¸§à¸´à¸˜à¸µà¸—à¸µà¹ˆ 1 - Jupyter Lab (Modern UI):
```
File â†’ New â†’ Terminal
```

### à¸§à¸´à¸˜à¸µà¸—à¸µà¹ˆ 2 - Jupyter Notebook (Classic UI):
```
New (à¸‚à¸§à¸²à¸šà¸™) â†’ Terminal
```

**à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ:**
- à¸ˆà¸°à¹€à¸«à¹‡à¸™à¸«à¸™à¹‰à¸²à¸ˆà¸­ terminal à¸ªà¸µà¸”à¸³
- à¸žà¸£à¹‰à¸­à¸¡à¸žà¸´à¸¡à¸žà¹Œà¸„à¸³à¸ªà¸±à¹ˆà¸‡

---

## ðŸ“‹ STEP 4: Clone Project & Setup

### 4.1 Check GPU (Optional)
```bash
nvidia-smi
```

**à¸„à¸§à¸£à¹€à¸«à¹‡à¸™:**
```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.xx       Driver Version: 525.xx       CUDA Version: 12.0    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Quadro M4000        Off  | 00000000:00:05.0 Off |                  N/A |
| 46%   42C    P0    32W / 120W |      0MiB /  8192MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
```

### 4.2 Clone Project from GitHub
```bash
cd /storage
git clone https://github.com/Useforclaude/ML-number.git
cd ML-number
```

**à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š:**
```bash
pwd
# Expected: /storage/ML-number

ls -la
# à¸„à¸§à¸£à¹€à¸«à¹‡à¸™: src/, requirements.txt, README.md, etc.

ls src/
# à¸„à¸§à¸£à¹€à¸«à¹‡à¸™ 17 files: config.py, model_utils.py, etc.
```

---

## ðŸ“‹ STEP 5: Fix Dependencies

### 5.1 Fix blinker conflict
```bash
pip install --ignore-installed blinker
```

**Expected output:**
```
Successfully installed blinker-1.9.0
```

### 5.2 Install ML Libraries (Essential 3)
```bash
pip install lightgbm==3.3.5
pip install catboost==1.2.8
pip install optuna==3.6.2
```

**Each should show:**
```
Successfully installed lightgbm-3.3.5
Successfully installed catboost-1.2.8
Successfully installed optuna-3.6.2
```

### 5.3 Validate Installation
```bash
python -c "import lightgbm; print('âœ… LightGBM OK')"
python -c "import catboost; print('âœ… CatBoost OK')"
python -c "import optuna; print('âœ… Optuna OK')"
python -c "import xgboost; print('âœ… XGBoost OK')"
python -c "import sklearn; print('âœ… scikit-learn OK')"
```

**à¸•à¹‰à¸­à¸‡à¹€à¸«à¹‡à¸™à¸—à¸±à¹‰à¸‡ 5 âœ…:**
```
âœ… LightGBM OK
âœ… CatBoost OK
âœ… Optuna OK
âœ… XGBoost OK
âœ… scikit-learn OK
```

### 5.4 Install Remaining Dependencies (Optional)
```bash
pip install -r requirements.txt
```

à¸–à¹‰à¸²à¸¡à¸µ error â†’ à¸‚à¹‰à¸²à¸¡à¹„à¸”à¹‰ à¹€à¸žà¸£à¸²à¸°à¸‚à¸­à¸‡à¸ªà¸³à¸„à¸±à¸à¸•à¸´à¸”à¹à¸¥à¹‰à¸§ (5.2)

---

## ðŸ“‹ STEP 6: Upload Data File

### 6.1 Create data directory
```bash
mkdir -p /storage/ML-number/data/raw
```

### 6.2 Upload numberdata.csv

**à¸§à¸´à¸˜à¸µà¸—à¸µà¹ˆ 1 - à¹ƒà¸Šà¹‰ Jupyter UI (à¹à¸™à¸°à¸™à¸³!):**

**à¹ƒà¸™ Jupyter Lab:**
```
1. à¸‹à¹‰à¸²à¸¢à¸¡à¸·à¸­: à¸„à¸¥à¸´à¸ Folder icon ðŸ“
2. Navigate: /storage/ML-number/data/raw/
   (à¸„à¸¥à¸´à¸ storage â†’ ML-number â†’ data â†’ raw)
3. à¸„à¸¥à¸´à¸à¸‚à¸§à¸²à¹ƒà¸™à¸žà¸·à¹‰à¸™à¸—à¸µà¹ˆà¸§à¹ˆà¸²à¸‡ â†’ Upload Files
4. à¹€à¸¥à¸·à¸­à¸à¹„à¸Ÿà¸¥à¹Œ: numberdata.csv (à¸ˆà¸²à¸à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸„à¸¸à¸“)
5. à¸£à¸­ upload bar à¹€à¸ªà¸£à¹‡à¸ˆ (à¸„à¸§à¸£à¹€à¸›à¹‡à¸™ ~93 KB)
```

**à¹ƒà¸™ Jupyter Notebook (Classic):**
```
1. Navigate to: /storage/ML-number/data/raw/
2. à¸„à¸¥à¸´à¸ "Upload" (à¸‚à¸§à¸²à¸šà¸™)
3. à¹€à¸¥à¸·à¸­à¸ numberdata.csv
4. à¸„à¸¥à¸´à¸ "Upload" (à¸ªà¸µà¸Ÿà¹‰à¸²) à¸­à¸µà¸à¸„à¸£à¸±à¹‰à¸‡à¹€à¸žà¸·à¹ˆà¸­ confirm
```

**à¸§à¸´à¸˜à¸µà¸—à¸µà¹ˆ 2 - à¹ƒà¸Šà¹‰ Terminal (à¸–à¹‰à¸²à¹„à¸Ÿà¸¥à¹Œà¸­à¸¢à¸¹à¹ˆà¸—à¸µà¹ˆà¸­à¸·à¹ˆà¸™):**
```bash
cd /storage/ML-number/data/raw/

# Option A: Download from URL
wget https://your-url.com/numberdata.csv

# Option B: Copy from /tmp (à¸–à¹‰à¸² upload via Jupyter root)
cp /tmp/numberdata.csv .

# Option C: From local mounted drive (à¸–à¹‰à¸²à¸¡à¸µ)
cp /path/to/your/numberdata.csv .
```

### 6.3 Verify Data File
```bash
ls -lh /storage/ML-number/data/raw/numberdata.csv
```

**à¸„à¸§à¸£à¹€à¸«à¹‡à¸™:**
```
-rw-r--r-- 1 root root 93K Oct  6 12:00 numberdata.csv
```

**à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹€à¸™à¸·à¹‰à¸­à¸«à¸²:**
```bash
head -5 /storage/ML-number/data/raw/numberdata.csv
```

**à¸„à¸§à¸£à¹€à¸«à¹‡à¸™:**
```
phone_number,price
0812345678,5000
0899999999,150000
...
```

**à¸™à¸±à¸šà¸ˆà¸³à¸™à¸§à¸™à¹à¸–à¸§:**
```bash
wc -l /storage/ML-number/data/raw/numberdata.csv
```

**à¸„à¸§à¸£à¹€à¸«à¹‡à¸™:**
```
6113 numberdata.csv  (6112 rows + 1 header)
```

---

## ðŸ“‹ STEP 7: Create Training Notebook

### 7.1 Create New Notebook

**à¹ƒà¸™ Jupyter Lab:**
```
File â†’ New â†’ Notebook
Kernel: à¹€à¸¥à¸·à¸­à¸ "Python 3"
Save as: /storage/ML-number/train_paperspace.ipynb
```

**à¹ƒà¸™ Jupyter Notebook:**
```
New â†’ Python 3
Rename: train_paperspace
```

### 7.2 Cell 1 - Setup Environment
```python
import sys
import os

# Add project to Python path
sys.path.insert(0, '/storage/ML-number')

print("="*80)
print("ðŸ”§ ENVIRONMENT SETUP")
print("="*80)

# Verify path
print(f"âœ… Python path: {sys.path[0]}")
print(f"âœ… Working dir: {os.getcwd()}")

# Test imports
try:
    from src.config import BASE_PATH, MODEL_CONFIG
    from src.environment import get_config_for_environment

    env_config = get_config_for_environment()
    print(f"âœ… Environment: {env_config['ENV_TYPE']}")
    print(f"âœ… BASE_PATH: {BASE_PATH}")
    print(f"âœ… Imports working!")
except ImportError as e:
    print(f"âŒ Import Error: {e}")
    print("âš ï¸  Fix: Check if /storage/ML-number/src/ exists")

print("="*80)
```

**Run: Shift+Enter**

**à¸„à¸§à¸£à¹€à¸«à¹‡à¸™:**
```
================================================================================
ðŸ”§ ENVIRONMENT SETUP
================================================================================
âœ… Python path: /storage/ML-number
âœ… Working dir: /home/jovyan
âœ… Environment: paperspace
âœ… BASE_PATH: /storage/ML-number
âœ… Imports working!
================================================================================
```

### 7.3 Cell 2 - Load Data
```python
from src.data_loader import find_and_load_data
import pandas as pd

print("="*80)
print("ðŸ“Š DATA LOADING")
print("="*80)

try:
    # Load data
    df_raw = find_and_load_data()

    print(f"âœ… Data loaded successfully!")
    print(f"âœ… Total rows: {len(df_raw)}")
    print(f"âœ… Columns: {df_raw.columns.tolist()}")
    print(f"âœ… Data types:\n{df_raw.dtypes}")

    # Show sample
    print(f"\nðŸ“‹ First 5 rows:")
    print(df_raw.head())

    # Basic stats
    print(f"\nðŸ“ˆ Price statistics:")
    print(df_raw['price'].describe())

except Exception as e:
    print(f"âŒ Error loading data: {e}")
    print("\nâš ï¸  Troubleshooting:")
    print("   1. Check: ls /storage/ML-number/data/raw/numberdata.csv")
    print("   2. Upload numberdata.csv to /storage/ML-number/data/raw/")
    print("   3. Verify file has 6112 rows + header")

print("="*80)
```

**Run: Shift+Enter**

**à¸„à¸§à¸£à¹€à¸«à¹‡à¸™:**
```
================================================================================
ðŸ“Š DATA LOADING
================================================================================
âœ… Data loaded successfully!
âœ… Total rows: 6112
âœ… Columns: ['phone_number', 'price']
âœ… Data types:
phone_number    object
price          float64
dtype: object

ðŸ“‹ First 5 rows:
  phone_number    price
0   0812345678   5000.0
1   0899999999  150000.0
...
================================================================================
```

### 7.4 Cell 3 - Test GPU (Optional)
```python
import torch
import subprocess

print("="*80)
print("ðŸ–¥ï¸  GPU CHECK")
print("="*80)

# PyTorch GPU check
if torch.cuda.is_available():
    print(f"âœ… PyTorch GPU available!")
    print(f"   Device: {torch.cuda.get_device_name(0)}")
    print(f"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    print(f"   CUDA Version: {torch.version.cuda}")
else:
    print("âš ï¸  PyTorch: No GPU detected")
    print("   Training will use CPU (slower but works)")

# nvidia-smi check
print(f"\nðŸ” nvidia-smi output:")
try:
    result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total,utilization.gpu',
                            '--format=csv,noheader'],
                           capture_output=True, text=True, timeout=5)
    if result.returncode == 0:
        print(f"   {result.stdout.strip()}")
    else:
        print("   âš ï¸  nvidia-smi not available")
except:
    print("   âš ï¸  nvidia-smi command failed")

print("="*80)
```

**Run: Shift+Enter**

**à¸–à¹‰à¸²à¸¡à¸µ GPU à¸„à¸§à¸£à¹€à¸«à¹‡à¸™:**
```
================================================================================
ðŸ–¥ï¸  GPU CHECK
================================================================================
âœ… PyTorch GPU available!
   Device: Quadro M4000
   Memory: 8.0 GB
   CUDA Version: 12.0

ðŸ” nvidia-smi output:
   Quadro M4000, 8192 MiB, 0 %
================================================================================
```

**à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µ GPU:**
```
âš ï¸  PyTorch: No GPU detected
   Training will use CPU (slower but works)
```
â†’ à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š Notebook Settings â†’ Instance Type â†’ à¸•à¹‰à¸­à¸‡à¹€à¸›à¹‡à¸™ "Free-GPU"

### 7.5 Cell 4 - Start Training (MAIN)
```python
from src.train_production import train_production_models
import time

print("="*80)
print("ðŸš€ ML TRAINING - PRODUCTION MODE")
print("="*80)

# Configuration
config = {
    'optimize': True,        # Use Optuna hyperparameter optimization
    'n_trials': 100,         # Number of Optuna trials (100 = ~9-12 hours)
    'use_gpu': True,         # Auto-fallback to CPU if GPU fails
    'verbose': True          # Show detailed progress
}

print(f"ðŸ“‹ Training Configuration:")
print(f"   Optimization: {config['optimize']}")
print(f"   Optuna Trials: {config['n_trials']}")
print(f"   GPU Enabled: {config['use_gpu']}")
print(f"   Verbose: {config['verbose']}")
print(f"\nâ±ï¸  Estimated Time:")
print(f"   With GPU: ~9-12 hours")
print(f"   CPU only: ~18-24 hours")
print(f"\nðŸ’¾ Progress saved to:")
print(f"   Checkpoints: /storage/ML-number/checkpoints/")
print(f"   Models: /storage/ML-number/models/")
print("\n" + "="*80)
print("âš ï¸  DO NOT CLOSE THIS NOTEBOOK DURING TRAINING!")
print("="*80 + "\n")

# Confirm before starting
input("Press ENTER to start training (or Ctrl+C to cancel)...")

# Start training
start_time = time.time()

try:
    results = train_production_models(
        optimize=config['optimize'],
        n_trials=config['n_trials'],
        use_gpu=config['use_gpu'],
        verbose=config['verbose']
    )

    elapsed = time.time() - start_time

    print("\n" + "="*80)
    print("âœ… TRAINING COMPLETE!")
    print("="*80)
    print(f"â±ï¸  Total time: {elapsed/3600:.2f} hours")
    print(f"ðŸŽ¯ Best RÂ² Score: {results.get('best_r2', 'N/A'):.4f}")
    print(f"ðŸ† Best Model: {results.get('best_model_name', 'N/A')}")
    print(f"ðŸ’¾ Model saved to: /storage/ML-number/models/deployed/best_model.pkl")
    print("="*80)

except KeyboardInterrupt:
    print("\nâš ï¸  Training interrupted by user!")
    print("ðŸ’¾ Checkpoints saved - you can resume later")
except Exception as e:
    print(f"\nâŒ Training error: {e}")
    import traceback
    traceback.print_exc()
```

**IMPORTANT: à¸à¹ˆà¸­à¸™ Run Cell à¸™à¸µà¹‰**
```
1. à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š Cells 1-3 à¸œà¹ˆà¸²à¸™à¸«à¸¡à¸”à¹à¸¥à¹‰à¸§ (âœ…)
2. Data loaded à¹€à¸£à¸µà¸¢à¸šà¸£à¹‰à¸­à¸¢ (âœ…)
3. Save notebook (Ctrl+S à¸«à¸£à¸·à¸­ Cmd+S)
4. à¹€à¸•à¸£à¸µà¸¢à¸¡à¹ƒà¸ˆà¸§à¹ˆà¸²à¸ˆà¸°à¸£à¸­ 9-12 à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡
```

**Run: Shift+Enter**

à¸ˆà¸°à¹€à¸«à¹‡à¸™:
```
Press ENTER to start training (or Ctrl+C to cancel)...
```

à¸à¸” **Enter** à¹€à¸žà¸·à¹ˆà¸­à¹€à¸£à¸´à¹ˆà¸¡ training

---

## ðŸ“Š What to Expect During Training

### Phase 1: XGBoost (GPU) - ~2.5 hours
```
================================================================================
ðŸ”¥ Training XGBoost (GPU)
================================================================================
      ðŸ”¥ XGBoost using GPU (device=cuda)

ðŸ“ˆ Progress: 1/100 (1.0%) | ETA: 2.4 hours
ðŸ“ˆ Progress: 2/100 (2.0%) | ETA: 2.3 hours
...
[03:45:12] ðŸ”¥ GPU: 87% | Mem: 1234 MiB / 8192 MiB | Temp: 62Â°C
```

### Phase 2: LightGBM (CPU) - ~3.5 hours
```
================================================================================
ðŸ”¥ Training LightGBM (CPU - Auto-fallback)
================================================================================
      ðŸ”¬ Testing LightGBM GPU compilation...
      âš ï¸  GPU test failed: ... (expected)
      ðŸ”„ Automatically falling back to CPU for LightGBM
      âšª LightGBM using CPU (device=cpu)

ðŸ“ˆ Progress: 1/100 (1.0%) | ETA: 3.4 hours â† MUST SEE THIS!
ðŸ“ˆ Progress: 2/100 (2.0%) | ETA: 3.3 hours
...
```

**âš ï¸  CRITICAL: à¸–à¹‰à¸² LightGBM stuck at 0/100 > 5 minutes:**
â†’ à¸à¸” "Interrupt Kernel" (â¬› icon)
â†’ à¸¡à¸µà¸›à¸±à¸à¸«à¸² n_jobs bug (à¹„à¸¡à¹ˆà¸™à¹ˆà¸²à¹€à¸à¸´à¸”à¹€à¸žà¸£à¸²à¸°à¹ƒà¸Šà¹‰ HANG-FIX)

### Phase 3: CatBoost (GPU) - ~1.5 hours
```
================================================================================
ðŸ”¥ Training CatBoost (GPU)
================================================================================
      ðŸ”¥ CatBoost using GPU (task_type=GPU)

ðŸ“ˆ Progress: 1/50 (2.0%) | ETA: 1.4 hours
...
[07:15:23] ðŸ”¥ GPU: 78% | Mem: 2145 MiB / 8192 MiB | Temp: 68Â°C
```

### Phase 4: RandomForest (CPU) - ~1 hour
```
================================================================================
ðŸ”¥ Training RandomForest (CPU)
================================================================================
      âšª RandomForest using CPU (n_jobs=-1)

ðŸ“ˆ Progress: 1/50 (2.0%) | ETA: 58 min
...
```

### Phase 5: Ensemble - ~15 min
```
================================================================================
ðŸ”¥ Creating Ensemble Models
================================================================================
âœ… Weighted Ensemble created
âœ… Stacking Ensemble created
âœ… Optimized Stacking created
```

---

## âœ… Verification During Training

### Every 30 minutes, check:

**1. Progress is moving:**
```
ðŸ“ˆ Progress: X/100 (increasing)
```

**2. GPU is utilized (if available):**
```
[HH:MM:SS] ðŸ”¥ GPU: 70-100% (XGBoost, CatBoost)
[HH:MM:SS] âšª GPU: 0% (LightGBM - CPU only, expected)
```

**3. Checkpoints are saving:**
```
ðŸ’¾ Checkpoint saved: checkpoint_YYYYMMDD_HHMMSS.json
```

**4. No errors:**
```
âŒ Error: ... â† à¹„à¸¡à¹ˆà¸„à¸§à¸£à¹€à¸«à¹‡à¸™
```

---

## ðŸ’¾ After Training Completes

### 7.6 Cell 5 - Verify Results
```python
import joblib
import json
from pathlib import Path

print("="*80)
print("ðŸ” VERIFICATION - Model & Results")
print("="*80)

# Check model file
model_path = Path('/storage/ML-number/models/deployed/best_model.pkl')
if model_path.exists():
    print(f"âœ… Model found: {model_path}")
    print(f"   Size: {model_path.stat().st_size / 1024:.1f} KB")

    # Load model
    deployment = joblib.load(model_path)
    print(f"\nðŸ“Š Model Details:")
    print(f"   Name: {deployment.get('model_name', 'Unknown')}")
    print(f"   RÂ² Score: {deployment.get('r2_score', 'N/A'):.4f}")
    print(f"   Features: {len(deployment.get('feature_names', []))}")
    print(f"   Timestamp: {deployment.get('timestamp', 'N/A')}")
else:
    print(f"âŒ Model not found: {model_path}")

# Check checkpoints
checkpoint_dir = Path('/storage/ML-number/checkpoints/')
checkpoints = sorted(checkpoint_dir.glob('*.json'))
print(f"\nðŸ’¾ Checkpoints found: {len(checkpoints)}")
if checkpoints:
    latest = checkpoints[-1]
    print(f"   Latest: {latest.name}")
    with open(latest) as f:
        data = json.load(f)
        print(f"   Timestamp: {data.get('timestamp', 'N/A')}")

print("="*80)
```

### 7.7 Cell 6 - Test Prediction
```python
# Test single prediction
test_numbers = [
    '0899999999',  # Very lucky (9999)
    '0812345678',  # Sequential
    '0888888888',  # All 8s
]

print("="*80)
print("ðŸ§ª TEST PREDICTIONS")
print("="*80)

for number in test_numbers:
    # Create features (simplified - full pipeline in actual code)
    print(f"\nðŸ“± Number: {number}")
    print(f"   Predicted price: à¸¿{100000:,.0f}  (à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡)")
    # Note: à¸•à¹‰à¸­à¸‡à¹ƒà¸Šà¹‰ full pipeline à¸ˆà¸£à¸´à¸‡à¹† à¸ˆà¸²à¸ src/

print("="*80)
```

---

## ðŸ“¥ Download Model

### à¸§à¸´à¸˜à¸µà¸—à¸µà¹ˆ 1 - Jupyter UI (à¹à¸™à¸°à¸™à¸³):
```
1. à¹ƒà¸™ Jupyter Lab à¸‹à¹‰à¸²à¸¢à¸¡à¸·à¸­: Navigate to /storage/ML-number/models/deployed/
2. à¸„à¸¥à¸´à¸à¸‚à¸§à¸²à¸—à¸µà¹ˆ best_model.pkl
3. à¹€à¸¥à¸·à¸­à¸ "Download"
4. Save à¹„à¸§à¹‰à¸—à¸µà¹ˆà¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸„à¸¸à¸“
```

### à¸§à¸´à¸˜à¸µà¸—à¸µà¹ˆ 2 - Terminal:
```bash
# Copy to accessible location
cp /storage/ML-number/models/deployed/best_model.pkl ~/best_model.pkl

# Then download via Jupyter UI from home directory
```

---

## ðŸ”§ Troubleshooting

### Issue 1: Import Error
```python
ImportError: No module named 'src.config'
```

**Fix:**
```python
# Cell 1 - Add this at top
import sys
sys.path.insert(0, '/storage/ML-number')
```

### Issue 2: Data File Not Found
```python
FileNotFoundError: numberdata.csv
```

**Fix:**
```bash
# In terminal
ls -la /storage/ML-number/data/raw/
# à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µà¹„à¸Ÿà¸¥à¹Œ â†’ Upload again (STEP 6.2)
```

### Issue 3: GPU Not Detected
```
âš ï¸  PyTorch: No GPU detected
```

**Fix:**
```
1. Stop notebook
2. Notebook Settings â†’ Instance Type
3. Change to: Free-GPU (M4000) or P4000/P5000
4. Start notebook again
5. Re-run Cell 3 to verify
```

### Issue 4: Training Hangs (LightGBM)
```
LightGBM: 0/100 (stuck for > 5 minutes)
```

**Fix:**
```
1. Kernel â†’ Interrupt Kernel
2. Check src/model_utils.py line 596, 603
3. Should be: n_jobs=1 (not n_jobs=-1)
4. If wrong â†’ Update from GitHub:
   cd /storage/ML-number
   git pull origin main
5. Restart kernel + re-run
```

### Issue 5: Out of Memory
```
CUDA out of memory
```

**Fix:**
```python
# In Cell 4, reduce n_trials:
config = {
    'n_trials': 50,  # Reduce from 100
    ...
}
```

### Issue 6: Kernel Died
```
Kernel died, restarting...
```

**Fix:**
```
1. Don't panic - checkpoints are saved!
2. Kernel â†’ Restart Kernel
3. Re-run Cells 1-2 (setup + data)
4. Skip Cell 4 (training) if already running
5. Check: /storage/ML-number/checkpoints/ for progress
```

---

## ðŸ“Š Expected Results

### Successful Training:
```
âœ… Training complete in ~9-12 hours (GPU) or 18-24 hours (CPU)
âœ… RÂ² Score > 0.90 (target: 0.93+)
âœ… Model saved: /storage/ML-number/models/deployed/best_model.pkl
âœ… Checkpoints: 15-20 files in checkpoints/
âœ… No errors in output
```

### What Good Looks Like:
```
ðŸŽ¯ Best RÂ² Score: 0.9324
ðŸ† Best Model: Optimized_Stacking
ðŸ’¾ Model saved to: /storage/ML-number/models/deployed/best_model.pkl
```

---

## ðŸ†˜ Need Help?

**During setup (STEP 1-6):**
- à¸–à¹‰à¸²à¸•à¸´à¸”à¸‚à¸±à¸” â†’ à¸–à¸²à¸¡à¹„à¸”à¹‰à¹€à¸¥à¸¢ à¸¡à¸µà¸„à¸³à¸ªà¸±à¹ˆà¸‡à¸žà¸£à¹‰à¸­à¸¡ copy-paste

**During training (STEP 7):**
- à¸–à¹‰à¸² progress à¹„à¸¡à¹ˆà¸‚à¸¢à¸±à¸š > 10 min â†’ Interrupt + Report
- à¸–à¹‰à¸² error â†’ Copy error message â†’ Report

**After training:**
- à¸–à¹‰à¸² RÂ² < 0.80 â†’ Review training logs
- à¸–à¹‰à¸² model file missing â†’ Check checkpoints/

---

## ðŸ“š Related Files

- **Setup**: `PAPERSPACE_SETUP.md`
- **Validation**: `validate_paperspace.py`
- **Error Prevention**: `PAPERSPACE_ERROR_PREVENTION.md`
- **GPU Config**: `PAPERSPACE_GPU_CONFIG_USAGE.md`
- **Main Docs**: `CLAUDE.md`, `README.md`

---

**Created**: 2025-10-06
**Version**: HANG-FIX compatible
**Platform**: Paperspace Gradient
**GPU**: M4000/P4000/P5000 (auto-detect)
**Training Time**: ~9-12 hours (GPU) / 18-24 hours (CPU)

ðŸŽ‰ **Ready to start training!** Follow STEP 1 â†’ STEP 7 â†’ Wait â†’ Download model
