# üñ•Ô∏è GPU Training Platforms Guide - ‡∏ü‡∏£‡∏µ‡πÅ‡∏•‡∏∞‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ñ‡∏π‡∏Å

> ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ML Training ‡∏û‡∏£‡πâ‡∏≠‡∏° GPU ‡∏ü‡∏£‡∏µ‡πÅ‡∏•‡∏∞‡πÄ‡∏™‡∏µ‡∏¢‡πÄ‡∏á‡∏¥‡∏ô

**‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î:** 5 ‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏° 2025

---

## üìã ‡∏™‡∏≤‡∏£‡∏ö‡∏±‡∏ç

1. [Overview](#-overview)
2. [Free Platforms](#-free-platforms-‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏ü‡∏£‡∏µ)
3. [Budget Paid Platforms](#-budget-paid-platforms-‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ñ‡∏π‡∏Å)
4. [Student Programs](#-student-programs-‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤)
5. [Comparison Table](#-comparison-table)
6. [Recommendations](#-recommendations-‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)
7. [Cost Optimization](#-cost-optimization-strategies)
8. [Quick Start Links](#-quick-start-links)

---

## üéØ Overview

### ‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ (11 ‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°)

| ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó | ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á |
|--------|-------|----------|
| **‡∏ü‡∏£‡∏µ 100%** | 5 | Kaggle, Colab, Paperspace, Lightning AI, Saturn Cloud |
| **‡∏ü‡∏£‡∏µ‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô** | 2 | Deepnote, Hugging Face Spaces |
| **‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤ (Credits)** | 2 | AWS Educate, GCP Education |
| **‡∏à‡πà‡∏≤‡∏¢‡πÄ‡∏á‡∏¥‡∏ô (‡∏ñ‡∏π‡∏Å)** | 3 | Vast.ai, RunPod, Lambda Labs |

### GPU ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ö‡πà‡∏≠‡∏¢

| GPU Model | VRAM | Performance | ‡∏£‡∏≤‡∏Ñ‡∏≤‡πÇ‡∏î‡∏¢‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì |
|-----------|------|-------------|----------------|
| NVIDIA M4000 | 8 GB | ‚≠ê‚≠ê‚≠ê | ‡∏ü‡∏£‡∏µ (Paperspace) |
| NVIDIA T4 | 16 GB | ‚≠ê‚≠ê‚≠ê‚≠ê | ‡∏ü‡∏£‡∏µ (Colab, Lightning AI, Saturn Cloud) |
| NVIDIA P100 | 16 GB | ‚≠ê‚≠ê‚≠ê‚≠ê | ‡∏ü‡∏£‡∏µ (Kaggle) |
| NVIDIA RTX 3090 | 24 GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | $0.20/hr (Vast.ai) |
| NVIDIA RTX 4090 | 24 GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | $0.35/hr (RunPod) |
| NVIDIA A100 | 40/80 GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | $0.50-1.10/hr (Lambda, RunPod) |
| NVIDIA V100 | 16/32 GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | $3.06/hr (AWS) |

---

## üÜì Free Platforms (‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏ü‡∏£‡∏µ)

### 1. üèÜ Kaggle (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ü‡∏£‡∏µ!)

**‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå:** https://www.kaggle.com/

**Specs:**
- **GPU:** NVIDIA Tesla P100 (16 GB VRAM)
- **CPU:** 2-core CPU
- **RAM:** 13 GB
- **Storage:** 20 GB disk space
- **‡πÄ‡∏ß‡∏•‡∏≤:** 30 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á/‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå (‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡∏ó‡∏∏‡∏Å‡∏ß‡∏±‡∏ô‡πÄ‡∏™‡∏≤‡∏£‡πå)
- **Timeout:** 9 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á/session (‡πÅ‡∏ï‡πà‡∏°‡∏µ persistence)

**‡∏Ç‡πâ‡∏≠‡∏î‡∏µ:**
- ‚úÖ GPU ‡πÅ‡∏£‡∏á (P100 ‡πÅ‡∏£‡∏á‡∏Å‡∏ß‡πà‡∏≤ T4)
- ‚úÖ Persistence support (checkpoint ‡πÑ‡∏°‡πà‡∏´‡∏≤‡∏¢)
- ‚úÖ ‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏¢‡∏≠‡∏∞ (30 ‡∏ä‡∏°./‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå)
- ‚úÖ Interface ‡πÉ‡∏ä‡πâ‡∏á‡πà‡∏≤‡∏¢ (Jupyter notebook)
- ‚úÖ ‡∏ä‡∏∏‡∏°‡∏ä‡∏ô‡πÉ‡∏´‡∏ç‡πà (datasets, notebooks ‡∏ü‡∏£‡∏µ)
- ‚úÖ Kaggle competitions (‡πÑ‡∏î‡πâ‡∏£‡∏≤‡∏á‡∏ß‡∏±‡∏•!)

**‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢:**
- ‚ö†Ô∏è ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡∏¥‡∏î Internet off ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ (‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î quota)
- ‚ö†Ô∏è Session timeout 9 ‡∏ä‡∏°. (‡πÅ‡∏ï‡πà resume ‡πÑ‡∏î‡πâ)

**‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö:**
- ‚úÖ Training ‡∏£‡∏∞‡∏¢‡∏∞‡∏Å‡∏•‡∏≤‡∏á (6-8 ‡∏ä‡∏°.)
- ‚úÖ Experiments, hyperparameter tuning
- ‚úÖ Competitions
- ‚úÖ **‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ Phone Number ML ‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤** ‚Üê

**‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô:**
1. ‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡∏ö‡∏±‡∏ç‡∏ä‡∏µ Kaggle (‡∏ü‡∏£‡∏µ)
2. Verify phone number (‡∏ñ‡∏∂‡∏á‡∏à‡∏∞‡πÉ‡∏ä‡πâ GPU ‡πÑ‡∏î‡πâ)
3. ‡∏™‡∏£‡πâ‡∏≤‡∏á notebook ‡πÉ‡∏´‡∏°‡πà
4. Settings ‚Üí Accelerator: GPU
5. Settings ‚Üí Persistence: Files only
6. Settings ‚Üí Environment: Latest
7. Run!

**Tips:**
- Enable GPU ‡∏ï‡∏≠‡∏ô‡∏à‡∏∞ train ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô (‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î quota)
- ‡πÉ‡∏ä‡πâ checkpoint manager ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö auto-resume
- Upload dataset ‡πÄ‡∏õ‡πá‡∏ô Kaggle dataset (‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤)

---

### 2. üìì Google Colab

**‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå:** https://colab.research.google.com/

**Specs:**
- **GPU:** NVIDIA Tesla T4 (16 GB VRAM)
- **CPU:** 2-core CPU
- **RAM:** 12 GB
- **Storage:** 100+ GB (Google Drive)
- **‡πÄ‡∏ß‡∏•‡∏≤:** ~12 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á/‡∏ß‡∏±‡∏ô (‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£)
- **Timeout:** 12 ‡∏ä‡∏°./session (‡∏ñ‡∏π‡∏Å‡∏ï‡∏±‡∏î‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ activity)

**‡∏Ç‡πâ‡∏≠‡∏î‡∏µ:**
- ‚úÖ ‡πÉ‡∏ä‡πâ‡∏á‡πà‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢)
- ‚úÖ Google Drive integration
- ‚úÖ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏£‡πá‡∏ß (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏≠ queue)
- ‚úÖ ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏ï‡∏±‡∏ß‡∏ï‡∏ô‡πÄ‡∏¢‡∏≠‡∏∞

**‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢:**
- ‚ùå Timeout ‡∏á‡πà‡∏≤‡∏¢ (‡πÑ‡∏°‡πà‡∏°‡∏µ activity 30-90 ‡∏ô‡∏≤‡∏ó‡∏µ = ‡∏ï‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠)
- ‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ persistence (session ‡∏´‡∏°‡∏î = ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÉ‡∏´‡∏°‡πà)
- ‚ùå GPU random (‡∏ö‡∏≤‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÑ‡∏î‡πâ K80 ‡πÅ‡∏ó‡∏ô T4)
- ‚ùå ‡∏à‡∏≥‡∏Å‡∏±‡∏î usage (‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ‡πÄ‡∏¢‡∏≠‡∏∞‡πÇ‡∏î‡∏ô limit)

**‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö:**
- ‚úÖ Quick experiments (< 2 ‡∏ä‡∏°.)
- ‚úÖ Code testing, debugging
- ‚úÖ Learning, tutorials
- ‚ùå ‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö long training (>4 ‡∏ä‡∏°.)

**Colab Pro ($10/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô):**
- GPU: V100 ‡∏´‡∏£‡∏∑‡∏≠ A100
- RAM: 25 GB
- Timeout: 24 ‡∏ä‡∏°.
- Priority access

**Colab Pro+ ($50/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô):**
- GPU: A100 (40 GB)
- RAM: 51 GB
- Timeout: ‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î
- Background execution

---

### 3. üñ•Ô∏è Paperspace Gradient ‚≠ê ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥!

**‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå:** https://www.paperspace.com/gradient

**Specs (Free-GPU tier):**
- **GPU:** NVIDIA Quadro M4000 (8 GB VRAM)
- **CPU:** 8-core CPU
- **RAM:** 30 GB
- **Storage:** 5 GB persistent storage
- **‡πÄ‡∏ß‡∏•‡∏≤:** ‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á! ‚úÖ
- **Timeout:** ‡πÑ‡∏°‡πà‡∏°‡∏µ timeout (‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡πÑ‡∏î‡πâ)

**‡∏Ç‡πâ‡∏≠‡∏î‡∏µ:**
- ‚úÖ **‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤!** (‡∏ó‡∏≥‡∏á‡∏≤‡∏ô 24/7 ‡πÑ‡∏î‡πâ)
- ‚úÖ ‡πÑ‡∏°‡πà‡∏°‡∏µ timeout (training ‡∏´‡∏•‡∏≤‡∏¢‡∏ß‡∏±‡∏ô‡πÑ‡∏î‡πâ)
- ‚úÖ Persistent storage (‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡∏´‡∏≤‡∏¢)
- ‚úÖ Git integration
- ‚úÖ Jupyter notebook interface
- ‚úÖ Public notebooks (share ‡πÑ‡∏î‡πâ)
- ‚úÖ TensorBoard built-in

**‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢:**
- ‚ö†Ô∏è **Queue ‡∏£‡∏≠‡∏ô‡∏≤‡∏ô** (free tier ‡∏°‡∏µ queue)
- ‚ö†Ô∏è M4000 ‡∏ä‡πâ‡∏≤‡∏Å‡∏ß‡πà‡∏≤ P100, T4 (~30-40% ‡∏ä‡πâ‡∏≤‡∏Å‡∏ß‡πà‡∏≤)
- ‚ö†Ô∏è Storage ‡∏ô‡πâ‡∏≠‡∏¢ (5 GB)

**‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö:**
- ‚úÖ **Long training runs** (‡∏´‡∏•‡∏≤‡∏¢‡∏ß‡∏±‡∏ô)
- ‚úÖ Training ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏£‡∏µ‡∏ö (‡∏£‡∏≠ queue ‡πÑ‡∏î‡πâ)
- ‚úÖ Persistent experiments
- ‚úÖ Background jobs

**‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô:**
1. ‡∏™‡∏°‡∏±‡∏Ñ‡∏£ Paperspace account
2. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Gradient ‚Üí Notebooks
3. Create Notebook ‚Üí Free-GPU
4. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å template: PyTorch, TensorFlow, etc.
5. Start notebook (‡∏£‡∏≠ queue 5-30 ‡∏ô‡∏≤‡∏ó‡∏µ)
6. Run!

**Tips:**
- ‡πÉ‡∏ä‡πâ‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà traffic ‡∏ô‡πâ‡∏≠‡∏¢ (‡∏Å‡∏•‡∏≤‡∏á‡∏Ñ‡∏∑‡∏ô US time = ‡πÄ‡∏ä‡πâ‡∏≤‡πÑ‡∏ó‡∏¢)
- Upload dataset ‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤ (storage ‡∏à‡∏≥‡∏Å‡∏±‡∏î)
- Save checkpoints ‡∏ö‡πà‡∏≠‡∏¢‡πÜ (‡πÅ‡∏°‡πâ‡πÑ‡∏°‡πà‡∏°‡∏µ timeout)

**Paid tiers:**
- **Growth:** $8/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô (P5000 GPU, 50 GB storage)
- **Pro:** $39/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô (RTX 4000 GPU, 200 GB storage)

---

### 4. üå©Ô∏è Lightning AI (‡πÄ‡∏î‡∏¥‡∏°‡∏ä‡∏∑‡πà‡∏≠ Grid.ai)

**‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå:** https://lightning.ai/

**Specs (Free tier):**
- **GPU:** NVIDIA Tesla T4 (16 GB VRAM)
- **CPU:** 4-core CPU
- **RAM:** 16 GB
- **Storage:** 50 GB
- **‡πÄ‡∏ß‡∏•‡∏≤:** 22 GPU ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
- **Timeout:** 8 ‡∏ä‡∏°./session

**‡∏Ç‡πâ‡∏≠‡∏î‡∏µ:**
- ‚úÖ GPU ‡πÅ‡∏£‡∏á (T4)
- ‚úÖ PyTorch Lightning integration ‡∏î‡∏µ‡∏°‡∏≤‡∏Å
- ‚úÖ Storage ‡πÄ‡∏¢‡∏≠‡∏∞ (50 GB)
- ‚úÖ Version control ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö experiments
- ‚úÖ TensorBoard, Weights & Biases integration
- ‚úÖ Multi-GPU (‡∏ñ‡πâ‡∏≤‡∏à‡πà‡∏≤‡∏¢‡πÄ‡∏á‡∏¥‡∏ô)

**‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢:**
- ‚ö†Ô∏è ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á (22 ‡∏ä‡∏°./‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)
- ‚ö†Ô∏è ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ Lightning framework (‡∏ñ‡πâ‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏ï‡πá‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û)
- ‚ö†Ô∏è Interface ‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Å‡∏ß‡πà‡∏≤ Colab

**‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö:**
- ‚úÖ PyTorch projects
- ‚úÖ Quick experiments (22 ‡∏ä‡∏°. = 2-3 training runs)
- ‚úÖ MLOps workflows
- ‚úÖ Team collaboration

**‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô:**
1. ‡∏™‡∏°‡∏±‡∏Ñ‡∏£ Lightning AI account
2. ‡∏™‡∏£‡πâ‡∏≤‡∏á Studio (environment)
3. Upload code/notebook
4. Run training script
5. ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° experiments ‡πÉ‡∏ô UI

**Tips:**
- ‡πÉ‡∏ä‡πâ PyTorch Lightning (optimized ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö platform ‡∏ô‡∏µ‡πâ)
- Monitor GPU hours ‡πÉ‡∏ô dashboard
- ‡πÉ‡∏ä‡πâ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡πâ‡∏°‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏°‡∏î‡πÄ‡∏î‡∏∑‡∏≠‡∏ô

**Paid tiers:**
- **Pro:** $50/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô (100 GPU hours, A10G GPU)
- **Team:** Custom pricing (Multi-GPU, A100)

---

### 5. ü™ê Saturn Cloud

**‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå:** https://saturncloud.io/

**Specs (Community tier):**
- **GPU:** NVIDIA Tesla T4 (16 GB VRAM)
- **CPU:** 4-core CPU
- **RAM:** 16 GB
- **Storage:** 10 GB
- **‡πÄ‡∏ß‡∏•‡∏≤:** 150 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô ‚úÖ
- **Timeout:** 3 ‡∏ä‡∏°. idle (‡∏ï‡πà‡∏≠‡πÑ‡∏î‡πâ)

**‡∏Ç‡πâ‡∏≠‡∏î‡∏µ:**
- ‚úÖ **‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏¢‡∏≠‡∏∞‡∏°‡∏≤‡∏Å!** (150 ‡∏ä‡∏°./‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)
- ‚úÖ Dask integration (distributed computing)
- ‚úÖ JupyterLab interface
- ‚úÖ RStudio support (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö R)
- ‚úÖ Git sync
- ‚úÖ Environment templates

**‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢:**
- ‚ö†Ô∏è Interface ‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Å‡∏ß‡πà‡∏≤ Colab
- ‚ö†Ô∏è Startup time ‡∏ô‡∏≤‡∏ô‡∏´‡∏ô‡πà‡∏≠‡∏¢ (1-3 ‡∏ô‡∏≤‡∏ó‡∏µ)
- ‚ö†Ô∏è Learning curve ‡∏™‡∏π‡∏á

**‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö:**
- ‚úÖ Data science workflows
- ‚úÖ Big data processing (Dask)
- ‚úÖ R users
- ‚úÖ Multiple training runs (150 ‡∏ä‡∏°. = 15-20 runs)

**‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô:**
1. ‡∏™‡∏°‡∏±‡∏Ñ‡∏£ Saturn Cloud account
2. Create Resource ‚Üí Jupyter Server
3. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Instance: T4 GPU
4. Start server (‡∏£‡∏≠ 1-3 ‡∏ô‡∏≤‡∏ó‡∏µ)
5. Upload notebook/code
6. Run!

**Tips:**
- ‡∏õ‡∏¥‡∏î server ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ (‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á)
- ‡πÉ‡∏ä‡πâ Dask ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ parallel processing
- Monitor hours ‡πÉ‡∏ô usage dashboard

**Paid tiers:**
- **Pro:** $50/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô (200 GPU hours, larger GPUs)
- **Team:** Custom pricing

---

### 6. üìì Deepnote (‡πÑ‡∏°‡πà‡∏°‡∏µ GPU ‡∏ü‡∏£‡∏µ)

**‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå:** https://deepnote.com/

**Specs (Personal tier):**
- **GPU:** ‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ GPU ‡πÉ‡∏ô free tier
- **CPU:** 4 vCPU
- **RAM:** 16 GB
- **Storage:** 5 GB
- **‡πÄ‡∏ß‡∏•‡∏≤:** 750 compute hours/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô (CPU only)

**‡∏Ç‡πâ‡∏≠‡∏î‡∏µ:**
- ‚úÖ Interface ‡∏™‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (modern UI)
- ‚úÖ Real-time collaboration ‡∏î‡∏µ‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°
- ‚úÖ SQL, BigQuery integration
- ‚úÖ Notion-style documentation
- ‚úÖ Version control built-in
- ‚úÖ Publishing workflows

**‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢:**
- ‚ùå **‡πÑ‡∏°‡πà‡∏°‡∏µ GPU ‡∏ü‡∏£‡∏µ!**
- üí∞ GPU ‡∏ï‡πâ‡∏≠‡∏á‡∏à‡πà‡∏≤‡∏¢ ~$15/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô (Team tier)

**‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö:**
- ‚úÖ CPU-only training
- ‚úÖ Data exploration, EDA
- ‚úÖ Team collaboration
- ‚úÖ Dashboards, reports
- ‚ùå **‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö deep learning**

**Paid tiers:**
- **Team:** $15/user/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô (T4 GPU access)

---

### 7. ü§ó Hugging Face Spaces (Deployment only)

**‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå:** https://huggingface.co/spaces

**Specs (Free tier):**
- **GPU:** ‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ GPU ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö training
- **CPU:** 2-core CPU
- **RAM:** 16 GB
- **Storage:** ‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î (Git LFS)
- **‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö:** Deploy models (inference only)

**‡∏Ç‡πâ‡∏≠‡∏î‡∏µ:**
- ‚úÖ Deploy models ‡∏ü‡∏£‡∏µ
- ‚úÖ Gradio/Streamlit support
- ‚úÖ Auto-restart
- ‚úÖ Share demos ‡∏Å‡∏±‡∏ö‡∏ä‡∏∏‡∏°‡∏ä‡∏ô
- ‚úÖ Custom domains

**‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢:**
- ‚ùå **‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö training!**
- ‚ùå CPU inference only (‡∏ü‡∏£‡∏µ)

**‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö:**
- ‚úÖ Deploy trained models
- ‚úÖ Create interactive demos
- ‚úÖ Portfolio projects
- ‚ùå **‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö training**

**Paid tiers:**
- **Upgraded Space:** $0.60/hr (GPU inference)

---

## üí∞ Budget Paid Platforms (‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ñ‡∏π‡∏Å)

### 8. üíé Vast.ai - ‡∏ñ‡∏π‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î!

**‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå:** https://vast.ai/

**Specs:**
- **GPU:** RTX 3060 Ti, RTX 3090, RTX 4090, A6000, A100
- **‡∏£‡∏≤‡∏Ñ‡∏≤:** $0.10 - $1.50/‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á (‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö GPU)
- **‡πÅ‡∏ö‡∏ö:** P2P GPU marketplace (‡πÄ‡∏ä‡πà‡∏≤ GPU ‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ô‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ)

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤:**
| GPU | VRAM | ‡∏£‡∏≤‡∏Ñ‡∏≤/‡∏ä‡∏°. | ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö AWS |
|-----|------|---------|-----------|
| RTX 3060 Ti | 8 GB | $0.10 | ‡∏ñ‡∏π‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 30 ‡πÄ‡∏ó‡πà‡∏≤ |
| RTX 3090 | 24 GB | $0.20 | ‡∏ñ‡∏π‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 15 ‡πÄ‡∏ó‡πà‡∏≤ |
| RTX 4090 | 24 GB | $0.35 | ‡∏ñ‡∏π‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 10 ‡πÄ‡∏ó‡πà‡∏≤ |
| A6000 | 48 GB | $0.50 | ‡∏ñ‡∏π‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 6 ‡πÄ‡∏ó‡πà‡∏≤ |
| A100 (40GB) | 40 GB | $0.80 | ‡∏ñ‡∏π‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 4 ‡πÄ‡∏ó‡πà‡∏≤ |

**‡∏Ç‡πâ‡∏≠‡∏î‡∏µ:**
- ‚úÖ **‡∏ñ‡∏π‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î!** (‡∏ñ‡∏π‡∏Å‡∏Å‡∏ß‡πà‡∏≤ cloud ‡πÉ‡∏´‡∏ç‡πà 5-30 ‡πÄ‡∏ó‡πà‡∏≤)
- ‚úÖ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å GPU ‡πÑ‡∏î‡πâ‡πÄ‡∏≠‡∏á (‡∏à‡∏≤‡∏Å marketplace)
- ‚úÖ ‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤
- ‚úÖ Pay-as-you-go (‡∏à‡πà‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)
- ‚úÖ Docker support

**‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢:**
- ‚ö†Ô∏è Reliability ‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô (‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö host)
- ‚ö†Ô∏è ‡∏ö‡∏≤‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ä‡πâ‡∏≤/‡πÑ‡∏°‡πà‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£
- ‚ö†Ô∏è ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ Docker (‡πÑ‡∏°‡πà‡∏°‡∏µ Jupyter built-in)
- ‚ö†Ô∏è ‡∏ï‡πâ‡∏≠‡∏á SSH (command line)

**‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö:**
- ‚úÖ Budget-friendly training
- ‚úÖ Long training runs (‡∏´‡∏•‡∏≤‡∏¢‡∏ß‡∏±‡∏ô)
- ‚úÖ Custom environments
- ‚úÖ ‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà comfortable ‡∏Å‡∏±‡∏ö Linux/Docker

**‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô:**
1. ‡∏™‡∏°‡∏±‡∏Ñ‡∏£ Vast.ai account
2. Deposit ‡πÄ‡∏á‡∏¥‡∏ô (‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥ $10)
3. Search GPU ‚Üí ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏≤‡∏°: Price, GPU model, Reliability score
4. Create instance (‡πÉ‡∏ä‡πâ template ‡∏´‡∏£‡∏∑‡∏≠ custom Docker image)
5. SSH ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ Jupyter (‡∏ñ‡πâ‡∏≤ image ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö)
6. Run training
7. Stop instance ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏™‡∏£‡πá‡∏à (‡∏à‡πà‡∏≤‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ)

**Tips:**
- ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å host ‡∏ó‡∏µ‡πà‡∏°‡∏µ Reliability score > 95%
- ‡πÉ‡∏ä‡πâ template: `pytorch/pytorch:latest` (‡∏°‡∏µ Jupyter)
- Save checkpoints ‡∏ö‡πà‡∏≠‡∏¢‡πÜ (‡∏Å‡∏±‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏≤‡∏¢)
- Monitor costs ‡πÉ‡∏ô billing dashboard

**Example cost:**
- RTX 3090 @ $0.20/hr √ó 8 ‡∏ä‡∏°. training = **$1.60** (~56 ‡∏ö‡∏≤‡∏ó)
- AWS p3.2xlarge @ $3.06/hr √ó 8 ‡∏ä‡∏°. = **$24.48** (~850 ‡∏ö‡∏≤‡∏ó)
- **‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î: $22.88 (94% ‡∏ñ‡∏π‡∏Å‡∏Å‡∏ß‡πà‡∏≤!)**

---

### 9. üèÉ RunPod

**‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå:** https://www.runpod.io/

**Specs:**
- **GPU:** RTX 3090, RTX 4090, A100, A40
- **‡∏£‡∏≤‡∏Ñ‡∏≤:** $0.20 - $2.00/‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á
- **‡πÅ‡∏ö‡∏ö:** Cloud GPU platform (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô AWS ‡πÅ‡∏ï‡πà‡∏ñ‡∏π‡∏Å‡∏Å‡∏ß‡πà‡∏≤)

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤:**
| GPU | VRAM | ‡∏£‡∏≤‡∏Ñ‡∏≤/‡∏ä‡∏°. |
|-----|------|---------|
| RTX 3090 | 24 GB | $0.29 |
| RTX 4090 | 24 GB | $0.69 |
| A40 | 48 GB | $0.79 |
| A100 (40GB) | 40 GB | $1.59 |
| A100 (80GB) | 80 GB | $1.99 |

**‡∏Ç‡πâ‡∏≠‡∏î‡∏µ:**
- ‚úÖ Jupyter notebook ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ
- ‚úÖ One-click templates (PyTorch, TensorFlow, etc.)
- ‚úÖ Reliable (‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ Vast.ai)
- ‚úÖ Serverless GPU (pay per second)
- ‚úÖ Web terminal built-in
- ‚úÖ File browser GUI

**‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢:**
- ‚ö†Ô∏è ‡πÅ‡∏û‡∏á‡∏Å‡∏ß‡πà‡∏≤ Vast.ai (~30-50%)
- ‚ö†Ô∏è Availability ‡∏à‡∏≥‡∏Å‡∏±‡∏î (popular GPUs ‡∏´‡∏°‡∏î‡πÄ‡∏£‡πá‡∏ß)

**‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö:**
- ‚úÖ Training ‡∏£‡∏∞‡∏¢‡∏∞‡∏™‡∏±‡πâ‡∏ô-‡∏Å‡∏•‡∏≤‡∏á (2-10 ‡∏ä‡∏°.)
- ‚úÖ Quick experiments
- ‚úÖ ‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ GUI (‡πÑ‡∏°‡πà‡∏ä‡∏≠‡∏ö command line)
- ‚úÖ Reliability ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç

**‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô:**
1. ‡∏™‡∏°‡∏±‡∏Ñ‡∏£ RunPod account
2. Deposit ‡πÄ‡∏á‡∏¥‡∏ô (‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥ $10)
3. Deploy Pod ‚Üí ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å GPU
4. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å template: Jupyter PyTorch/TensorFlow
5. ‡πÄ‡∏õ‡∏¥‡∏î Jupyter ‡∏ú‡πà‡∏≤‡∏ô web (‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢)
6. Run training
7. Stop pod ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏™‡∏£‡πá‡∏à

**Tips:**
- ‡πÉ‡∏ä‡πâ Serverless pods ‡∏ñ‡πâ‡∏≤ training ‡∏™‡∏±‡πâ‡∏ô‡πÜ (< 1 ‡∏ä‡∏°.)
- ‡πÉ‡∏ä‡πâ Community Cloud (‡∏ñ‡∏π‡∏Å‡∏Å‡∏ß‡πà‡∏≤ Secure Cloud)
- Monitor spending ‡πÉ‡∏ô dashboard

**Example cost:**
- RTX 4090 @ $0.69/hr √ó 6 ‡∏ä‡∏°. = **$4.14** (~145 ‡∏ö‡∏≤‡∏ó)

---

### 10. üî¨ Lambda Labs Cloud

**‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå:** https://lambdalabs.com/service/gpu-cloud

**Specs:**
- **GPU:** A100 (40/80 GB), H100
- **‡∏£‡∏≤‡∏Ñ‡∏≤:** $0.50 - $2.00/‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á
- **‡πÅ‡∏ö‡∏ö:** ML-focused cloud (made for ML)

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤:**
| GPU | VRAM | ‡∏£‡∏≤‡∏Ñ‡∏≤/‡∏ä‡∏°. |
|-----|------|---------|
| RTX A6000 | 48 GB | $0.50 |
| A100 (40GB) | 40 GB | $1.10 |
| A100 (80GB) | 80 GB | $1.60 |
| H100 | 80 GB | $2.00 |

**‡∏Ç‡πâ‡∏≠‡∏î‡∏µ:**
- ‚úÖ GPU ‡πÅ‡∏£‡∏á‡∏™‡∏∏‡∏î (H100!)
- ‚úÖ Interface ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏á‡πà‡∏≤‡∏¢
- ‚úÖ Made for ML (‡πÑ‡∏°‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô AWS)
- ‚úÖ PyTorch, TensorFlow pre-installed
- ‚úÖ Jupyter built-in
- ‚úÖ Fast networking (40-100 Gbps)

**‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢:**
- ‚ö†Ô∏è ‡πÅ‡∏û‡∏á‡∏Å‡∏ß‡πà‡∏≤ Vast.ai (~2-3 ‡πÄ‡∏ó‡πà‡∏≤)
- ‚ö†Ô∏è Availability ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏°‡∏≤‡∏Å (popular!)
- ‚ö†Ô∏è ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏≠ waitlist ‡∏ö‡∏≤‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á

**‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö:**
- ‚úÖ Production ML workflows
- ‚úÖ Large models (LLMs, diffusion models)
- ‚úÖ Research projects
- ‚úÖ ‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ H100

**‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô:**
1. ‡∏™‡∏°‡∏±‡∏Ñ‡∏£ Lambda account (‡∏≠‡∏≤‡∏à‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏≠ approval)
2. Add payment method
3. Launch instance ‚Üí ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å GPU
4. SSH ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡∏¥‡∏î Jupyter
5. Run training
6. Terminate instance ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏™‡∏£‡πá‡∏à

**Tips:**
- ‡∏à‡∏≠‡∏á‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤ (availability ‡∏à‡∏≥‡∏Å‡∏±‡∏î)
- ‡πÉ‡∏ä‡πâ on-demand ‡∏ñ‡πâ‡∏≤‡∏à‡∏∞ train ‡∏™‡∏±‡πâ‡∏ô‡πÜ
- ‡πÉ‡∏ä‡πâ reserved instances ‡∏ñ‡πâ‡∏≤‡∏à‡∏∞ train ‡∏ô‡∏≤‡∏ô‡πÜ (‡∏ñ‡∏π‡∏Å‡∏Å‡∏ß‡πà‡∏≤)

---

## üéì Student Programs (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤)

### 11. üéì AWS Educate / AWS Academy

**‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå:** https://aws.amazon.com/education/awseducate/

**Specs:**
- **Credits:** $100-300 (‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°)
- **GPU:** V100, A100, P3, P4 instances
- **‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£:** Email .edu (‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤)

**GPU Instances & Pricing:**
| Instance | GPU | VRAM | ‡∏£‡∏≤‡∏Ñ‡∏≤/‡∏ä‡∏°. | $100 ‡πÑ‡∏î‡πâ‡∏Å‡∏µ‡πà‡∏ä‡∏°. |
|----------|-----|------|---------|---------------|
| p3.2xlarge | V100 | 16 GB | $3.06 | ~32 ‡∏ä‡∏°. |
| p3.8xlarge | 4√óV100 | 64 GB | $12.24 | ~8 ‡∏ä‡∏°. |
| p4d.24xlarge | 8√óA100 | 320 GB | $32.77 | ~3 ‡∏ä‡∏°. |

**‡∏Ç‡πâ‡∏≠‡∏î‡∏µ:**
- ‚úÖ GPU ‡πÅ‡∏£‡∏á‡∏°‡∏≤‡∏Å (V100, A100)
- ‚úÖ ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ AWS ecosystem
- ‚úÖ SageMaker notebook
- ‚úÖ Credits ‡∏ü‡∏£‡∏µ ($100-300)
- ‚úÖ Learning resources ‡∏ü‡∏£‡∏µ

**‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢:**
- ‚ö†Ô∏è ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ .edu email
- ‚ö†Ô∏è Credits ‡∏´‡∏°‡∏î‡πÄ‡∏£‡πá‡∏ß (GPU ‡πÅ‡∏û‡∏á)
- ‚ö†Ô∏è ‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏°‡∏≤‡∏Å (learning curve ‡∏™‡∏π‡∏á)
- ‚ö†Ô∏è ‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠ quota ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö GPU

**‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö:**
- ‚úÖ ‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏≤‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô AWS
- ‚úÖ Research projects
- ‚úÖ Course assignments
- ‚ùå ‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ train ‡∏ö‡πà‡∏≠‡∏¢‡πÜ (credits ‡∏´‡∏°‡∏î‡πÄ‡∏£‡πá‡∏ß)

---

### 12. üéì Google Cloud Platform (GCP) Education

**‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå:** https://cloud.google.com/edu

**Specs:**
- **Credits:** $300 (90 ‡∏ß‡∏±‡∏ô‡πÅ‡∏£‡∏Å)
- **GPU:** T4, V100, A100
- **‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£:** Google account (‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ .edu)

**GPU Instances & Pricing:**
| Instance | GPU | VRAM | ‡∏£‡∏≤‡∏Ñ‡∏≤/‡∏ä‡∏°. | $300 ‡πÑ‡∏î‡πâ‡∏Å‡∏µ‡πà‡∏ä‡∏°. |
|----------|-----|------|---------|---------------|
| n1 + T4 | T4 | 16 GB | $0.95 | ~315 ‡∏ä‡∏°. |
| n1 + V100 | V100 | 16 GB | $2.48 | ~120 ‡∏ä‡∏°. |
| a2 + A100 | A100 | 40 GB | $3.67 | ~81 ‡∏ä‡∏°. |

**‡∏Ç‡πâ‡∏≠‡∏î‡∏µ:**
- ‚úÖ Credits ‡πÄ‡∏¢‡∏≠‡∏∞ ($300)
- ‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏Å‡∏±‡∏ö Colab Pro ‡πÑ‡∏î‡πâ
- ‚úÖ Vertex AI (AutoML)
- ‚úÖ BigQuery integration
- ‚úÖ ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ .edu email

**‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢:**
- ‚ö†Ô∏è Credits ‡∏´‡∏°‡∏î‡πÉ‡∏ô 90 ‡∏ß‡∏±‡∏ô
- ‚ö†Ô∏è GPU quota ‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏≠‡∏ô‡∏∏‡∏°‡∏±‡∏ï‡∏¥
- ‚ö†Ô∏è ‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô (‡πÅ‡∏ï‡πà‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ AWS)

**‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö:**
- ‚úÖ ‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤/‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
- ‚úÖ Short-term projects (90 ‡∏ß‡∏±‡∏ô)
- ‚úÖ Learning cloud platforms

---

## üìä Comparison Table

### ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î

| Platform | GPU | VRAM | ‡∏ä‡∏°./‡πÄ‡∏î‡∏∑‡∏≠‡∏ô | ‡∏£‡∏≤‡∏Ñ‡∏≤ | Reliability | Ease of Use | Best For |
|----------|-----|------|-----------|------|-------------|-------------|----------|
| **Kaggle** | P100 | 16GB | 30/‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå | ‡∏ü‡∏£‡∏µ | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Medium training |
| **Colab** | T4 | 16GB | ~12/‡∏ß‡∏±‡∏ô | ‡∏ü‡∏£‡∏µ | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Quick experiments |
| **Paperspace** | M4000 | 8GB | ‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î | ‡∏ü‡∏£‡∏µ | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | Long training |
| **Lightning AI** | T4 | 16GB | 22 | ‡∏ü‡∏£‡∏µ | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | PyTorch projects |
| **Saturn Cloud** | T4 | 16GB | 150 | ‡∏ü‡∏£‡∏µ | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | Data science |
| **Deepnote** | ‚ùå | - | 750 (CPU) | ‡∏ü‡∏£‡∏µ | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Collaboration |
| **HF Spaces** | ‚ùå | - | - | ‡∏ü‡∏£‡∏µ | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Deployment |
| **Vast.ai** | 3090 | 24GB | ‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î | $0.20/hr | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | Budget training |
| **RunPod** | 4090 | 24GB | ‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î | $0.69/hr | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | Reliable budget |
| **Lambda** | A100 | 40GB | ‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î | $1.10/hr | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | Production ML |
| **AWS Educate** | V100 | 16GB | ~32 ($100) | Credits | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | Students |
| **GCP Edu** | T4 | 16GB | ~315 ($300) | Credits | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | Students |

---

## üéØ Recommendations (‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)

### ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Phone Number ML Project (‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤)

#### ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ó‡∏µ‡πà 1: **Kaggle** ‚≠ê ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î!

**‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•:**
- ‚úÖ P100 GPU ‡πÅ‡∏£‡∏á‡∏û‡∏≠ (‡πÅ‡∏£‡∏á‡∏Å‡∏ß‡πà‡∏≤ T4)
- ‚úÖ 30 ‡∏ä‡∏°./‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠ (6-8 ‡∏ä‡∏°./run)
- ‚úÖ Persistence support (checkpoint ‡πÑ‡∏°‡πà‡∏´‡∏≤‡∏¢)
- ‚úÖ ‡πÄ‡∏£‡∏≤‡∏°‡∏µ package ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏•‡πâ‡∏ß!
- ‚úÖ ‡∏ü‡∏£‡∏µ 100%

**‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà:**
- Training ‡πÅ‡∏£‡∏Å (baseline models)
- Hyperparameter tuning
- Final production training

---

#### ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ó‡∏µ‡πà 2: **Paperspace Gradient**

**‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•:**
- ‚úÖ ‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤ (‡∏£‡∏±‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡∏ß‡∏±‡∏ô‡πÑ‡∏î‡πâ)
- ‚úÖ M4000 ‡∏ä‡πâ‡∏≤‡∏Å‡∏ß‡πà‡∏≤ P100 ‡πÅ‡∏ï‡πà‡∏ó‡∏≥‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏ö
- ‚úÖ ‡∏ü‡∏£‡∏µ 100%
- ‚ö†Ô∏è ‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏≠ queue (5-30 ‡∏ô‡∏≤‡∏ó‡∏µ)

**‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà:**
- Long experiments (>10 ‡∏ä‡∏°.)
- Background training
- Multiple runs ‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á

---

#### ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ó‡∏µ‡πà 3: **Vast.ai** (‡∏à‡πà‡∏≤‡∏¢‡πÄ‡∏á‡∏¥‡∏ô)

**‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•:**
- ‚úÖ RTX 3090 ‡πÅ‡∏£‡∏á‡∏Å‡∏ß‡πà‡∏≤ P100 ‡∏°‡∏≤‡∏Å (~40%)
- ‚úÖ ‡∏ñ‡∏π‡∏Å‡∏°‡∏≤‡∏Å ($0.20/hr √ó 6 ‡∏ä‡∏°. = $1.20 = 42 ‡∏ö‡∏≤‡∏ó)
- ‚úÖ ‡∏£‡∏±‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤ Kaggle ~30%

**‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà:**
- ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏£‡πá‡∏ß
- Kaggle quota ‡∏´‡∏°‡∏î
- Testing production setup

**‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô:**
```
6 ‡∏ä‡∏°. training √ó $0.20/hr = $1.20 (42 ‡∏ö‡∏≤‡∏ó)
vs.
Kaggle: ‡∏ü‡∏£‡∏µ ‡πÅ‡∏ï‡πà‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤ 8 ‡∏ä‡∏°.
```

---

### ‡∏ï‡∏≤‡∏°‡∏Å‡∏£‡∏ì‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ

#### 1. **Quick Experiments (< 2 ‡∏ä‡∏°.)**
‚Üí **Google Colab** (‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏£‡πá‡∏ß, ‡πÉ‡∏ä‡πâ‡∏á‡πà‡∏≤‡∏¢)

#### 2. **Medium Training (2-8 ‡∏ä‡∏°.)**
‚Üí **Kaggle** (GPU ‡πÅ‡∏£‡∏á, persistence)

#### 3. **Long Training (> 10 ‡∏ä‡∏°.)**
‚Üí **Paperspace** (‡∏ü‡∏£‡∏µ, ‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤) ‡∏´‡∏£‡∏∑‡∏≠ **Vast.ai** (‡∏ñ‡πâ‡∏≤‡∏à‡πà‡∏≤‡∏¢‡πÑ‡∏î‡πâ)

#### 4. **Budget Critical**
‚Üí **Vast.ai** ($0.10-0.50/hr)

#### 5. **Reliability Critical**
‚Üí **Lambda Labs** ($1.10/hr) ‡∏´‡∏£‡∏∑‡∏≠ **RunPod** ($0.69/hr)

#### 6. **Learning/Students**
‚Üí **GCP Education** ($300 credits) ‡∏´‡∏£‡∏∑‡∏≠ **Colab** (‡∏ü‡∏£‡∏µ)

#### 7. **Production ML**
‚Üí **Lambda Labs** (H100) ‡∏´‡∏£‡∏∑‡∏≠ **AWS** (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö enterprise)

#### 8. **PyTorch Projects**
‚Üí **Lightning AI** (22 ‡∏ä‡∏°./‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)

#### 9. **Data Science (CPU)**
‚Üí **Deepnote** (750 ‡∏ä‡∏°./‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)

#### 10. **Model Deployment**
‚Üí **Hugging Face Spaces** (‡∏ü‡∏£‡∏µ, inference only)

---

## üí° Cost Optimization Strategies

### ‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå‡∏ó‡∏µ‡πà 1: **Multi-Platform Strategy**

‡πÉ‡∏ä‡πâ‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏ú‡∏™‡∏°‡∏Å‡∏±‡∏ô:

```
Week 1: Kaggle (‡∏ü‡∏£‡∏µ 30 ‡∏ä‡∏°.)
  ‚Üí Quick experiments
  ‚Üí Baseline models
  ‚Üí Initial hyperparameter tuning

Week 2: Paperspace (‡∏ü‡∏£‡∏µ ‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î)
  ‚Üí Long training runs
  ‚Üí Extended experiments
  (‡∏£‡∏≠ queue ‡∏Ç‡∏ì‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏∑‡πà‡∏ô)

Week 3: Saturn Cloud (‡∏ü‡∏£‡∏µ 150 ‡∏ä‡∏°.)
  ‚Üí Final training runs
  ‚Üí Production models

Emergency: Vast.ai ($0.20/hr)
  ‚Üí Rush projects
  ‚Üí Deadline critical
```

---

### ‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå‡∏ó‡∏µ‡πà 2: **Code Optimization**

‡∏•‡∏î training time ‡∏•‡∏á 50-70%:

```python
# 1. ‡∏•‡∏î Optuna trials
N_TRIALS = 50  # ‡πÅ‡∏ó‡∏ô 100 (‡πÄ‡∏£‡πá‡∏ß 2 ‡πÄ‡∏ó‡πà‡∏≤)

# 2. ‡∏•‡∏î Cross-Validation folds
CV_FOLDS = 5  # ‡πÅ‡∏ó‡∏ô 10 (‡πÄ‡∏£‡πá‡∏ß 2 ‡πÄ‡∏ó‡πà‡∏≤)

# 3. Early Stopping
early_stopping = {
    'patience': 10,
    'min_delta': 0.001
}

# 4. Feature Selection
# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏Ñ‡πà top 100 features ‡πÅ‡∏ó‡∏ô 250
max_features = 100  # ‡πÄ‡∏£‡πá‡∏ß ~30%

# ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:
# Training time: 8 ‡∏ä‡∏°. ‚Üí 2-3 ‡∏ä‡∏°. (‡∏•‡∏î 60-70%)
# R¬≤ score: 0.93 ‚Üí 0.90-0.91 (‡∏•‡∏î‡∏ô‡∏¥‡∏î‡∏´‡∏ô‡πà‡∏≠‡∏¢)
```

---

### ‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå‡∏ó‡∏µ‡πà 3: **Spot/Preemptible Instances**

‡πÉ‡∏ä‡πâ spot instances (‡∏ñ‡∏π‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 60-90%):

**Vast.ai:**
- Interruptible instances: ‡∏ñ‡∏π‡∏Å‡∏Å‡∏ß‡πà‡∏≤ ~40%
- ‡πÅ‡∏ï‡πà‡∏≠‡∏≤‡∏à‡πÇ‡∏î‡∏ô interrupt (‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ checkpoint)

**AWS/GCP:**
- Spot instances: ‡∏ñ‡∏π‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 60-90%
- ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: p3.2xlarge spot = $0.92/hr (‡∏õ‡∏Å‡∏ï‡∏¥ $3.06/hr)

**Tips:**
- ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö training ‡∏ó‡∏µ‡πà‡∏°‡∏µ checkpoint
- Set up auto-resume
- ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö non-urgent training

---

### ‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå‡∏ó‡∏µ‡πà 4: **Local GPU (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)**

‡∏ñ‡πâ‡∏≤‡∏°‡∏µ gaming PC:

```bash
# Check GPU
nvidia-smi

# ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ NVIDIA GPU (GTX 1660 ‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏õ):
# 1. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á CUDA Toolkit
# 2. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á PyTorch with CUDA
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# 3. ‡∏£‡∏±‡∏ô training ‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á
python main.py --run-all --optimize --use-gpu

# ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ:
# ‚úÖ ‡∏ü‡∏£‡∏µ 100%
# ‚úÖ ‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤
# ‚úÖ ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏≠ queue

# ‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢:
# ‚ö†Ô∏è Gaming GPU ‡∏ä‡πâ‡∏≤‡∏Å‡∏ß‡πà‡∏≤ datacenter GPU
# ‚ö†Ô∏è ‡πÑ‡∏ü‡∏ü‡πâ‡∏≤ ~5-10 ‡∏ö‡∏≤‡∏ó/‡∏ä‡∏°. (‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö‡∏£‡∏≤‡∏Ñ‡∏≤‡πÑ‡∏ü)
```

**GPU Performance Comparison:**
- GTX 1660 Ti: ~70% ‡∏ä‡πâ‡∏≤‡∏Å‡∏ß‡πà‡∏≤ T4
- RTX 3060: ~30% ‡∏ä‡πâ‡∏≤‡∏Å‡∏ß‡πà‡∏≤ T4
- RTX 3080: ‡πÄ‡∏£‡πá‡∏ß‡∏û‡∏≠‡πÜ P100
- RTX 3090: ‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤ P100 ~40%
- RTX 4090: ‡πÄ‡∏£‡πá‡∏ß‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (‡πÅ‡∏£‡∏á‡∏Å‡∏ß‡πà‡∏≤ P100 ~2 ‡πÄ‡∏ó‡πà‡∏≤)

---

### ‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå‡∏ó‡∏µ‡πà 5: **Scheduled Training**

‡∏£‡∏±‡∏ô‡∏ï‡∏≠‡∏ô‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ñ‡∏π‡∏Å:

**Vast.ai:**
- Queue ‡∏™‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô: 2-6 AM UTC (9-13 ‡∏ô. ‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏ó‡∏¢)
- ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ñ‡∏π‡∏Å‡∏•‡∏á ~20-30%

**Cloud Providers:**
- Spot instances ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î: ‡∏Å‡∏•‡∏≤‡∏á‡∏Ñ‡∏∑‡∏ô + weekend

**Kaggle:**
- ‡πÉ‡∏ä‡πâ quota ‡∏ï‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå (‡∏ß‡∏±‡∏ô‡∏à‡∏±‡∏ô‡∏ó‡∏£‡πå‡∏´‡∏•‡∏±‡∏á reset)

---

## üöÄ Quick Start Links

### Free Platforms

1. **Kaggle**
   - Sign up: https://www.kaggle.com/account/login
   - Docs: https://www.kaggle.com/docs/notebooks
   - GPU Guide: https://www.kaggle.com/docs/efficient-gpu-usage

2. **Google Colab**
   - Start: https://colab.research.google.com/
   - Pro: https://colab.research.google.com/signup
   - Tips: https://colab.research.google.com/notebooks/gpu.ipynb

3. **Paperspace Gradient**
   - Sign up: https://console.paperspace.com/signup
   - Docs: https://docs.paperspace.com/gradient/
   - Free GPU: https://www.paperspace.com/pricing

4. **Lightning AI**
   - Sign up: https://lightning.ai/
   - Docs: https://lightning.ai/docs/
   - Studios: https://lightning.ai/studios

5. **Saturn Cloud**
   - Sign up: https://saturncloud.io/start/
   - Docs: https://saturncloud.io/docs/
   - Free tier: https://saturncloud.io/pricing/

---

### Paid Platforms

6. **Vast.ai**
   - Sign up: https://cloud.vast.ai/
   - Pricing: https://vast.ai/pricing
   - Templates: https://vast.ai/templates/

7. **RunPod**
   - Sign up: https://www.runpod.io/console/signup
   - Pricing: https://www.runpod.io/gpu-instance/pricing
   - Templates: https://www.runpod.io/console/explore

8. **Lambda Labs**
   - Sign up: https://lambdalabs.com/service/gpu-cloud
   - Pricing: https://lambdalabs.com/service/gpu-cloud#pricing
   - Docs: https://docs.lambdalabs.com/

---

### Student Programs

9. **AWS Educate**
   - Apply: https://aws.amazon.com/education/awseducate/
   - Academy: https://aws.amazon.com/training/awsacademy/
   - Free tier: https://aws.amazon.com/free/

10. **GCP Education**
    - Credits: https://cloud.google.com/edu
    - Free tier: https://cloud.google.com/free
    - Compute Engine: https://cloud.google.com/compute/docs/gpus

---

## üìö Additional Resources

### GPU Learning Resources

- **CUDA Tutorial:** https://developer.nvidia.com/cuda-zone
- **PyTorch GPU:** https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html
- **TensorFlow GPU:** https://www.tensorflow.org/guide/gpu

### Benchmark Comparisons

- **GPU Benchmarks:** https://lambdalabs.com/gpu-benchmarks
- **ML Performance:** https://www.pugetsystems.com/labs/hpc/

### Community Forums

- **r/MachineLearning:** https://reddit.com/r/MachineLearning
- **Kaggle Forums:** https://www.kaggle.com/discussions
- **Fast.ai Forums:** https://forums.fast.ai/

---

## üéØ Final Recommendations for Phone Number ML Project

### Best Free Option: **Kaggle**
```
GPU: P100 (16 GB)
Time: 6-8 hours/run
Cost: ‡∏ü‡∏£‡∏µ
Reliability: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
Package: number-ML-kaggle-MODERN-20251005.zip
Status: ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ! ‚úÖ
```

### Best Paid Option: **Vast.ai**
```
GPU: RTX 3090 (24 GB)
Time: 4-6 hours/run (‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤ 30%)
Cost: $0.80-1.20/run (~28-42 ‡∏ö‡∏≤‡∏ó)
Reliability: ‚≠ê‚≠ê‚≠ê
Setup: ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ Docker
```

### Backup Option: **Paperspace**
```
GPU: M4000 (8 GB)
Time: 10-12 hours/run (‡∏ä‡πâ‡∏≤‡∏Å‡∏ß‡πà‡∏≤ 30%)
Cost: ‡∏ü‡∏£‡∏µ (‡πÅ‡∏ï‡πà‡∏£‡∏≠ queue)
Reliability: ‚≠ê‚≠ê‚≠ê‚≠ê
Best for: Long training, non-urgent
```

---

## üìû Support & Questions

‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠:

- **Kaggle:** https://www.kaggle.com/discussions
- **Paperspace:** https://docs.paperspace.com/
- **Vast.ai:** https://vast.ai/faq
- **RunPod:** https://docs.runpod.io/

---

**Created:** 2025-10-05
**Last Updated:** 2025-10-05
**Version:** 1.0
**Author:** Claude Code Assistant
**Project:** ML Phone Number Price Prediction

---

**‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏:**
- ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏ä‡πá‡∏Ñ‡∏ó‡∏µ‡πà‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
- Quota ‡πÅ‡∏•‡∏∞ limits ‡∏≠‡∏≤‡∏à‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏ï‡∏≤‡∏°‡∏ö‡∏±‡∏ç‡∏ä‡∏µ
- GPU availability ‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ (peak time ‡∏≠‡∏≤‡∏à‡∏´‡∏°‡∏î)
