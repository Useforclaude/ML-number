"""
Data Handler for ML Project - Load and Clean Data
By Alex - World-Class AI Expert
"""
import pandas as pd
import numpy as np
import os
import warnings
from collections import defaultdict
warnings.filterwarnings('ignore')

from src.config import CONFIG, DATA_PATH, BASE_PATH, ENV_TYPE, DATA_CONFIG
from src.features import PREMIUM_SUFFIX_WEIGHTS

# ====================================================================================
# HELPER FUNCTIONS
# ====================================================================================
def find_phone_column(df):
    """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥"""
    possible_names = DATA_CONFIG['phone_column_names']
    
    for col in df.columns:
        if any(name in col.lower() for name in possible_names):
            print(f"‚úÖ ‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£: '{col}'")
            return col
    
    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠ ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡∏à‡∏≤‡∏Å pattern
    for col in df.columns:
        sample = df[col].astype(str).iloc[0]
        if len(sample) == 10 and sample.isdigit():
            print(f"‚úÖ ‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£ (‡∏à‡∏≤‡∏Å pattern): '{col}'")
            return col
    
    raise ValueError("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå!")

def find_price_column(df):
    """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏£‡∏≤‡∏Ñ‡∏≤‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥"""
    possible_names = DATA_CONFIG['price_column_names']
    
    for col in df.columns:
        if any(name in col.lower() for name in possible_names):
            print(f"‚úÖ ‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏£‡∏≤‡∏Ñ‡∏≤: '{col}'")
            return col
    
    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠ ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    if len(numeric_cols) == 1:
        col = numeric_cols[0]
        print(f"‚úÖ ‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏£‡∏≤‡∏Ñ‡∏≤ (‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•): '{col}'")
        return col
    
    raise ValueError("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏£‡∏≤‡∏Ñ‡∏≤!")

def clean_phone_number(phone):
    """‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå"""
    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô string ‡πÅ‡∏•‡∏∞‡∏•‡∏ö‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á
    phone_str = str(phone).strip().replace(' ', '').replace('-', '')
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö
    if phone_str.startswith('+66'):
        phone_str = '0' + phone_str[3:]
    elif phone_str.startswith('66') and len(phone_str) == 11:
        phone_str = '0' + phone_str[2:]
    elif phone_str.startswith('0') and len(phone_str) == 10:
        pass  # ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß
    elif len(phone_str) == 9:
        phone_str = '0' + phone_str
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
    if len(phone_str) == 10 and phone_str.isdigit() and phone_str[0] == '0':
        return phone_str
    else:
        return None

# ====================================================================================
# MAIN DATA LOADING FUNCTION
# ====================================================================================
def load_and_clean_data(file_path=None, auto_clean=True, filter_outliers_param=True, max_price=100000):
    """
    ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå

    Parameters:
    -----------
    file_path : str, optional
        Path to data file. If None, will look for files in data/raw/
    auto_clean : bool
        Whether to automatically clean the data
    filter_outliers_param : bool
        Whether to filter price outliers (‚â•100k)
    max_price : int
        Maximum price threshold for filtering (default: 100,000)

    Returns:
    --------
    df_raw : pd.DataFrame
        Raw data
    df_cleaned : pd.DataFrame
        Cleaned data
    """
    print("="*100)
    print("üìÇ LOADING AND CLEANING DATA")
    print("="*100)
    
    # Find data file if not specified
    if file_path is None:
        raw_data_path = os.path.join(DATA_PATH, 'raw')
        if os.path.exists(raw_data_path):
            csv_files = [f for f in os.listdir(raw_data_path) if f.endswith('.csv')]
            if csv_files:
                file_path = os.path.join(raw_data_path, csv_files[0])
                print(f"üìÅ Found data file: {file_path}")
            else:
                # Use centralized configuration from DATA_CONFIG
                default_files = DATA_CONFIG['default_filenames']
                search_paths = DATA_CONFIG['search_paths']

                # Search for data files
                for search_dir in search_paths:
                    if not os.path.exists(search_dir):
                        continue
                    for filename in default_files:
                        potential_path = os.path.join(search_dir, filename)
                        if os.path.exists(potential_path):
                            file_path = potential_path
                            print(f"üìÅ Auto-detected data file: {file_path}")
                            break
                    if file_path:
                        break
    
    if file_path is None or not os.path.exists(file_path):
        raise FileNotFoundError("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•! ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏∞‡∏ö‡∏∏ path ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
    
    # Load data
    print(f"\nüìä Loading data from: {file_path}")
    df_raw = pd.read_csv(file_path)
    print(f"‚úÖ Loaded {len(df_raw):,} rows")
    
    # Auto detect columns
    phone_col = find_phone_column(df_raw)
    price_col = find_price_column(df_raw)
    
    # Rename columns for consistency
    df_raw = df_raw.rename(columns={
        phone_col: 'phone_number',
        price_col: 'price'
    })
    
    # Show sample
    print("\n‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö:")
    print(df_raw[['phone_number', 'price']].head())
    
    if not auto_clean:
        return df_raw, None
    
    # Clean data
    print("\nüßπ Cleaning data...")
    
    # Make a copy
    df_cleaned = df_raw.copy()
    
    # Clean phone numbers
    print("\nüì± Cleaning phone numbers...")
    df_cleaned['phone_number'] = df_cleaned['phone_number'].apply(clean_phone_number)
    
    # Remove invalid phone numbers
    initial_count = len(df_cleaned)
    df_cleaned = df_cleaned.dropna(subset=['phone_number'])
    removed_count = initial_count - len(df_cleaned)
    if removed_count > 0:
        print(f"   - ‡∏•‡∏ö‡πÄ‡∏ö‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á: {removed_count:,} ‡πÄ‡∏ö‡∏≠‡∏£‡πå")
    
    # Clean prices
    print("\nüí∞ Cleaning prices...")
    df_cleaned['price'] = pd.to_numeric(df_cleaned['price'], errors='coerce')
    df_cleaned = df_cleaned.dropna(subset=['price'])
    
    # Remove outliers using domain knowledge
    print("\nüìä ‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏£‡∏≤‡∏Ñ‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î:")
    print(df_cleaned['price'].describe())
    
    # Calculate percentiles for outlier removal
    p01 = df_cleaned['price'].quantile(0.001)
    p99_9 = df_cleaned['price'].quantile(0.999)
    
    # Filter outliers
    initial_count = len(df_cleaned)
    df_cleaned = df_cleaned[
        (df_cleaned['price'] >= max(50, p01)) &
        (df_cleaned['price'] <= min(10_000_000, p99_9 * 1.5))
    ].copy()
    
    outliers_removed = initial_count - len(df_cleaned)
    print(f"\nüîß Removed {outliers_removed:,} outliers")
    print(f"   - Price range: ‡∏ø{df_cleaned['price'].min():,.0f} - ‡∏ø{df_cleaned['price'].max():,.0f}")
    
    # Show distribution
    print("\nüíé ‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡πÄ‡∏ö‡∏≠‡∏£‡πå‡∏ï‡∏≤‡∏°‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏£‡∏≤‡∏Ñ‡∏≤:")
    price_ranges = [
        (100, 1000), (1000, 10000), (10000, 50000),
        (50000, 100000), (100000, 500000), (500000, float('inf'))
    ]
    
    for low, high in price_ranges:
        if high == float('inf'):
            count = len(df_cleaned[df_cleaned['price'] >= low])
            print(f"   - ‡∏£‡∏≤‡∏Ñ‡∏≤ ‚â• ‡∏ø{low:,}: {count:,} ‡πÄ‡∏ö‡∏≠‡∏£‡πå")
        else:
            count = len(df_cleaned[(df_cleaned['price'] >= low) & (df_cleaned['price'] < high)])
            print(f"   - ‡∏£‡∏≤‡∏Ñ‡∏≤ ‡∏ø{low:,} - ‡∏ø{high:,}: {count:,} ‡πÄ‡∏ö‡∏≠‡∏£‡πå")
    
    # Remove duplicates
    initial_count = len(df_cleaned)
    df_cleaned = df_cleaned.drop_duplicates(subset=['phone_number'])
    duplicates_removed = initial_count - len(df_cleaned)
    if duplicates_removed > 0:
        print(f"\nüîÑ Removed {duplicates_removed:,} duplicate phone numbers")
    
    # Final summary
    print("\nüìä ‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:")
    print(f"   - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö: {len(df_raw):,} ‡πÅ‡∏ñ‡∏ß")
    print(f"   - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏∞‡∏≠‡∏≤‡∏î: {len(df_cleaned):,} ‡πÅ‡∏ñ‡∏ß")
    print(f"   - ‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠: {len(df_cleaned)/len(df_raw)*100:.1f}%")
    
    # Reset index
    df_cleaned = df_cleaned.reset_index(drop=True)

    # Filter outliers if requested (NEW - Session 012)
    if filter_outliers_param:
        from src.data_filter import filter_outliers
        df_cleaned = filter_outliers(df_cleaned, max_price=max_price, verbose=True)

    # Save cleaned data
    cleaned_path = os.path.join(DATA_PATH, 'processed', 'cleaned_data.csv')
    os.makedirs(os.path.dirname(cleaned_path), exist_ok=True)
    df_cleaned.to_csv(cleaned_path, index=False)
    print(f"\nüíæ Saved cleaned data to: {cleaned_path}")

    print("\n‚úÖ Data loading and cleaning completed!")
    print("="*100)

    return df_raw, df_cleaned

# ====================================================================================
# ADDITIONAL DATA UTILITIES
# ====================================================================================
def get_data_info(df):
    """Get detailed information about the dataset"""
    info = {
        'shape': df.shape,
        'columns': list(df.columns),
        'dtypes': df.dtypes.to_dict(),
        'missing_values': df.isnull().sum().to_dict(),
        'duplicates': df.duplicated().sum(),
        'memory_usage': df.memory_usage(deep=True).sum() / 1024**2  # MB
    }
    
    if 'price' in df.columns:
        info['price_stats'] = {
            'min': df['price'].min(),
            'max': df['price'].max(),
            'mean': df['price'].mean(),
            'median': df['price'].median(),
            'std': df['price'].std()
        }
    
    return info

def validate_phone_numbers(df, phone_col='phone_number'):
    """Validate phone numbers in dataframe"""
    invalid_phones = []
    
    for idx, phone in df[phone_col].items():
        if pd.isna(phone):
            invalid_phones.append((idx, phone, "Missing value"))
        elif not str(phone).startswith('0'):
            invalid_phones.append((idx, phone, "Doesn't start with 0"))
        elif len(str(phone)) != 10:
            invalid_phones.append((idx, phone, f"Invalid length: {len(str(phone))}"))
        elif not str(phone).isdigit():
            invalid_phones.append((idx, phone, "Contains non-numeric characters"))
    
    if invalid_phones:
        print(f"‚ö†Ô∏è Found {len(invalid_phones)} invalid phone numbers")
        return pd.DataFrame(invalid_phones, columns=['index', 'phone_number', 'issue'])
    else:
        print("‚úÖ All phone numbers are valid")
        return None

def create_price_bins(df, price_col='price', n_bins=10):
    """Create price bins for stratification"""
    df['price_bin'] = pd.qcut(df[price_col], q=n_bins, labels=False, duplicates='drop')
    df['price_category'] = pd.qcut(
        df[price_col], 
        q=[0, 0.25, 0.5, 0.75, 0.9, 1.0],
        labels=['low', 'medium-low', 'medium', 'medium-high', 'high']
    )
    return df

# ====================================================================================
# NEW FUNCTIONS FOR DATA LEAKAGE FIX
# ====================================================================================

def calculate_sample_weights(df, is_train=True):
    """
    Calculate sample weights for training data only
    
    Parameters:
    -----------
    df : DataFrame with 'price' column
    is_train : bool, if False returns weight=1 for all
    
    Returns:
    --------
    df : DataFrame with added 'sample_weight' column
    """
    df = df.copy()
    
    if not is_train:
        df['sample_weight'] = 1.0
        return df
    
    print("‚öñÔ∏è Calculating sample weights from TRAINING data...")
    
    prices = df['price'].clip(lower=100)
    price_log = np.log1p(prices)
    log_scaled = (price_log - price_log.min()) / (price_log.max() - price_log.min() + 1e-9)

    # Base weighting grows smoothly with log price (focus on upper tail)
    base_weight = 0.6 + 1.7 * np.power(log_scaled, 1.25)

    # Tier boosts for premium ranges
    tier_boost = np.select(
        [
            prices >= 50000,
            prices >= 20000,
            prices >= 10000,
            prices >= 5000
        ],
        [2.0, 1.2, 0.8, 0.4],
        default=0.0
    )

    # Slight penalty for very low prices to balance the distribution
    low_price_penalty = np.where(prices < 800, 0.25, 0.0)

    sample_weights = base_weight + tier_boost + low_price_penalty

    # Normalize and guard against extremely small weights
    sample_weights = np.clip(sample_weights, 0.3, None)
    sample_weights = sample_weights / sample_weights.mean()

    df['sample_weight'] = sample_weights
    print(f"‚úÖ Sample weights calculated for {len(df)} samples")
    return df

def calculate_market_statistics(train_df):
    """
    Calculate market statistics from TRAINING data only
    
    Parameters:
    -----------
    train_df : DataFrame with 'phone_number' and 'price' columns
    
    Returns:
    --------
    dict : Market statistics for use in feature engineering
    """
    print("üìä Calculating market statistics from TRAINING data...")
    
    pattern_prices = {}
    premium_suffix_prices = defaultdict(list)
    
    for idx, row in train_df.iterrows():
        phone = str(row['phone_number'])
        price = row['price']
        
        # Ending patterns
        for length in [3, 4]:
            if len(phone) >= length:
                pattern = phone[-length:]
                if pattern not in pattern_prices:
                    pattern_prices[pattern] = []
                pattern_prices[pattern].append(price)
                if pattern in PREMIUM_SUFFIX_WEIGHTS:
                    premium_suffix_prices[pattern].append(price)
        
        # ABC pattern
        if len(phone) >= 6:
            abc = phone[3:6]
            if abc not in pattern_prices:
                pattern_prices[abc] = []
            pattern_prices[abc].append(price)
    
    # Calculate averages and popularity
    pattern_avg_prices = {}
    pattern_popularity = {}
    
    for pattern, prices in pattern_prices.items():
        if len(prices) >= 2:
            pattern_avg_prices[pattern] = np.median(prices)
            pattern_popularity[pattern] = len(prices)
    
    print(f"‚úÖ Market statistics calculated from {len(train_df)} training samples")

    premium_suffix_stats = {
        suffix: float(np.median(prices))
        for suffix, prices in premium_suffix_prices.items()
        if len(prices) >= 2
    }

    return {
        'avg_prices': pattern_avg_prices,
        'popularity': pattern_popularity,
        'n_train_samples': len(train_df),
        'premium_suffix_stats': premium_suffix_stats,
        'global_median': float(train_df['price'].median()),
        'global_mean': float(train_df['price'].mean())
    }
