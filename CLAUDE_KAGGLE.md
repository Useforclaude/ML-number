# ü§ñ CLAUDE.md - Instructions for Claude Code

## üìã Project Overview

**‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ**: ML Phone Number Price Prediction (‡πÄ‡∏ö‡∏≠‡∏£‡πå‡∏°‡∏∑‡∏≠‡∏ñ‡∏∑‡∏≠‡∏°‡∏á‡∏Ñ‡∏•)  
**‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢**: ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• ML ‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ R¬≤ > 0.90 ‡πÇ‡∏î‡∏¢‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÇ‡∏Ñ‡πâ‡∏î‡∏î‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏ß‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î  
**Platform**: Kaggle Notebook

---

## üéØ Mission Statement

**‡∏Ç‡πâ‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (‡∏´‡πâ‡∏≤‡∏°‡∏ù‡πà‡∏≤‡∏ù‡∏∑‡∏ô):**

```plaintext
‚ùå ‡∏´‡πâ‡∏≤‡∏°‡∏•‡∏î‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô
‚ùå ‡∏´‡πâ‡∏≤‡∏°‡∏•‡∏î‡πÇ‡∏Ñ‡πâ‡∏î
‚ùå ‡∏´‡πâ‡∏≤‡∏°‡∏•‡∏î‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô
‚ùå ‡∏´‡πâ‡∏≤‡∏°‡∏•‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤
‚ùå ‡∏´‡πâ‡∏≤‡∏°‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î
‚ùå ‡∏´‡πâ‡∏≤‡∏°‡∏õ‡∏£‡∏±‡∏ö features, config, model parameters
‚ùå ‡∏´‡πâ‡∏≤‡∏°‡∏Ç‡πâ‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏î‡πÜ

‚úÖ ‡∏ï‡πâ‡∏≠‡∏á Train models ‡∏Ñ‡∏£‡∏ö‡∏ó‡∏∏‡∏Å‡∏ï‡∏±‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î
‚úÖ ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÉ‡∏´‡πâ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à (‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)
‚úÖ ‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏≤‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà‡∏Å‡πá‡πÑ‡∏î‡πâ ‡∏Ç‡∏≠‡πÅ‡∏Ñ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏ó‡∏£‡∏ô‡∏°‡∏≤‡∏Ñ‡∏£‡∏ö‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå
‚úÖ ‡∏ó‡∏≥‡∏ï‡∏≤‡∏°‡∏™‡∏±‡πà‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡πÄ‡∏Å‡∏¥‡∏ô
```

---

## üìÅ Project Structure

```
ML_Project_Refactored/
‚îú‚îÄ‚îÄ üìÇ src/
‚îÇ   ‚îú‚îÄ‚îÄ config.py              # Configuration ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
‚îÇ   ‚îú‚îÄ‚îÄ data_handler.py        # Load & Clean data
‚îÇ   ‚îú‚îÄ‚îÄ features.py            # Feature Engineering (250+ features)
‚îÇ   ‚îú‚îÄ‚îÄ data_splitter.py       # Data splitting strategies
‚îÇ   ‚îú‚îÄ‚îÄ model_utils.py         # Model utilities & preprocessing
‚îÇ   ‚îú‚îÄ‚îÄ tier_models.py         # Tier-based modeling
‚îÇ   ‚îú‚îÄ‚îÄ train.py               # Training pipeline
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py            # Model evaluation
‚îÇ   ‚îî‚îÄ‚îÄ visualize.py           # Visualization functions
‚îÇ
‚îú‚îÄ‚îÄ üìÇ api/
‚îÇ   ‚îú‚îÄ‚îÄ prediction.py          # Prediction pipeline
‚îÇ   ‚îî‚îÄ‚îÄ app.py                 # API implementation
‚îÇ
‚îú‚îÄ‚îÄ üìÇ models/
‚îÇ   ‚îî‚îÄ‚îÄ deployed/              # Trained models
‚îÇ
‚îú‚îÄ‚îÄ üìÇ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                   # Raw data
‚îÇ   ‚îî‚îÄ‚îÄ processed/             # Processed data
‚îÇ
‚îú‚îÄ‚îÄ üìÇ utils/
‚îÇ   ‚îî‚îÄ‚îÄ helpers.py             # Helper functions
‚îÇ
‚îú‚îÄ‚îÄ main.py                    # Main pipeline script
‚îî‚îÄ‚îÄ requirements.txt           # Dependencies
```

---

## üêõ Known Issues & Critical Fixes

### 1. **Import Errors** (Critical)
```python
# ‚ùå ‡∏ú‡∏¥‡∏î
from config import CONFIG
from model_utils import optimize_xgboost

# ‚úÖ ‡∏ñ‡∏π‡∏Å
from src.config import CONFIG
from src.model_utils import optimize_xgboost
```

**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ**:
- ‡πÅ‡∏Å‡πâ‡∏ó‡∏∏‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô `src/` ‡πÉ‡∏´‡πâ import ‡∏à‡∏≤‡∏Å `src.xxx`
- ‡πÉ‡∏ä‡πâ absolute imports ‡πÅ‡∏ó‡∏ô relative imports

### 2. **KeyError ‡πÉ‡∏ô Hyperparameters**
```python
# ‚ùå ‡πÄ‡∏Å‡∏¥‡∏î KeyError
params = {
    'n_estimators': trial.suggest_int('n_estimators_xgb', 100, 1000)
}

# ‚úÖ ‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠ parameter ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô
params = {
    'n_estimators': trial.suggest_int('xgb_n_estimators', 100, 1000),
    'max_depth': trial.suggest_int('xgb_max_depth', 3, 15),
    'learning_rate': trial.suggest_float('xgb_learning_rate', 0.01, 0.3)
}
```

### 3. **Feature Grouping Bug**
```python
# ‚ùå ‡∏ú‡∏¥‡∏î - ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏°‡∏µ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô
feature_groups = {
    'power_features': ['power_sum', 'weighted_sum'],
    'count_features': ['power_sum', 'digit_count']  # ‡∏ã‡πâ‡∏≥!
}

# ‚úÖ ‡∏ñ‡∏π‡∏Å - ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ã‡πâ‡∏≥
feature_groups = {
    'power_features': ['power_sum', 'weighted_sum'],
    'count_features': ['digit_count', 'unique_count']
}
```

### 4. **Data Leakage ‡πÉ‡∏ô Market Features**
```python
# ‚ùå ‡∏ú‡∏¥‡∏î - ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡∏£‡∏ß‡∏° test set)
market_stats = calculate_market_statistics(df)

# ‚úÖ ‡∏ñ‡∏π‡∏Å - ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ training set
train_df = df.iloc[train_idx]
market_stats = calculate_market_statistics(train_df)
```

### 5. **NaN/Inf Handling**
```python
# ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏™‡πà‡∏´‡∏•‡∏±‡∏á preprocessing ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á
X_processed = X_processed.replace([np.inf, -np.inf], np.nan)
X_processed = X_processed.fillna(X_processed.median())
```

### 6. **GPU Parameters on CPU**
```python
# ‚ùå ‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ‡∏ö‡∏ô Kaggle (‡πÑ‡∏°‡πà‡∏°‡∏µ GPU)
params = {
    'task_type': 'GPU',
    'devices': '0:1'
}

# ‚úÖ ‡πÉ‡∏ä‡πâ CPU
params = {
    'task_type': 'CPU',
    'thread_count': -1
}
```

### 7. **Hardcoded Paths**
```python
# ‚ùå Hardcoded
REFACTORING_PATH = '/kaggle/working/ML_Project_Refactored'

# ‚úÖ ‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô
REFACTORING_PATH = os.getenv('KAGGLE_WORKING_DIR', '/kaggle/working/ML_Project_Refactored')
```

---

## üîß Setup Instructions for Kaggle

### Cell 1: Complete Setup

```python
import os
import sys
import shutil
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

print("="*100)
print("üöÄ PHONE NUMBER PRICE PREDICTION - SETUP")
print("="*100)

# ====================================================================================
# 1. Copy Project Files
# ====================================================================================
input_dir = '/kaggle/input/project-refactored/ML_Project_Refactored'
working_dir = '/kaggle/working/ML_Project_Refactored'

if not os.path.exists(working_dir):
    shutil.copytree(input_dir, working_dir)
    print("‚úÖ Project files copied")

os.chdir(working_dir)
sys.path.insert(0, working_dir)
sys.path.insert(0, os.path.join(working_dir, 'src'))

# ====================================================================================
# 2. Create Directories
# ====================================================================================
os.makedirs(f'{working_dir}/data/raw', exist_ok=True)
os.makedirs(f'{working_dir}/data/processed', exist_ok=True)
os.makedirs(f'{working_dir}/models/deployed', exist_ok=True)
os.makedirs(f'{working_dir}/results', exist_ok=True)
print("‚úÖ Directories created")

# ====================================================================================
# 3. Prepare Data
# ====================================================================================
df = pd.read_csv('/kaggle/input/project-refactored/numberdata.csv')

# Fix column names
if 'phone_num' in df.columns:
    df.rename(columns={'phone_num': 'phone_number'}, inplace=True)

# Clean phone numbers
df['phone_number'] = df['phone_number'].astype(str).str.replace(r'\D', '', regex=True).str.zfill(10)

# Filter valid data
df = df[df['phone_number'].str.len() == 10]
df = df[(df['price'] > 0) & (df['price'] <= 10000000)]

# Save
df.to_csv(f'{working_dir}/data/raw/numberdata.csv', index=False)
df.to_csv('/kaggle/working/numberdata.csv', index=False)
print(f"‚úÖ Data ready: {len(df)} records")

# ====================================================================================
# 4. Fix Module Imports (Critical!)
# ====================================================================================
files_to_fix = {
    'src/data_handler.py': [('from config import', 'from src.config import')],
    'src/features.py': [('from config import', 'from src.config import')],
    'src/data_splitter.py': [('from config import', 'from src.config import')],
    'src/model_utils.py': [
        ('from config import', 'from src.config import'),
        ('from sklearn.preprocessing import SimpleImputer', 'from sklearn.impute import SimpleImputer')
    ],
    'src/train.py': [
        ('from config import', 'from src.config import'),
        ('from model_utils import', 'from src.model_utils import')
    ],
    'src/evaluate.py': [('from config import', 'from src.config import')],
    'src/visualize.py': [('from config import', 'from src.config import')]
}

for file_path, replacements in files_to_fix.items():
    full_path = os.path.join(working_dir, file_path)
    if os.path.exists(full_path):
        with open(full_path, 'r') as f:
            content = f.read()
        for old, new in replacements:
            content = content.replace(old, new)
        with open(full_path, 'w') as f:
            f.write(content)

print("‚úÖ Module imports fixed")

# ====================================================================================
# 5. Fix config.py
# ====================================================================================
config_file = f'{working_dir}/src/config.py'
with open(config_file, 'r') as f:
    content = f.read()

content = content.replace(
    "BASE_PATH = Path(os.path.dirname(os.path.abspath(__file__))).parent",
    f"BASE_PATH = Path('{working_dir}')"
)

if 'POWER_WEIGHTS' not in content:
    content += "\nCONFIG['POWER_WEIGHTS'] = {str(i): i for i in range(10)}"

with open(config_file, 'w') as f:
    f.write(content)

print("‚úÖ config.py fixed")

# ====================================================================================
# 6. Install Packages
# ====================================================================================
print("\nüì¶ Installing packages...")
os.system("pip install scipy scikit-learn xgboost lightgbm catboost optuna seaborn matplotlib joblib -q")

print("\n" + "="*100)
print("‚úÖ SETUP COMPLETE!")
print("="*100)
```

### Cell 2: Full Training Pipeline

```python
import sys
import os
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

# Setup paths
sys.path.clear()
sys.path.insert(0, '/kaggle/working/ML_Project_Refactored')
sys.path.insert(1, '/kaggle/working/ML_Project_Refactored/src')
os.chdir('/kaggle/working/ML_Project_Refactored')

print("="*100)
print("üî• FULL TRAINING PIPELINE")
print("="*100)

# Import modules
from src.config import CONFIG, MODEL_CONFIG
from src.data_handler import load_and_clean_data, calculate_sample_weights, calculate_market_statistics
from src.features import create_all_features
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# ====================================================================================
# 1. LOAD DATA
# ====================================================================================
print("\nüìä [1/5] Loading data...")

df_raw, df_cleaned = load_and_clean_data('/kaggle/working/numberdata.csv')

if 'log_price' not in df_cleaned.columns:
    df_cleaned['log_price'] = np.log1p(df_cleaned['price'])

df_cleaned = calculate_sample_weights(df_cleaned)

# Split indices (for preventing data leakage)
train_idx, test_idx = train_test_split(
    range(len(df_cleaned)), test_size=0.2, random_state=42
)

# Calculate market stats from training data only
train_df = df_cleaned.iloc[train_idx]
try:
    market_stats = calculate_market_statistics(train_df)
except:
    market_stats = {}

print(f"‚úÖ Data loaded: {len(df_cleaned)} records")

# ====================================================================================
# 2. CREATE FEATURES
# ====================================================================================
print("\nüéØ [2/5] Creating features (250+)...")

result = create_all_features(df_cleaned, market_stats=market_stats)
df_features = result[0] if isinstance(result, tuple) else result

if 'log_price' not in df_features.columns:
    df_features['log_price'] = df_cleaned['log_price']

# Get numeric features
exclude_cols = ['phone_number', 'price', 'log_price', 'sample_weight']
feature_cols = [col for col in df_features.columns if col not in exclude_cols]
numeric_features = [col for col in feature_cols 
                   if df_features[col].dtype in ['float64', 'int64', 'float32', 'int32']]

X = df_features[numeric_features]
y = df_features['log_price']

# Clean data
X = X.replace([np.inf, -np.inf], np.nan)
X = X.fillna(X.median())

# Split
X_train = X.iloc[train_idx]
X_test = X.iloc[test_idx]
y_train = y.iloc[train_idx]
y_test = y.iloc[test_idx]

# Scale
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print(f"‚úÖ Features created: {X_train_scaled.shape[1]}")

# ====================================================================================
# 3. TRAIN MODELS (‡∏Ñ‡∏£‡∏ö‡∏ó‡∏∏‡∏Å‡∏ï‡∏±‡∏ß)
# ====================================================================================
print("\nüöÄ [3/5] Training all models...")

import xgboost as xgb
import lightgbm as lgb
import catboost as cb
from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor
from sklearn.metrics import r2_score

models = {}
predictions = {}

# XGBoost
print("\nüìà Training XGBoost...")
xgb_model = xgb.XGBRegressor(
    n_estimators=1000,
    max_depth=10,
    learning_rate=0.05,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    verbosity=0
)
xgb_model.fit(X_train_scaled, y_train)
predictions['XGBoost'] = xgb_model.predict(X_test_scaled)
models['XGBoost'] = xgb_model
print(f"   ‚úÖ XGBoost R¬≤: {r2_score(y_test, predictions['XGBoost']):.4f}")

# LightGBM
print("\nüìà Training LightGBM...")
lgb_model = lgb.LGBMRegressor(
    n_estimators=1000,
    max_depth=10,
    learning_rate=0.05,
    num_leaves=100,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    verbosity=-1
)
lgb_model.fit(X_train_scaled, y_train)
predictions['LightGBM'] = lgb_model.predict(X_test_scaled)
models['LightGBM'] = lgb_model
print(f"   ‚úÖ LightGBM R¬≤: {r2_score(y_test, predictions['LightGBM']):.4f}")

# CatBoost
print("\nüìà Training CatBoost...")
cat_model = cb.CatBoostRegressor(
    iterations=1000,
    depth=10,
    learning_rate=0.05,
    random_state=42,
    verbose=False
)
cat_model.fit(X_train_scaled, y_train)
predictions['CatBoost'] = cat_model.predict(X_test_scaled)
models['CatBoost'] = cat_model
print(f"   ‚úÖ CatBoost R¬≤: {r2_score(y_test, predictions['CatBoost']):.4f}")

# RandomForest
print("\nüìà Training RandomForest...")
rf_model = RandomForestRegressor(
    n_estimators=500,
    max_depth=20,
    min_samples_split=5,
    min_samples_leaf=2,
    random_state=42,
    n_jobs=-1
)
rf_model.fit(X_train_scaled, y_train)
predictions['RandomForest'] = rf_model.predict(X_test_scaled)
models['RandomForest'] = rf_model
print(f"   ‚úÖ RandomForest R¬≤: {r2_score(y_test, predictions['RandomForest']):.4f}")

# ExtraTrees
print("\nüìà Training ExtraTrees...")
et_model = ExtraTreesRegressor(
    n_estimators=500,
    max_depth=None,
    min_samples_split=2,
    random_state=42,
    n_jobs=-1
)
et_model.fit(X_train_scaled, y_train)
predictions['ExtraTrees'] = et_model.predict(X_test_scaled)
models['ExtraTrees'] = et_model
print(f"   ‚úÖ ExtraTrees R¬≤: {r2_score(y_test, predictions['ExtraTrees']):.4f}")

# GradientBoosting
print("\nüìà Training GradientBoosting...")
gb_model = GradientBoostingRegressor(
    n_estimators=1000,
    max_depth=5,
    learning_rate=0.05,
    subsample=0.8,
    random_state=42
)
gb_model.fit(X_train_scaled, y_train)
predictions['GradientBoosting'] = gb_model.predict(X_test_scaled)
models['GradientBoosting'] = gb_model
print(f"   ‚úÖ GradientBoosting R¬≤: {r2_score(y_test, predictions['GradientBoosting']):.4f}")

print("\n‚úÖ All models trained successfully!")

# ====================================================================================
# 4. ENSEMBLE
# ====================================================================================
print("\nüéØ [4/5] Creating ensemble...")

# Simple averaging ensemble
ensemble_pred = np.mean(list(predictions.values()), axis=0)
ensemble_r2 = r2_score(y_test, ensemble_pred)

print(f"‚úÖ Ensemble R¬≤: {ensemble_r2:.4f}")

# ====================================================================================
# 5. SAVE MODELS
# ====================================================================================
print("\nüíæ [5/5] Saving models...")

import joblib

save_path = '/kaggle/working/ML_Project_Refactored/models/deployed'
os.makedirs(save_path, exist_ok=True)

# Save all models
for name, model in models.items():
    joblib.dump(model, f"{save_path}/{name}.pkl")

# Save scaler and feature names
joblib.dump(scaler, f"{save_path}/scaler.pkl")
joblib.dump(numeric_features, f"{save_path}/feature_names.pkl")

# Save best model info
best_model_name = max(predictions.keys(), key=lambda k: r2_score(y_test, predictions[k]))
joblib.dump(models[best_model_name], f"{save_path}/best_model.pkl")

print(f"\n‚úÖ Models saved to: {save_path}")
print(f"‚úÖ Best model: {best_model_name}")

# ====================================================================================
# SUMMARY
# ====================================================================================
print("\n" + "="*100)
print("‚ú® TRAINING COMPLETE!")
print("="*100)

for name in predictions.keys():
    r2 = r2_score(y_test, predictions[name])
    print(f"   {name:20s} R¬≤ = {r2:.6f}")

print(f"\n   {'Ensemble':20s} R¬≤ = {ensemble_r2:.6f}")
print("\n" + "="*100)
```

---

## üìä Expected Workflow

```mermaid
graph TD
    A[Cell 1: Setup] --> B[Copy Files]
    B --> C[Fix Imports]
    C --> D[Prepare Data]
    D --> E[Install Packages]
    E --> F[Cell 2: Training]
    F --> G[Load Data]
    G --> H[Create Features]
    H --> I[Train All Models]
    I --> J[Create Ensemble]
    J --> K[Save Models]
    K --> L[Complete!]
```

---

## ‚ö†Ô∏è Critical Reminders

1. **‡∏´‡πâ‡∏≤‡∏°‡∏Ç‡πâ‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏î‡πÜ** - ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ó‡∏£‡∏ô‡∏Ñ‡∏£‡∏ö‡∏ó‡∏∏‡∏Å‡∏ï‡∏±‡∏ß:
   - XGBoost
   - LightGBM
   - CatBoost
   - RandomForest
   - ExtraTrees
   - GradientBoosting
   - Ensemble

2. **‡∏´‡πâ‡∏≤‡∏°‡∏õ‡∏£‡∏±‡∏ö Configuration** ‡πÉ‡∏î‡πÜ ‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ error

3. **‡∏´‡πâ‡∏≤‡∏°‡∏•‡∏î Features** - ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ 250+ features ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î

4. **‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏°‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç** - ‡∏Ç‡∏≠‡πÅ‡∏Ñ‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏ó‡∏£‡∏ô‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡∏à‡∏∞‡∏ô‡∏≤‡∏ô 1 ‡∏ä‡∏°. ‡∏´‡∏£‡∏∑‡∏≠ 3 ‡∏ä‡∏°. ‡∏Å‡πá‡πÑ‡∏î‡πâ

5. **‡∏ó‡∏≥‡∏ï‡∏≤‡∏°‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô** - ‡∏≠‡∏¢‡πà‡∏≤‡∏Ç‡πâ‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡πÄ‡∏≠‡∏á

---

## üéØ Success Criteria

```python
# ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡∏à‡∏∞‡πÑ‡∏î‡πâ:
‚úÖ Models trained: 6+ models
‚úÖ Ensemble created
‚úÖ R¬≤ Score > 0.90
‚úÖ All models saved to /kaggle/working/ML_Project_Refactored/models/deployed/
‚úÖ No errors during training
```

---

## üìù Notes for Claude Code

1. **‡∏≠‡πà‡∏≤‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏î‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏¥‡∏°‡πÉ‡∏´‡πâ‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î** - ‡∏≠‡∏¢‡πà‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏á‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏≠‡∏∞‡πÑ‡∏£
2. **‡πÅ‡∏Å‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà error** - ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á optimize ‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á
3. **Test ‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô** - import ‚Üí function ‚Üí pipeline
4. **KISS principle** - Keep It Simple, Stupid!
5. **‡∏≠‡∏¢‡πà‡∏≤‡∏Ñ‡∏¥‡∏î‡πÅ‡∏ó‡∏ô** - ‡∏ó‡∏≥‡∏ï‡∏≤‡∏°‡∏™‡∏±‡πà‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô

---

## üîç Debugging Guide

‡∏´‡∏≤‡∏Å error:

1. ‡∏≠‡πà‡∏≤‡∏ô error message ‡πÉ‡∏´‡πâ‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö root cause (‡∏°‡∏±‡∏Å‡πÄ‡∏õ‡πá‡∏ô import ‡∏´‡∏£‡∏∑‡∏≠ KeyError)
3. ‡πÅ‡∏Å‡πâ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏ô‡∏ï‡∏≠ ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÅ‡∏Å‡πâ‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏¥‡∏î‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß
4. Test ‡∏ó‡∏µ‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô
5. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å error ‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ

---

## ‚úÖ Final Checklist

- [ ] Setup environment (Cell 1)
- [ ] Fix all imports
- [ ] Prepare data
- [ ] Install packages
- [ ] Train all models (Cell 2)
- [ ] Create ensemble
- [ ] Save models
- [ ] Verify R¬≤ > 0.90
- [ ] No errors

---

**‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢**: ‡πÉ‡∏´‡πâ Cell 2 ‡∏£‡∏±‡∏ô‡∏à‡∏ô‡∏à‡∏ö‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏°‡∏µ error ‡πÅ‡∏•‡∏∞‡πÑ‡∏î‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡∏°‡∏≤‡∏Ñ‡∏£‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î

**‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏**: ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠ instructions ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏ï‡∏≤‡∏° ‡∏´‡πâ‡∏≤‡∏°‡∏ó‡∏≥‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏≠‡∏∑‡πà‡∏ô‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ

---

*Generated for Claude Code by Alex - World-Class AI Expert*  
*Version: 1.0 | Last Updated: 2025-10-03*